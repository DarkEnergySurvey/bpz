{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Alhambra as validation</h2>\n",
    "\n",
    "-- Check Alhambra photo-z's meet WL requirement\n",
    "\n",
    "-- Weight color/may of spec-z to alhambra \n",
    "\n",
    "-- train machine on spec-z\n",
    "\n",
    "-- cull alhambra space until predictions agree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from weighted_kde import gaussian_kde as gss_kde\n",
    "import sys \n",
    "import time\n",
    "import cPickle as pickle\n",
    "import sml_mla as ml\n",
    "\n",
    "import ml_metrics as ml_m\n",
    "sys.path.append('/Users/hoyleb/Documents/python/modules/photoz-wg/validation/')\n",
    "import bh_photo_z_validation as pval\n",
    "import ml_params as mlp\n",
    "from astropy.table import Table, vstack\n",
    "\n",
    "from weighted_kde import gaussian_kde as gss_kde\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy.special import erf\n",
    "from sklearn import tree\n",
    "import copy\n",
    "from scipy import optimize\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor, NearestNeighbors\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import calculate_weights as cw\n",
    "import kmeansClusters as km\n",
    "import anomaly_detection as ad\n",
    "import augment_data as augd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def normalise(arr):\n",
    "    arr = np.array(arr, dtype=float)\n",
    "    arr = arr / np.sum(arr)\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#how many machines to train\n",
    "Nmachines = 50\n",
    "\n",
    "#some functions to generate a machine and to test performance\n",
    "def rand_machine():\n",
    "    clf = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "    if np.random.uniform() < 0.5:\n",
    "        clf = RandomForestRegressor()\n",
    "    # get parameters from this MLA\n",
    "    curr_params = clf.get_params()\n",
    "    params = mlp.getRandomParams()\n",
    "    params['n_estimators'] = np.random.randint(10, 100)\n",
    "    curr_params = ml.combineParameters(curr_params, params)\n",
    "    curr_params = ml.tree_loss(curr_params, clf)\n",
    "    clf.set_params(**curr_params)\n",
    "    return clf\n",
    "\n",
    "def get_score(truth_, pred_, sample_weight=None):\n",
    "    return  {'r2' : r2_score(truth_, pred_, sample_weight=sample_weight),\n",
    "     'other': ml_m.getStats((truth_ - pred_) / (1 + truth_), sample_weight=sample_weight)\n",
    "     }\n",
    "\n",
    "#loop over all trees to get a redshift dist\n",
    "def allPredictions(cl, inp):\n",
    "    pred = cl.predict(inp)\n",
    "\n",
    "    pdf = np.zeros((len(pred), len(cl.estimators_)))\n",
    "    if hasattr(cl, 'estimator_weights_'):\n",
    "        weights = cl.estimator_weights_ / np.sum(cl.estimator_weights_)\n",
    "        weightsInt = np.array(len(weights) * 3 / np.sum(weights) * weights, dtype=int)\n",
    "        wpdf = np.zeros((len(pred), np.sum(weightsInt)))\n",
    "        del pdf\n",
    "    sm = 0\n",
    "    for i, DT in enumerate(cl.estimators_):\n",
    "        if isinstance(DT, (list, tuple, np.ndarray)):\n",
    "            DT = DT[0]\n",
    "        DTz = DT.predict(inp)\n",
    "\n",
    "        if hasattr(cl, 'estimator_weights_'):\n",
    "            #make a weighted pdf\n",
    "            for j in range(weightsInt[i]):\n",
    "                wpdf[:, sm] = DTz\n",
    "                sm += 1\n",
    "        else:\n",
    "            pdf[:, i] = DTz\n",
    "\n",
    "    if hasattr(cl, 'estimator_weights_'):\n",
    "        rind = np.random.choice(range(sm), size=len(pred), replace=True)\n",
    "        return np.std(wpdf[:, 0:sm], axis=1), np.array([wpdf[i,rind[i]] for i in range(len(rind))])\n",
    "    \n",
    "    rind = np.random.choice(range(len(pdf[0])), size=len(pdf), replace=True)\n",
    "    return np.std(pdf, axis=1), np.array([pdf[i,rind[i]] for i in range(len(rind))])\n",
    "\n",
    "\n",
    "# parralelisation function\n",
    "# beware some global variables like score_metric is in here\n",
    "def xvFitPredict(_clf, inputs, outputs, train_weights_arr, _indho):\n",
    "\n",
    "    # train on non held out\n",
    "    _intr = np.setdiff1d(np.arange(len(inputs)), _indho, assume_unique=True)\n",
    "\n",
    "    inp_ = copy.deepcopy(inputs[_intr])\n",
    "    outp_ = copy.deepcopy(outputs[_intr])\n",
    "\n",
    "    #if we have training weights, then bootstrap resample from weights\n",
    "\n",
    "    wt_ = train_weights_arr[_intr]\n",
    "    wt_ = wt_ / np.sum(wt_)\n",
    "\n",
    "    _clf.fit(inp_, outp_, wt_)\n",
    "\n",
    "    dictXv = {}\n",
    "    # calculate stats on held out fraction\n",
    "    dictXv['predict'] = _clf.predict(inputs[_indho])\n",
    "\n",
    "    dictXv['sigma'] = allPredictions(_clf, inputs[_indho])\n",
    "\n",
    "    # calcaulate score\n",
    "    dictXv['scoreXv'] = get_score(outputs[_indho], dictXv['predict'], \n",
    "                                  sample_weight=train_weights_arr[_indho])\n",
    "    dictXv['outputs'] = outputs[_indho]\n",
    "    dictXv['index'] = _indho\n",
    "    return dictXv\n",
    "\n",
    "\n",
    "import augment_data as ad\n",
    "\n",
    "#kde_augment or kde_knn_augment\n",
    "\n",
    "def k_fold_val(inputs, outputs, train_weights, Nfolds, Niterations):\n",
    "      \n",
    "    indHo = np.array_split(np.arange(len(inputs)), Nfolds)\n",
    "    results = {}\n",
    "    score_best = 100\n",
    "    for i in range(Niterations):\n",
    "        \n",
    "        clf = rand_machine()\n",
    "        resXv = {}\n",
    "        for j in range(len(indHo)):\n",
    "            resXv[j] = xvFitPredict(clf, inputs, outputs, train_weights, indHo[j])\n",
    "            \n",
    "        scoreXv = np.zeros(Nfolds).astype(float)\n",
    "        predict = np.zeros(len(inputs), dtype=float)\n",
    "        sigma = np.zeros(len(inputs), dtype=float)\n",
    "        for k in resXv:\n",
    "            scoreXv[k] = resXv[k]['scoreXv']['other']['sigma_68']\n",
    "            predict[indHo[k]] = resXv[k]['predict']\n",
    "            sigma[indHo[k]] = resXv[k]['sigma']\n",
    "            \n",
    "        score = np.mean(scoreXv)\n",
    "        print score, np.std(scoreXv)\n",
    "        \n",
    "        if score < score_best:\n",
    "            score_best = score\n",
    "            #results['xval'] = resXv\n",
    "            clf.fit(inputs, outputs, train_weights)\n",
    "            results['clf'] = clf\n",
    "            results['predict'] = predict\n",
    "            results['sigma'] = sigma\n",
    "            results['z_mc'] = predict + np.random.normal(size=len(predict)) * sigma\n",
    "            \n",
    "    return results, score_best\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "almost_black = '#262626'\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams.update({'font.size': 32, \n",
    "                     'axes.linewidth': 5,\n",
    "                    'text.color': almost_black,\n",
    "                    'xtick.major.size': 4,\n",
    "                    'ytick.major.size': 4,\n",
    "                    'legend.fancybox': True,\n",
    "                    'figure.dpi': 300,\n",
    "                    'legend.fontsize': 14,\n",
    "                    'legend.framealpha': 0.8,\n",
    "                    'legend.shadow': True,\n",
    "                    'xtick.labelsize': 32,\n",
    "                     'markersize': 10,\n",
    "                     'elinewidth':2,\n",
    "                    'ytick.labelsize': 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imag = np.linspace(17,24,15)\n",
    "imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Does alahmbra photo-z matched to spec-z meet WL requirements?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1Spec_Matched_Alhambra.fits')\n",
    "#print d.keys()\n",
    "PRIMUS = np.array([i.replace(' ','')== 'PRIMUS' for i in d['SOURCE']])\n",
    "\n",
    "i = np.array(d['FLAG'] != 3) * np.array(PRIMUS == False) * (d['MAG_AUTO_I']<24)\n",
    "d = d[i]\n",
    "plt.plot(d['zb_1'], d['SPEC_Z'], 'o')\n",
    "plt.xlabel('Alhambra q-z')\n",
    "plt.ylabel('spec-z')\n",
    "deltaz = ml_m.DeltaZ(np.array(d['SPEC_Z']), np.array(d['zb_1']))\n",
    "print 'stats on (spec-z - alh-z)/(1 + spec-z)'\n",
    "print ml_m.getStats(deltaz)\n",
    "print 'for {:} objects'.format(len(deltaz))\n",
    "\n",
    "print \"np.amin(d['MAG_AUTO_I']), np.amax(d['MAG_AUTO_I'])\"\n",
    "print np.amin(d['MAG_AUTO_I']), np.amax(d['MAG_AUTO_I'])\n",
    "\n",
    "num = []\n",
    "f = plt.figure()\n",
    "bns = np.linspace(-1,1, 100)\n",
    "bn = (bns[1:] + bns[:-1]) / 2.0\n",
    "i_err = {'cosmos': {}, 'alhambra':{},'i_mag':imag, 'cosmos_num': {},'alhambra_num':{} }\n",
    "\n",
    "\n",
    "for i in range(len(imag)-1):\n",
    "    ind = np.array(d['MAG_AUTO_I'] <= imag[i + 1]) * np.array(d['MAG_AUTO_I'] > imag[i])\n",
    "    num.append(np.sum(ind))\n",
    "    if np.sum(ind) > 1:\n",
    "        deltaz = ml_m.DeltaZ(d['SPEC_Z'][ind], d['zb_1'][ind])\n",
    "        h = np.histogram(deltaz, bins=bns)[0]\n",
    "        sts = ml_m.getStats(deltaz)\n",
    "        plt.plot(bn, h, label='{:}'.format(sts['sigma_68']))\n",
    "        i_err['alhambra']['{:}'.format(imag[i])] = deltaz\n",
    "        i_err['alhambra_num']['{:}'.format(imag[i])] = np.sum(ind)\n",
    "        print imag[i + 1]\n",
    "        print sts\n",
    "        print np.sum(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Quantify the redshift error from using photo-z not spec-z as true z</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cosmos data\n",
    "d = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1Spec_Matched_COSMOS.fits')\n",
    "PRIMUS = np.array([i.replace(' ','')== 'PRIMUS' for i in d['SOURCE']])\n",
    "i = np.array(d['FLAG'] != 3) * np.array(PRIMUS == False)\n",
    "d = d[i]\n",
    "\n",
    "plt.plot(d['ZMINCHI2'], d['SPEC_Z'], 'o')\n",
    "plt.xlabel('Cosmos p-z')\n",
    "plt.ylabel('spec-z')\n",
    "deltaz = ml_m.DeltaZ(d['SPEC_Z'], d['ZMINCHI2'])\n",
    "print 'stats on (spec-z - cos-z)/(1 + spec-z)'\n",
    "print ml_m.getStats(deltaz)\n",
    "print 'for {:} objects'.format(len(deltaz))\n",
    "\n",
    "num = []\n",
    "f = plt.figure()\n",
    "for i in range(len(imag)-1):\n",
    "    ind = np.array(d['MAG_AUTO_I_2'] <= imag[i + 1]) * np.array(d['MAG_AUTO_I_2'] > imag[i])\n",
    "    num.append(np.sum(ind))\n",
    "    if np.sum(ind) > 1:\n",
    "        deltaz = ml_m.DeltaZ(np.array(d['SPEC_Z'][ind]), np.array(d['ZMINCHI2'][ind]))\n",
    "        h = np.histogram(deltaz, bins=bns)[0]\n",
    "        sts = ml_m.getStats(deltaz)\n",
    "        plt.plot(bn, h, label='{:}'.format(sts['sigma_68']))\n",
    "        i_err['cosmos']['{:}'.format(imag[i])] = deltaz\n",
    "        i_err['cosmos_num']['{:}'.format(imag[i])] = np.sum(ind)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "f = plt.figure()\n",
    "plt.plot((imag[1:]+imag[:-1])/2.0, num )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(i_err, open('/Users/hoyleb/DATA/DES/PHOTOZ/CosmosAlhambra_phot_spec_z_rescaling.p', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generating photo-z like data with the correct distributions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = d[d['MAG_AUTO_I_2']<24]\n",
    "ind1 = np.random.choice(np.arange(len(d)), size=1e5, replace=True)\n",
    "\n",
    "\n",
    "z = np.array(d['SPEC_Z'][ind1]) # or the redshift column\n",
    "mag_auto_i = np.array(d['MAG_AUTO_I_2'][ind1]) # the magnitude column\n",
    "\n",
    "#note predictions are only suitable for 16<MAG_AUTO_I<24\n",
    "z_alh = np.zeros_like(z)\n",
    "print np.amin(mag_auto_i), np.amax(mag_auto_i)\n",
    "for i in np.arange(len(i_err['i_mag'])-1):\n",
    "    ind = (mag_auto_i > i_err['i_mag'][i]) * (mag_auto_i <= i_err['i_mag'][i+1])\n",
    "    if np.sum(ind) > 0:\n",
    "        z_alh[ind] = z[ind] +  np.random.choice(i_err['cosmos']['{:}'.format(i_err['i_mag'][i])], size=np.sum(ind), replace=True)\n",
    "\n",
    "        \n",
    "plt.plot(z_alh, z, 'o')\n",
    "plt.xlabel('phot-z')\n",
    "plt.ylabel('spec-z')\n",
    "\n",
    "deltaz = ml_m.DeltaZ(z, z_alh)\n",
    "print 'stats on (spec-z - cos-z)/(1 + spec-z)'\n",
    "print ml_m.getStats(deltaz)\n",
    "print \" \"\n",
    "print ml_m.getStats(ml_m.DeltaZ(np.array(d['SPEC_Z'][ind1]), np.array(d['ZMINCHI2'])[ind1]))\n",
    "\n",
    "print \" \"\n",
    "print \"{'errsig68': 0.0002357407488243309, 'outlierFrac': 3.280067283431455, 'median': 0.00047995645364236903, 'sigma_68': 0.011495836644654334, 'sigma_95': 0.079045752990336296, 'sigma': 0.082332335184199301, 'mean': 0.00061993605824146067}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.amin(d['MAG_AUTO_I_2']), np.amax(d['MAG_AUTO_I_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=6\n",
    "_ = plt.hist(np.random.choice(i_err['alhambra']['{:}'.format(i_err['i_mag'][i])], size=5000, replace=True), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Compare alahmbra photo-z and cosmos photo-z</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compare cosmos and alhambra photo-z's\n",
    "dac = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/ALHAMBRA_Matched_COSMOS_1as.fits')\n",
    "print dac.keys()\n",
    "#PRIMUS = np.array([i.replace(' ','')== 'PRIMUS' for i in d1['SOURCE']])\n",
    "i = np.array(dac['MAG_AUTO_I'] < 23.5 ) * np.array(dac['MAG_AUTO_I'] > 17 ) * np.array(dac['MAGERR_AUTO_I'] <0.4 )\n",
    "#i = np.ones(len(dac), dtype=bool)\n",
    "plt.plot(dac['ZMINCHI2'][i], dac['zb_1'][i], 'o')\n",
    "plt.xlabel('Cosmos p-z')\n",
    "plt.ylabel('ALhambra-z')\n",
    "deltaz = ml_m.DeltaZ(dac['zb_1'][i], dac['ZMINCHI2'][i])\n",
    "print 'stats on (alh-z - cos-z)/(1 + spec-z)'\n",
    "print ml_m.getStats(deltaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dac.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103Spec_notin_Alhambra.fits')\n",
    "PRIMUS = np.array([i.replace(' ','')== 'PRIMUS' for i in d1['SOURCE']])\n",
    "i = np.array(d1['FLAG'] != 3) * np.array(PRIMUS == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1[i].write('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103Spec_notin_Alhambra_noPrimus_flagne3.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print  np.sum(np.array(PRIMUS == False)), np.sum(np.array(d1['FLAG'] != 3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(d1), np.sum(i)\n",
    "d1 = d1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sml_mla as ml\n",
    "import calculate_weights as cw\n",
    "\n",
    "test_d = '/Users/hoyleb/DATA/DES/PHOTOZ/merged.Y1A1_GOLD_1_0_3_000001.fits_alhambra.fits'\n",
    "weight_f = ['MAG_AUTO_G','MAG_AUTO_R','MAG_AUTO_I','MAG_AUTO_Z','MAG_AUTO_I-MAG_AUTO_R',\n",
    "            'MAG_AUTO_G-MAG_AUTO_R','MAG_AUTO_I-MAG_AUTO_Z']\n",
    "\n",
    "inptestW, test_info = ml.dataSet(test_d, weight_f, ['COADD_OBJECTS_ID', 'zb_1']).loadData()\n",
    "inpTrain, train_info = ml.dataSet(d1, weight_f, ['COADD_OBJECTS_ID', 'SPEC_Z']).loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n_neighbors_array = [1,2,3,4,5,10]\n",
    "train_test = cw.best_lima_knn_weights(\n",
    "        inpTrain,\n",
    "        inptestW,\n",
    "        verbose=1,\n",
    "        n_neighbors_array=n_neighbors_array\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1['WEIGHTS_TO_ALHAMBRA'] = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zbins = np.linspace(0, 1.6, num = 100)\n",
    "train_t_z = gss_kde(np.array(train_info['SPEC_Z']), weights=train_test).evaluate(zbins) \n",
    "train_t_nw_z = gss_kde(np.array(train_info['SPEC_Z'])).evaluate(zbins) \n",
    "test_t_z = gss_kde(np.array(test_info['zb_1'])).evaluate(zbins) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(zbins, train_t_nw_z, label='UnWeighted spec-z dist')\n",
    "plt.plot(zbins, train_t_z, label='Weighted spec-z dist')\n",
    "plt.plot(zbins, test_t_z, label='ALHAMBRA photo-z dist')\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, mag in enumerate(weight_f):\n",
    "    mbins = np.linspace(np.amin(inptestW[:, i]),np.amax(inptestW[:, i]), num = 100)\n",
    "    train_t_z = gss_kde(np.array(inpTrain[:, i]), weights=train_test).evaluate(mbins) \n",
    "    test_t_z = gss_kde(np.array(inptestW[:, i])).evaluate(mbins) \n",
    "    f = plt.figure()\n",
    "    plt.plot(zbins, train_t_z, label='Weighted spec dist')\n",
    "    plt.plot(zbins, test_t_z, label='ALHAMBRA dist')\n",
    "    plt.legend()\n",
    "    plt.xlabel(mag)\n",
    "    plt.ylabel('density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = np.array(d1['WEIGHTS_TO_ALHAMBRA'] > 0)\n",
    "print np.sum(i)\n",
    "_ = plt.hist(d1['WEIGHTS_TO_ALHAMBRA'][i],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2 = d1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2.write('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103Spec_notin_Alhambra_noPrimus_flagne3.weights.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make predictions on alhambra using \n",
    "#%>des_ml_output.py ml_alhambra.outxv20.p merged.Y1A1_GOLD_1_0_3_000001.fits_alhambra.fits MAGERR_AUTO_I,MAGERR_AUTO_R,MAGERR_AUTO_Z,MAGERR_AUTO_G,MAG_AUTO_G,MAG_AUTO_R,MAG_AUTO_I,MAG_AUTO_Z,COADD_OBJECTS_ID,zb_1\n",
    "res = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/merged.Y1A1_GOLD_1_0_3_000001.fits_alhambra.fitsml_alhambra.outxv20.DES.point.predictions.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print res.keys()\n",
    "i = np.array(res['MAGERR_AUTO_I']  > 0 ) * np.array(res['MAGERR_AUTO_I'] < 0.2) * np.array(\n",
    "    res['MAG_AUTO_I'] - res['MAG_AUTO_Z'] > -10) * np.array(res['MAG_AUTO_Z'] > 16) * np.array(\n",
    "    res['MAG_AUTO_Z']<25) * np.array(res['MAG_AUTO_I'] > 16) * np.array(res['MAG_AUTO_I']<23.5) * np.array(\n",
    "    res['MAG_AUTO_R'] > 16) * np.array(res['MAG_AUTO_R']<25) * np.array(\n",
    "    res['MAG_AUTO_G'] > 16) * np.array(res['MAG_AUTO_G']<25)\n",
    "res = res[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(res['zb_1'], res['Z'],',')\n",
    "plt.xlabel('Alhambra-z')\n",
    "plt.ylabel('ML-z')\n",
    "plt.plot([0, 3], [0, 3], '--', linewidth=2, color=almost_black)\n",
    "plt.xlim(0, 3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "deltaz = ml_m.DeltaZ(res['zb_1'], res['Z'])\n",
    "print 'stats on (ALH-z - ML-z)/(1 + ALH-z)'\n",
    "print ml_m.getStats(deltaz)\n",
    "\n",
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (res['Z'] < zbins[i+1]) * (res['Z'] >= zbins[i])\n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(res['MAGERR_AUTO_I'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp_res, res_info = ml.dataSet(res, weight_f, ['COADD_OBJECTS_ID']).loadData()\n",
    "for i, mag in enumerate(weight_f):\n",
    "    f = plt.figure()\n",
    "    plt.plot(inp_res[: ,i], deltaz, ',', label='Delta_z')\n",
    "    plt.legend()\n",
    "    plt.xlabel(mag)\n",
    "    plt.ylabel('Delta_z')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#kmeans clusters on \n",
    "clf = km.fit_kmeans(inp_res, 25, verbose=True)\n",
    "clusters = km.get_clusters(clf, inp_res)\n",
    "keep = np.zeros(len(clusters), dtype=bool)\n",
    "deltaz = ml_m.DeltaZ(res['zb_1'], res['Z'])\n",
    "for i in np.unique(clusters):\n",
    "    ind = clusters == i\n",
    "    indx = np.arange(len(ind))[ind]\n",
    "    np.random.shuffle(indx)\n",
    "    \n",
    "    if np.sum(ind) > 75:\n",
    "        sts =  ml_m.getStats(deltaz[indx[0: int(len(indx)*0.3)]])\n",
    "        print 'cluster {:}'.format(i)\n",
    "        print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "        if sts['sigma_68'] < 0.1:\n",
    "            keep[indx[int(len(indx) * 0.3): ]] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(keep), len(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "res_keep = res[keep]\n",
    "\n",
    "plt.plot(res_keep['zb_1'], res_keep['Z'],',')\n",
    "plt.xlabel('Alhambra-z')\n",
    "plt.ylabel('ML-z')\n",
    "plt.plot([0, 3], [0, 3], '--', linewidth=2, color=almost_black)\n",
    "plt.xlim(0, 3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "deltaz_keep =  ml_m.DeltaZ(res_keep['zb_1'], res_keep['Z'])\n",
    "print 'stats on (ALH-z - alh-z)/(1 + ALH-z)' ,len(res_keep), len(res) \n",
    "print ml_m.getStats(deltaz_keep)\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (res_keep['Z'] < zbins[i+1]) * (res_keep['Z'] >= zbins[i])\n",
    "    ind1 = (res['Z'] < zbins[i+1]) * (res['Z'] >= zbins[i])\n",
    "    \n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts), 'Culled data {:0.2f}%'.format(100 - np.sum(ind)*100.0 / np.sum(ind1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dspec = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103Spec_notin_Alhambra.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dspec = dspec[dspec['FLAG'] != 3]\n",
    "print np.unique(np.array(dspec['SOURCE']))\n",
    "SOURCE = np.array([i.replace(' ', '') for i in dspec['SOURCE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zbins = np.linspace(0, 1.6, num = 100)\n",
    "test_t_z = gss_kde(np.array(test_info['zb_1'])).evaluate(zbins) \n",
    "best_chi2 = 1e99\n",
    "for i in range(500):\n",
    "    sample = np.random.choice(np.unique(SOURCE), size=np.random.randint(1, len(np.unique(SOURCE))), replace=False )\n",
    "    ind = np.zeros(len(SOURCE), dtype=bool)\n",
    "    for j in sample:\n",
    "        ind += j == SOURCE \n",
    "    train_t_nw_z = gss_kde(np.array(dspec['SPEC_Z'][ind])).evaluate(zbins) \n",
    "    \n",
    "    chi2 = np.sum((train_t_nw_z - test_t_z)**2)\n",
    "    if chi2 < best_chi2:\n",
    "        best_chi2 = chi2\n",
    "        best_sample = sample\n",
    "        print chi2, sample\n",
    "\n",
    "ind = np.zeros(len(SOURCE), dtype=bool)\n",
    "for j in best_sample:\n",
    "    ind += j == SOURCE \n",
    "train_t_nw_z = gss_kde(np.array(dspec['SPEC_Z'][ind])).evaluate(zbins) \n",
    "\n",
    "plt.plot(zbins, train_t_nw_z, label='Selected spec-z dist')\n",
    "plt.plot(zbins, test_t_z, label='ALHAMBRA photo-z dist')\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('density')\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('density')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_sample = ['EBOSS_DES_ELG', 'VUDS', 'DEEP2', 'SDSS_OZDES' ,'DES_AAOMEGA' ,'DR12_LOWZ' ,'SPARCS', 'ATLAS']\n",
    "best_sample = ['3DHST', 'PANSTARRS']\n",
    "\n",
    "ind = np.zeros(len(SOURCE), dtype=bool)\n",
    "for j in best_sample:\n",
    "    ind += j == SOURCE \n",
    "    \n",
    "print np.sum(ind)\n",
    "train_t_nw_z = gss_kde(np.array(dspec['SPEC_Z'][ind])).evaluate(zbins) \n",
    "\n",
    "plt.plot(zbins, train_t_nw_z, label='Selected spec-z dist')\n",
    "plt.plot(zbins, test_t_z, label='ALHAMBRA photo-z dist')\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('density')\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.sum(ind)\n",
    "\n",
    "test_d = '/Users/hoyleb/DATA/DES/PHOTOZ/merged.Y1A1_GOLD_1_0_3_000001.fits_alhambra.fits'\n",
    "weight_f = ['MAG_AUTO_G','MAG_AUTO_R','MAG_AUTO_I','MAG_AUTO_Z','MAG_AUTO_I-MAG_AUTO_R',\n",
    "            'MAG_AUTO_G-MAG_AUTO_R','MAG_AUTO_I-MAG_AUTO_Z']\n",
    "inptestW, test_info = ml.dataSet(res, weight_f, ['COADD_OBJECTS_ID', 'zb_1']).loadData()\n",
    "inpTrain, train_info = ml.dataSet(dspec[ind], weight_f, ['COADD_OBJECTS_ID', 'SPEC_Z']).loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_neighbors_array = [1,2,3,4,5,10]\n",
    "train_test = cw.best_lima_knn_weights(\n",
    "        inpTrain,\n",
    "        inptestW,\n",
    "        verbose=1,\n",
    "        n_neighbors_array=n_neighbors_array\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dspec = dspec[ind]\n",
    "dspec['WEIGHTS_TO_ALHAMBRA'] = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_t_nw_z = gss_kde(np.array(dspec['SPEC_Z'])).evaluate(zbins) \n",
    "zbins = np.linspace(0, 1.6, num = 100)\n",
    "train_t_z = gss_kde(np.array(dspec['SPEC_Z']), weights=train_test).evaluate(zbins) \n",
    "train_t_nw_z = gss_kde(np.array(dspec['SPEC_Z'])).evaluate(zbins) \n",
    "test_t_z = gss_kde(np.array(test_info['zb_1'])).evaluate(zbins) \n",
    "plt.plot(zbins, train_t_nw_z, label='UnWeighted spec-z dist')\n",
    "plt.plot(zbins, train_t_z, label='Weighted spec-z dist')\n",
    "plt.plot(zbins, test_t_z, label='ALHAMBRA photo-z dist')\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('density')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dspec.write('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103Spec_notin_Alhambra.selected_sample1.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CHFTLS \n",
    "res_chf = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1A1_GOLD_1_0_3_COSMOS2015_matched.fitsml_alhambra.outxv20.DES.point.predictions.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep = np.ones(len(res_chf), dtype=bool)\n",
    "keep = np.array(res_chf['MAG_AUTO_I'] < 24) * np.array(res_chf['MAGERR_AUTO_I'] < 0.4) *np.array(res_chf['MAG_AUTO_I'] > 17)\n",
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "res_keep = res_chf[keep]\n",
    "\n",
    "plt.plot(res_keep['ZMINCHI2'], res_keep['Z'],',')\n",
    "plt.xlabel('Cosmos-z')\n",
    "plt.ylabel('ML-z')\n",
    "plt.plot([0, 3], [0, 3], '--', linewidth=2, color=almost_black)\n",
    "plt.xlim(0, 3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "deltaz_keep =  ml_m.DeltaZ(res_keep['ZMINCHI2'], res_keep['Z'])\n",
    "print 'stats on (COSMOS-z - alh-z)/(1 + COSMOS-z)' ,len(res_keep), len(res) \n",
    "print ml_m.getStats(deltaz_keep)\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (res_keep['Z'] < zbins[i+1]) * (res_keep['Z'] >= zbins[i])\n",
    "    ind1 = (res_chf['Z'] < zbins[i+1]) * (res_chf['Z'] >= zbins[i])\n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts), 'Culled data {:0.2f}%'.format(100 - np.sum(ind)*100.0 / np.sum(ind1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kmeans clusters on \n",
    "inp_res, res_info = ml.dataSet(res_chf, weight_f, ['COADD_OBJECTS_ID']).loadData()\n",
    "\n",
    "clf = km.fit_kmeans(inp_res, 50, verbose=True)\n",
    "clusters = km.get_clusters(clf, inp_res)\n",
    "deltaz =  ml_m.DeltaZ(res_chf['ZMINCHI2'], res_chf['Z'])\n",
    "keep = np.zeros(len(clusters), dtype=bool)\n",
    "keep_cluster = []\n",
    "for i in np.unique(clusters):\n",
    "    ind = clusters == i\n",
    "    indx = np.arange(len(ind))[ind]\n",
    "    np.random.shuffle(indx)\n",
    "    \n",
    "    if np.sum(ind) > 75:\n",
    "        sts =  ml_m.getStats(deltaz[indx[0: int(len(indx)*0.3)]])\n",
    "        print 'cluster {:}'.format(i)\n",
    "        print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "        if sts['sigma_68'] < 0.1:\n",
    "            keep[indx[int(len(indx) * 0.3): ]] = True\n",
    "            keep_cluster.append(i)\n",
    "print keep_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "res_keep = res_chf[keep]\n",
    "\n",
    "plt.plot(res_keep['ZMINCHI2'], res_keep['Z'],',')\n",
    "plt.xlabel('Cosmos-z')\n",
    "plt.ylabel('ML-z')\n",
    "plt.plot([0, 3], [0, 3], '--', linewidth=2, color=almost_black)\n",
    "plt.xlim(0, 3)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "deltaz_keep =  ml_m.DeltaZ(res_keep['ZMINCHI2'], res_keep['Z'])\n",
    "print 'stats on (Cosmos-z - alh-z)/(1 + ALH-z)' ,len(res_keep), len(res_chf) \n",
    "print ml_m.getStats(deltaz_keep)\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (res_keep['Z'] < zbins[i+1]) * (res_keep['Z'] >= zbins[i])\n",
    "    ind1 = (res_chf['Z'] < zbins[i+1]) * (res_chf['Z'] >= zbins[i])\n",
    "    \n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(\n",
    "        **sts), 'Culled data {:0.2f}%'.format(100 - np.sum(ind) * (100.0 / 0.66) / np.sum(ind1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#kmeans clusters on \n",
    "inp_wl, res_wl = ml.dataSet('/Users/hoyleb/DATA/DES/PHOTOZ/WL_INFO_0_1M_ID.Y1A1_GOLD_1_0_3.nside128.fits', \n",
    "                          weight_f, ['COADD_OBJECTS_ID']).loadData()\n",
    "#how much WL data do we throw away?\n",
    "clusters_wl = km.get_clusters(clf, inp_wl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kmeans clusters on \n",
    "print keep_cluster\n",
    "kept_wl = 0\n",
    "indkeep = np.zeros(len(clusters_wl), dtype=bool)\n",
    "for i in keep_cluster:\n",
    "    ind = i == clusters_wl\n",
    "    if np.sum(ind) > 0:\n",
    "        kept_wl += np.sum(ind) \n",
    "        indkeep[ind] = True\n",
    "print 'WL sample kept={:}, total={:} fraction kept: {:} %'.format(kept_wl , len(clusters_wl), kept_wl * 100.0 / len(clusters_wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, mag in enumerate(weight_f):\n",
    "    mbins = np.linspace(np.amin(inp_wl[indkeep, i]),np.amax(inp_wl[indkeep, i]), num = 100)\n",
    "    uncut_m = gss_kde(np.array(inp_wl[:, i])).evaluate(mbins) \n",
    "    cut_m = gss_kde(np.array(inp_wl[indkeep, i])).evaluate(mbins) \n",
    "    f = plt.figure()\n",
    "    plt.plot(mbins, uncut_m, label='Full WL dist')\n",
    "    plt.plot(mbins, cut_m, label='Culled WL dist')\n",
    "    plt.legend()\n",
    "    plt.xlabel(mag)\n",
    "    plt.ylabel('density')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=Table.read('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.fits')\n",
    "print len(d)\n",
    "d = d[d['F814W'] < 24]\n",
    "d = d[d['Stellar_Flag'] <=0.7 ]\n",
    "print len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(d['Stellar_Flag'])\n",
    "\n",
    "f = plt.figure()\n",
    "\n",
    "for i in np.unique(d['Field']):\n",
    "    ind = np.array(i == d['Field'])\n",
    "    plt.plot(d['RA'][ind], d['Dec'][ind], '--', label=str(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('Dec')\n",
    "#plt.ylim(0,10)\n",
    "#plt.xlim(30,170)\n",
    "\n",
    "ind = np.array(4 == d['Field'])\n",
    "d[ind].write('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.DESY1A1.fits')\n",
    "d[ind == False].write('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.nonDESY1A1.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dn = Table.read('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.nonDESY1A1.fitsphotoz.DesY1A1.xv100.DES.point.predictions.fits')\n",
    "#comparison with kfold cross validation:\n",
    "res = p.load(open('/Users/hoyleb/DATA/ALHAMBRA/photoz.DesY1A1.xv100.p', 'r'))\n",
    "scoreXv = np.zeros(0)\n",
    "truths = np.zeros(0)\n",
    "indexXv = np.zeros(0, dtype=int)\n",
    "prediction = np.zeros(0)\n",
    "ID = np.zeros(0, dtype=int)\n",
    "\n",
    "for ii, j in enumerate(res['results']['resXv']):\n",
    "    scoreXv = np.append(scoreXv, j['scoreXv'])\n",
    "    prediction = np.append(prediction, j['predict'])\n",
    "    indexXv = np.append(indexXv, j['index'])\n",
    "    truths = np.append(truths, j['outputs'])\n",
    "    ID = np.append(ID, j['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "\n",
    "deltaz_keep =  ml_m.DeltaZ(truths, prediction)\n",
    "print 'stats on (AH-z - ML-z)/(1 + ALH-z)'\n",
    "print ml_m.getStats(deltaz_keep)\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (prediction < zbins[i+1]) * (prediction >= zbins[i])\n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make COSMOS data clean</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1A1_GOLD_1_0_3_COSMOS2015_matched.fits')\n",
    "print len(d)\n",
    "d = d[d['MAG_AUTO_I']<23.5]\n",
    "d = d[d['MAG_AUTO_I']>15]\n",
    "d = d[d['MAGERR_AUTO_I']>0]\n",
    "d = d[d['MAGERR_AUTO_I']<0.3]\n",
    "\n",
    "for i in ['MAG_AUTO_R', 'MAG_AUTO_G', 'MAG_AUTO_I', 'MAG_AUTO_Z']:\n",
    "    d = d[d[i]<27]\n",
    "    d = d[d[i]>12]\n",
    "\n",
    "    \n",
    "for i in ['MAGERR_AUTO_R', 'MAGERR_AUTO_G', 'MAGERR_AUTO_I', 'MAGERR_AUTO_Z']:\n",
    "    d = d[d[i]<0.5]\n",
    "    d = d[d[i]>0]\n",
    "\n",
    "    \n",
    "print len(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d.write('/Users/hoyleb/DATA/DES/PHOTOZ/Y1A1_GOLD_1_0_3_COSMOS2015_matched.cleanmags.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train on DES mags in alhambra field 4</h3>\n",
    "Do we hit requirements, assuming no cosmic variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = p.load(open('/Users/hoyleb/DATA/ALHAMBRA/photoz.Alhabra.Desmags.z.xv50.p', 'r'))\n",
    "scoreXv = np.zeros(0)\n",
    "truths = np.zeros(0)\n",
    "indexXv = np.zeros(0, dtype=int)\n",
    "prediction = np.zeros(0)\n",
    "ID = np.zeros(0, dtype=int)\n",
    "\n",
    "for ii, j in enumerate(res['results']['resXv']):\n",
    "    scoreXv = np.append(scoreXv, j['scoreXv'])\n",
    "    prediction = np.append(prediction, j['predict'])\n",
    "    indexXv = np.append(indexXv, j['index'])\n",
    "    truths = np.append(truths, j['outputs'])\n",
    "    ID = np.append(ID, j['id'])\n",
    "\n",
    "'Print DES g/r/i/z photometry'\n",
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "\n",
    "deltaz_keep =  ml_m.DeltaZ(truths, prediction)\n",
    "print 'stats on (AH-z - ML-z)/(1 + ALH-z)'\n",
    "print ml_m.getStats(deltaz_keep)\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (prediction < zbins[i+1]) * (prediction >= zbins[i])\n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we hit requirements when we use pseudo DES photometry from other fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = Table.read('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.fits.pseudoDesMags.fitsphotoz.Alhabra.Desmags.z.xv50.DES.point.predictions.fits')\n",
    "d = d[d['Stellar_Flag'] < 0.7]\n",
    "d = d[d['F814W'] < 24]\n",
    "d = d[d['MAG_AUTO_I']<23.5]\n",
    "print 'Pseudo des photometery'\n",
    "\n",
    "print 'All fields together'\n",
    "\n",
    "truths = d['zb_1']\n",
    "prediction = d['Z']\n",
    "deltaz_keep =  ml_m.DeltaZ(truths, prediction)\n",
    "print 'stats on (AH-z - ML-z)/(1 + ALH-z)'\n",
    "print ml_m.getStats(deltaz_keep)\n",
    "for i in range(len(zbins) - 1):\n",
    "    ind = (prediction < zbins[i+1]) * (prediction >= zbins[i])\n",
    "    print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "    sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "    print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "\n",
    "    print 'wl_val_test', wl_val_test(np.mean(prediction[ind]), np.mean(truths[ind]))\n",
    "    \n",
    "for field in np.unique(d['Field']):\n",
    "    ind  = d['Field'] == field\n",
    "    print ' '\n",
    "    print 'Field: ',field\n",
    "    \n",
    "    deltaz_keep =  ml_m.DeltaZ(truths[ind], prediction[ind])\n",
    "    print 'stats on (AH-z - ML-z)/(1 + ALH-z)'\n",
    "    print ml_m.getStats(deltaz_keep)\n",
    "    for i in range(len(zbins) - 1):\n",
    "        ind1 = (prediction[ind] < zbins[i+1]) * (prediction[ind] >= zbins[i])\n",
    "        print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "        sts =  ml_m.getStats(deltaz_keep[ind1])\n",
    "        print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "        print 'wl_val_test', wl_val_test(np.mean(prediction[ind][ind1]), np.mean(truths[ind][ind1]))\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zbins = np.array([0, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3])\n",
    "\n",
    "for i in np.unique(d['Field']):\n",
    "    ind = np.array(i == d['Field'])\n",
    "    #plt.plot(d['Z'][ind], d['zb_1'][ind], 'o', label='Region:{:} Number {:}'.format(str(i), np.sum(ind)))\n",
    "\n",
    "    d_ = d[ind]\n",
    "    deltaz_keep =  ml_m.DeltaZ(d_['zb_1'], d_['Z'])\n",
    "    hb = np.histogram(deltaz_keep, bins=np.arange(150)/75.0 - 1)\n",
    "    plt.plot(hb[1][1:] - 1.0/150, hb[0] *1.0 / np.sum(hb[0]), label='Region:{:} Number {:}'.format(str(i), np.sum(ind)))\n",
    "    print 'stats on (AH-z - ML-z)/(1 + ALH-z)'\n",
    "    print ml_m.getStats(deltaz_keep)\n",
    "    for i in range(len(zbins) - 1):\n",
    "        ind = (d_['Z'] < zbins[i+1]) * (d_['Z'] >= zbins[i])\n",
    "        print '{:0.2f} < z <{:0.2f}'.format(zbins[i], zbins[i + 1])\n",
    "        sts =  ml_m.getStats(deltaz_keep[ind])\n",
    "        print 'median: {median:0.3f} sigma_68  {sigma_68:0.3f} , outfrac  {outlierFrac:0.3f}'.format(**sts)\n",
    "        \n",
    "plt.legend()\n",
    "plt.xlabel('ALH_z - ML_z')\n",
    "plt.ylabel('#')\n",
    "plt.xlim(-0.2,0.2)\n",
    "\n",
    "f = plt.figure()\n",
    "#now make pdf plots\n",
    "zbn = np.linspace(0,3,300)\n",
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "cnt=0\n",
    "for i in np.unique(d['Field']):\n",
    "    f = plt.figure()\n",
    "    ind = np.array(i == d['Field'])\n",
    "    #plt.plot(d['Z'][ind], d['zb_1'][ind], 'o', label='Region:{:} Number {:}'.format(str(i), np.sum(ind)))\n",
    "    d_ = d[ind]\n",
    "    true_z =  gss_kde(d_['zb_1']).evaluate(zbn) \n",
    "    pred_z = gss_kde(d_['Z']).evaluate(zbn) \n",
    "   \n",
    "    plt.plot(zbn, true_z,'-', color=col[cnt], label='Alh-z region:{:}'.format(str(i)))\n",
    "    plt.plot(zbn, pred_z,'--', color=col[cnt], label='ML-z region:{:}'.format(str(i)))\n",
    "    cnt +=1\n",
    "    plt.legend()\n",
    "    plt.xlabel('Redshift')\n",
    "    plt.ylabel('#')\n",
    "\n",
    "\n",
    "true_z =  gss_kde(truths).evaluate(zbn) \n",
    "pred_z = gss_kde(prediction).evaluate(zbn) \n",
    "f = plt.figure()\n",
    "plt.plot(zbn, true_z,'-', color=col[cnt], label='Alh-z COSMOS')\n",
    "plt.plot(zbn, pred_z,'--', color=col[cnt], label='ML-z COSMOS')\n",
    "cnt +=1\n",
    "plt.legend()\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now apply weights to alhambra data and see how the dndz looks for different fields, after weighting is applied.\n",
    "d1= Table.read('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.DESY1A1.fits')\n",
    "dn = Table.read('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.nonDESY1A1.fits')\n",
    "\n",
    "weight_f = ['F365W', 'dF365W', 'F396W', 'dF396W', 'F427W', 'dF427W', 'F458W', 'dF458W', 'F489W', 'dF489W', 'F520W', \n",
    "            'dF520W', 'F551W', 'dF551W', 'F582W', 'dF582W', 'F613W', 'dF613W', 'F644W', 'dF644W', 'F675W', 'dF675W', \n",
    "            'F706W', 'dF706W', 'F737W', 'dF737W', 'F768W', 'dF768W', 'F799W', 'dF799W', 'F830W', 'dF830W', 'F861W', \n",
    "            'dF861W', 'F892W', 'dF892W', 'F923W', 'dF923W', 'F954W', 'dF954W', 'J', 'dJ', 'H', 'dH', 'KS', 'dKS', \n",
    "            'F814W', 'dF814W']\n",
    "\n",
    "inpTrain, train_info = ml.dataSet(d1, weight_f, ['ID', 'zb_1']).loadData()\n",
    "inptestW, test_info = ml.dataSet(dn, weight_f, ['ID', 'Field', 'zb_1']).loadData()\n",
    "\n",
    "zbins = np.linspace(0, 1.6, num = 100)\n",
    "train_t_nw_z = gss_kde(np.array(train_info['zb_1'])).evaluate(zbins) \n",
    "\n",
    "\n",
    "n_neighbors_array = [5, 10, 20, 50]\n",
    "weights_alahmbra = {'features': weight_f, 'Field_weights': {}}\n",
    "\n",
    "for i in np.unique(test_info['Field']):\n",
    "    ind_test = test_info['Field'] == i\n",
    "    train_test = cw.best_lima_knn_weights(\n",
    "            inpTrain,\n",
    "            inptestW[ind_test],\n",
    "            verbose=1,\n",
    "            n_neighbors_array=n_neighbors_array\n",
    "        )\n",
    "    \n",
    "    weights_alahmbra['Field_weights'][i] = train_test\n",
    "    \n",
    "    train_t_z = gss_kde(np.array(train_info['zb_1']), weights=train_test).evaluate(zbins) \n",
    "    test_t_z = gss_kde(np.array(test_info['zb_1'][ind_test])).evaluate(zbins) \n",
    "    f = plt.figure()\n",
    "    plt.plot(zbins, train_t_nw_z, label='Train alh-z unweighted')\n",
    "    plt.plot(zbins, train_t_z, label='Train alh-z weighted')\n",
    "    plt.plot(zbins, test_t_z, label='Test alh-z')\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train a photo machine to make predictions using these weights\n",
    "alh_clf = {}\n",
    "for i in np.unique(test_info['Field']):\n",
    "    ind_test = test_info['Field'] == i\n",
    "    train_test = weights_alahmbra['Field_weights'][i]\n",
    "    \n",
    "    results, score = k_fold_val(inpTrain, train_info['zb_1'], train_test, 10, 30)\n",
    "    alh_clf[i] = {}\n",
    "    alh_clf[i]['clf'] = results['clf']\n",
    "    alh_clf[i]['results'] = results\n",
    "    alh_clf[i]['predict_test'] = results['clf'].predict(inptestW[ind_test])\n",
    "    alh_clf[i]['truth_test'] = test_info['zb_1'][ind_test]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def zarr_from_ml(z_, sigma_, weights_):\n",
    "    weights1 = normalise(weights_)\n",
    "    ind = np.random.choice(np.arange(len(z_), dtype=int), size=np.ceil(1.0/np.sum(weights1**2)), p=weights1, replace=True)\n",
    "    zrr = z_[ind] + np.random.normal(size=len(ind)) * sigma_[ind]\n",
    "    cnt =0\n",
    "    while np.sum(zrr<0) > 0:\n",
    "        ind1 = zrr <0\n",
    "        zrr[ind1] = z_[ind][ind1]+ np.random.normal(size=np.sum(ind1)) * sigma_[ind][ind1]\n",
    "    return zrr\n",
    "\n",
    "def wl_val_test(x1,x2):\n",
    "    #if np.abs(x1-x2)<0.02:\n",
    "    #    return True\n",
    "    return np.abs(x1-x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tom_zbins = [0, 0.3, 0.5 , 0.7, 0.9, 1.1, 1.3]\n",
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "for i in np.unique(test_info['Field']):\n",
    "    print 'prediction for field ',i\n",
    "    ind_test = test_info['Field'] == i\n",
    "    sigma, z_mc = allPredictions(alh_clf[i]['clf'], inptestW[ind_test])\n",
    "    \n",
    "    f = plt.figure()\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (alh_clf[i]['predict_test'] <= tom_zbins[j+1]) * (alh_clf[i]['predict_test'] > tom_zbins[j])\n",
    "        z_txt= '{:0.2f}<z<{:0.2f}'.format(tom_zbins[j], tom_zbins[j+1])\n",
    "        print z_txt\n",
    "        pz_ = alh_clf[i]['predict_test'][ind] + np.random.normal(size=np.sum(ind))*sigma[ind]\n",
    "        wlres =  wl_val_test(np.mean(alh_clf[i]['truth_test'][ind]), np.mean(pz_))\n",
    "        print wlres\n",
    "      \n",
    "        \n",
    "        #pz_ = z_mc[ind] \n",
    "        train_t_z = gss_kde(pz_).evaluate(zbins) \n",
    "        test_t_z = gss_kde(alh_clf[i]['truth_test'][ind]).evaluate(zbins) \n",
    "    \n",
    "        plt.plot(zbins, train_t_z, '--',color=col[j], alpha=0.8, linewidth=3, label='ML-z: {:0.2f} '.format(wlres) )\n",
    "        plt.plot(zbins, test_t_z, '-',color=col[j], alpha=0.8, linewidth=3,label='Alh-z: '+ z_txt)\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Field {:}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tom_zbins = [0, 1.3]\n",
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "for i in np.unique(test_info['Field']):\n",
    "    print 'prediction for field ',i\n",
    "    ind_test = test_info['Field'] == i\n",
    "    sigma, z_mc = allPredictions(alh_clf[i]['clf'], inptestW[ind_test])\n",
    "    \n",
    "    \n",
    "    f = plt.figure()\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (alh_clf[i]['predict_test'] <= tom_zbins[j+1]) * (alh_clf[i]['predict_test'] > tom_zbins[j])\n",
    "        z_txt= '{:0.2f}<z<{:0.2f}'.format(tom_zbins[j], tom_zbins[j+1])\n",
    "        print z_txt\n",
    "        wlres =  wl_val_test(np.mean(alh_clf[i]['truth_test'][ind]), np.mean(alh_clf[i]['predict_test'][ind]))\n",
    "        print wlres\n",
    "      \n",
    "        pz_ = alh_clf[i]['predict_test'][ind]# + np.random.normal(size=np.sum(ind))*sigma[ind]\n",
    "        pz_ = z_mc[ind] \n",
    "        train_t_z = gss_kde(pz_).evaluate(zbins) \n",
    "        test_t_z = gss_kde(alh_clf[i]['truth_test'][ind]).evaluate(zbins) \n",
    "    \n",
    "        plt.plot(zbins, train_t_z, '--',color=col[j], alpha=0.8, linewidth=3, label='ML-z: {:0.2f} '.format(wlres))\n",
    "        plt.plot(zbins, test_t_z, '-',color=col[j], alpha=0.8, linewidth=3,label='Alh-z: ' + z_txt)\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Field {:}'.format(i))\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ignore weighting and calcualte metrics\n",
    "res = p.load(open('/Users/hoyleb/DATA/ALHAMBRA/photoz.DesY1A1.xv100.p', 'r'))\n",
    "inptestW_, test_info_ = ml.dataSet(dn, res['features']['input'], ['ID', 'Field', 'zb_1']).loadData()\n",
    "pz_ = res['clf'].predict(inptestW_)\n",
    "sigma, z_mc = allPredictions(res['clf'], inptestW_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tom_zbins = [0, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n",
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "for i in np.unique(test_info_['Field']):\n",
    "    print 'prediction for field ',i\n",
    "    ind_test = test_info['Field'] == i\n",
    "    \n",
    "    f = plt.figure()\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (pz_[ind_test] <= tom_zbins[j+1]) * (pz_[ind_test] > tom_zbins[j])\n",
    "        z_txt= '{:0.2f}<z<{:0.2f}'.format(tom_zbins[j], tom_zbins[j+1])\n",
    "        print z_txt\n",
    "        wlres =  wl_val_test(np.mean(test_info_['zb_1'][ind_test][ind]), np.mean(pz_[ind_test][ind]))\n",
    "        print wlres\n",
    "      \n",
    "        pz = pz_[ind_test][ind] #+ np.random.normal(size=np.sum(ind))*sigma[ind_test][ind]\n",
    "        pz_ = z_mc[ind] \n",
    "        train_t_z = gss_kde(pz).evaluate(zbins) \n",
    "        test_t_z = gss_kde(test_info_['zb_1'][ind_test][ind]).evaluate(zbins) \n",
    "        \n",
    "        plt.plot(zbins, train_t_z, '--',color=col[j], alpha=0.8, linewidth=3, label='ML-z: {:0.2f} '.format(wlres) + z_txt)\n",
    "        plt.plot(zbins, test_t_z, '-',color=col[j], alpha=0.8, linewidth=3,label='Alh-z: ' + z_txt)\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Field {:}'.format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Train on mutli-fields DES pseudo photometry</h3>\n",
    "\n",
    "make predictions on some held out fields, and also field 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = Table.read('/Users/hoyleb/DATA/ALHAMBRA/alhambra_survey_photoZ_catalogue_2013.fits.pseudoDesMags.fits')\n",
    "print len(d)\n",
    "d = d[d['Stellar_Flag'] < 0.7]\n",
    "d = d[d['F814W'] < 24]\n",
    "print len(d)\n",
    "\n",
    "d2 = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/merged.Y1A1_GOLD_1_0_3_000001.fits_alhambra.fits')\n",
    "print len(d2)\n",
    "d2 = d2[d2['Stellar_Flag'] < 0.7]\n",
    "d2 = d2[d2['F814W'] < 24]\n",
    "print len(d2)\n",
    "\n",
    "feats_des = ['MAG_AUTO_G','MAG_AUTO_R','MAG_AUTO_I','MAG_AUTO_Z','MAG_AUTO_G-MAG_AUTO_R','MAG_AUTO_G-MAG_AUTO_I',\n",
    "               'MAG_AUTO_G-MAG_AUTO_Z','MAG_AUTO_R-MAG_AUTO_I','MAG_AUTO_R-MAG_AUTO_Z','MAG_AUTO_I-MAG_AUTO_Z']\n",
    "\n",
    "inpTrain, train_info = ml.dataSet(d, feats_des, ['ID', 'zb_1', 'Field']).loadData()\n",
    "\n",
    "inpTest, test_info = ml.dataSet(d2, feats_des, ['ID', 'zb_1', 'Field']).loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = np.unique(d['Field'])\n",
    "fields = [i for i in fields if i != 4]\n",
    "print fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psudo_des = {}\n",
    "for i1, fld in enumerate(fields):\n",
    "    ind_train = np.zeros(len(d), dtype=bool)\n",
    "    train_fields = [i for i in fields if i != fld]\n",
    "    for fld1 in train_fields:\n",
    "        ind_train += d['Field']==fld1\n",
    "    print 'train_fields', np.unique(d['Field'][ind_train])\n",
    "    ind_train = np.arange(len(d))[ind_train]\n",
    "    np.random.shuffle(ind_train)\n",
    "    \n",
    "    test_fields = [fld, 4]\n",
    "    ind_test = np.zeros(len(d), dtype=bool)\n",
    "    for fld1 in test_fields:\n",
    "        ind_test += d['Field']==fld1\n",
    "    print 'test fields', np.unique(d['Field'][ind_test])\n",
    "    \n",
    "    train_weights = np.ones(len(ind_train), dtype=float)\n",
    "    train_weights = train_weights / np.sum(train_weights)\n",
    "    \n",
    "    results, score = k_fold_val(inpTrain[ind_train], train_info['zb_1'][ind_train], train_weights, 10, 30)\n",
    "    print score\n",
    "    psudo_des[fld] = {}\n",
    "    psudo_des[fld]['clf'] = results['clf']\n",
    "    psudo_des[fld]['results'] = results\n",
    "    psudo_des[fld]['predict_test'] = results['clf'].predict(inpTrain[ind_test])\n",
    "    psudo_des[fld]['test_ID'] = train_info['ID'][ind_test]\n",
    "    psudo_des[fld]['test_Field'] = train_info['Field'][ind_test]\n",
    "    psudo_des[fld]['truth_test'] = train_info['zb_1'][ind_test]\n",
    "    psudo_des[fld]['predict_test_desphot'] = results['clf'].predict(inpTest)\n",
    "    psudo_des[fld]['truth_test_des_phot'] = test_info['zb_1']\n",
    "    psudo_des[fld]['test_ID_des_phot'] = test_info['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cosmos = '/Users/hoyleb/DATA/DES/PHOTOZ/Y1A1_GOLD_1_0_3_COSMOS2015_matched.cleanmags.fits'\n",
    "feats_des = ['MAG_AUTO_G','MAG_AUTO_R','MAG_AUTO_I','MAG_AUTO_Z','MAG_AUTO_G-MAG_AUTO_R','MAG_AUTO_G-MAG_AUTO_I',\n",
    "               'MAG_AUTO_G-MAG_AUTO_Z','MAG_AUTO_R-MAG_AUTO_I','MAG_AUTO_R-MAG_AUTO_Z','MAG_AUTO_I-MAG_AUTO_Z']\n",
    "\n",
    "inpCos, Cos_info = ml.dataSet(cosmos, feats_des, ['ZMINCHI2', 'COADD_OBJECTS_ID']).loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psudo_des = pickle.load(open('/Users/hoyleb/DATA/ALHAMBRA/pseudo.des.mags.train5fields.test2.p', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "tom_zbins = [0, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n",
    "zbins = np.linspace(0, 2, num=200)\n",
    "\n",
    "for fld in psudo_des.keys():\n",
    "    print 'for field', fld   , '& 4' \n",
    "    \n",
    "    z_ml_ps = psudo_des[fld]['predict_test']\n",
    "    z_truth_ps = psudo_des[fld]['truth_test']\n",
    "    \n",
    "    \n",
    "    z_ml = psudo_des[fld]['predict_test_desphot']\n",
    "    z_truth = psudo_des[fld]['truth_test_des_phot']\n",
    "    \n",
    "    z_cosmo = psudo_des[fld]['clf'].predict(inpCos)\n",
    "    z_cosmo_truth = Cos_info['ZMINCHI2']\n",
    "    \n",
    "    f = plt.figure()\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml_ps <= tom_zbins[j+1]) * (z_ml_ps > tom_zbins[j])\n",
    "        z_txt= '{:0.2f}<z<{:0.2f}'.format(tom_zbins[j], tom_zbins[j+1])\n",
    "        print z_txt\n",
    "        wlres =  wl_val_test(np.mean(z_truth_ps[ind]), np.mean(z_ml_ps[ind]))\n",
    "        print wlres\n",
    "      \n",
    "        pz_ = z_ml_ps[ind]# + np.random.normal(size=np.sum(ind))*sigma[ind]\n",
    "        train_t_z = gss_kde(pz_).evaluate(zbins) \n",
    "        test_t_z = gss_kde(z_truth_ps[ind]).evaluate(zbins) \n",
    "    \n",
    "        plt.plot(zbins, train_t_z, '--',color=col[j], alpha=0.8, linewidth=3, label='ML-z: {:0.2f} '.format(wlres))\n",
    "        plt.plot(zbins, test_t_z, '-',color=col[j], alpha=0.8, linewidth=3,label='Alh-z: ' + z_txt)\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Field 4&{:} pseudo mags'.format(fld))\n",
    "    \n",
    "   \n",
    "    f = plt.figure()\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml <= tom_zbins[j+1]) * (z_ml > tom_zbins[j])\n",
    "        z_txt= '{:0.2f}<z<{:0.2f}'.format(tom_zbins[j], tom_zbins[j+1])\n",
    "        print z_txt\n",
    "        wlres =  wl_val_test(np.mean(z_truth[ind]), np.mean(z_ml[ind]))\n",
    "        print wlres\n",
    "      \n",
    "        pz_ = z_ml[ind]# + np.random.normal(size=np.sum(ind))*sigma[ind]\n",
    "        train_t_z = gss_kde(pz_).evaluate(zbins) \n",
    "        test_t_z = gss_kde(z_truth[ind]).evaluate(zbins) \n",
    "    \n",
    "        plt.plot(zbins, train_t_z, '--',color=col[j], alpha=0.8, linewidth=3, label='ML-z: {:0.2f} '.format(wlres))\n",
    "        plt.plot(zbins, test_t_z, '-',color=col[j], alpha=0.8, linewidth=3,label='Alh-z: ' + z_txt)\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Field 4 real mags')\n",
    "    \n",
    "       \n",
    "    f = plt.figure()\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_cosmo <= tom_zbins[j+1]) * (z_cosmo > tom_zbins[j])\n",
    "        z_txt= '{:0.2f}<z<{:0.2f}'.format(tom_zbins[j], tom_zbins[j+1])\n",
    "        print z_txt\n",
    "        wlres =  wl_val_test(np.mean(z_cosmo_truth[ind]), np.mean(z_cosmo[ind]))\n",
    "        print wlres\n",
    "      \n",
    "        pz_ = z_cosmo[ind]# + np.random.normal(size=np.sum(ind))*sigma[ind]\n",
    "        train_t_z = gss_kde(pz_).evaluate(zbins) \n",
    "        test_t_z = gss_kde(z_cosmo_truth[ind]).evaluate(zbins) \n",
    "    \n",
    "        plt.plot(zbins, train_t_z, '--',color=col[j], alpha=0.8, linewidth=3, label='ML-z: {:0.2f} '.format(wlres))\n",
    "        plt.plot(zbins, test_t_z, '-',color=col[j], alpha=0.8, linewidth=3,label='Alh-z: ' + z_txt)\n",
    "    plt.legend()\n",
    "    plt.xlabel('redshift')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Cosmos photo-z real mags excl. {:}&4'.format(fld))\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "tom_zbins = [0, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n",
    "zbins = np.linspace(0, 2, num=200)\n",
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_ml_ps = psudo_des[fld]['predict_test']\n",
    "    z_truth_ps = psudo_des[fld]['truth_test']\n",
    "\n",
    "    wlresArr = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml_ps <= tom_zbins[j+1]) * (z_ml_ps > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_truth_ps[ind]), np.mean(z_ml_ps[ind]))\n",
    "        #print wlres\n",
    "        if wlres is True:\n",
    "            wlres = 0.01\n",
    "        wlresArr.append(wlres)\n",
    "        z_meanArr.append(z_mean)\n",
    "        \n",
    "    plt.plot(z_meanArr, wlresArr, '--',color=col[i], alpha=0.8, linewidth=3, label='Test Field 4&{:}'.format(fld))\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('WL: |<z>-<z_ml>|')\n",
    "plt.title('Pseudo mags')\n",
    "plt.ylim(0,0.08)\n",
    "\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_ml_ps = psudo_des[fld]['predict_test']\n",
    "    z_truth_ps = psudo_des[fld]['truth_test']\n",
    "    mu = []\n",
    "    sig = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml_ps <= tom_zbins[j+1]) * (z_ml_ps > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_truth_ps[ind]), np.mean(z_ml_ps[ind]))\n",
    "        deltaz_keep =  ml_m.DeltaZ(z_truth_ps[ind], z_ml_ps[ind])\n",
    "        stats = ml_m.getStats(deltaz_keep)\n",
    "        z_meanArr.append(z_mean)\n",
    "        mu.append(stats['median'])\n",
    "        sig.append(stats['sigma_68'])\n",
    "    z_meanArr = np.array(z_meanArr) + i*0.01 - 0.02\n",
    "    sig = np.array(sig)*0.1\n",
    "    plt.errorbar(z_meanArr, mu, yerr=sig, fmt='o',color=col[i], alpha=0.8, label='Test Field 4&{:}'.format(fld))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('mu, sigma68*0.1')\n",
    "plt.title('Pseudo mags')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = ['red', 'blue', 'green', 'purple', 'grey', 'orange','red']\n",
    "tom_zbins = [0, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n",
    "zbins = np.linspace(0, 2, num=200)\n",
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_ml_ps = psudo_des[fld]['predict_test'][psudo_des[fld]['test_Field']==4]\n",
    "    z_truth_ps = psudo_des[fld]['truth_test'][psudo_des[fld]['test_Field']==4]\n",
    "\n",
    "    wlresArr = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml_ps <= tom_zbins[j+1]) * (z_ml_ps > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_truth_ps[ind]), np.mean(z_ml_ps[ind]))\n",
    "        #print wlres\n",
    "        if wlres is True:\n",
    "            wlres = 0.01\n",
    "        wlresArr.append(wlres)\n",
    "        z_meanArr.append(z_mean)\n",
    "        \n",
    "    plt.plot(z_meanArr, wlresArr, '--',color=col[i], alpha=0.8, linewidth=3, label='Excl. train 4&{:}'.format(fld))\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('WL: |<z>-<z_ml>|')\n",
    "plt.title('Pseudo mags Field 4')\n",
    "plt.ylim(0,0.08)\n",
    "\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_ml_ps = psudo_des[fld]['predict_test'][psudo_des[fld]['test_Field']==4]\n",
    "    z_truth_ps = psudo_des[fld]['truth_test'][psudo_des[fld]['test_Field']==4]\n",
    "    mu = []\n",
    "    sig = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml_ps <= tom_zbins[j+1]) * (z_ml_ps > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_truth_ps[ind]), np.mean(z_ml_ps[ind]))\n",
    "        deltaz_keep =  ml_m.DeltaZ(z_truth_ps[ind], z_ml_ps[ind])\n",
    "        stats = ml_m.getStats(deltaz_keep)\n",
    "        z_meanArr.append(z_mean)\n",
    "        mu.append(stats['median'])\n",
    "        sig.append(stats['sigma_68'])\n",
    "    z_meanArr = np.array(z_meanArr) + i*0.01 - 0.02\n",
    "    sig = np.array(sig)*0.1\n",
    "    plt.errorbar(z_meanArr, mu, yerr=sig, fmt='o',color=col[i], alpha=0.8, label='Excl. train 4&{:}'.format(fld))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('mu, sigma68*0.1')\n",
    "plt.title('Pseudo mags Field 4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "    z_ml = psudo_des[fld]['predict_test_desphot']\n",
    "    z_truth = psudo_des[fld]['truth_test_des_phot']\n",
    "\n",
    "    wlresArr = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml <= tom_zbins[j+1]) * (z_ml > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_truth[ind]), np.mean(z_ml[ind]))\n",
    "        #print wlres\n",
    "        if wlres is True:\n",
    "            wlres = 0.01\n",
    "        wlresArr.append(wlres)\n",
    "        z_meanArr.append(z_mean)\n",
    "        \n",
    "    plt.plot(z_meanArr, wlresArr, '--',color=col[i], alpha=0.8, linewidth=3, label='Excl. train 4&{:}'.format(fld))\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('WL: |<z>-<z_ml>|')\n",
    "plt.title('DES mags field 4')\n",
    "plt.ylim(0,0.15)\n",
    "\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_ml = psudo_des[fld]['predict_test_desphot']\n",
    "    z_truth = psudo_des[fld]['truth_test_des_phot']\n",
    "\n",
    "    mu = []\n",
    "    sig = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_ml <= tom_zbins[j+1]) * (z_ml > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_truth[ind]), np.mean(z_ml[ind]))\n",
    "        deltaz_keep =  ml_m.DeltaZ(z_truth[ind], z_ml[ind])\n",
    "        stats = ml_m.getStats(deltaz_keep)\n",
    "        z_meanArr.append(z_mean)\n",
    "        mu.append(stats['median'])\n",
    "        sig.append(stats['sigma_68'])\n",
    "    z_meanArr = np.array(z_meanArr) + i*0.01 - 0.02\n",
    "    sig = np.array(sig)*0.1\n",
    "    plt.errorbar(z_meanArr, mu, yerr=sig, fmt='o',color=col[i], alpha=0.8, label='Excl. train 4&{:}'.format(fld))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('mu, sigma68*0.1')\n",
    "plt.title('Real DES mags field 4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_cosmo = psudo_des[fld]['clf'].predict(inpCos)\n",
    "    z_cosmo_truth = Cos_info['ZMINCHI2']\n",
    "    \n",
    "    wlresArr = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_cosmo <= tom_zbins[j+1]) * (z_cosmo > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_cosmo_truth[ind]), np.mean(z_cosmo[ind]))\n",
    "        #print wlres\n",
    "        if wlres is True:\n",
    "            wlres = 0.01\n",
    "        wlresArr.append(wlres)\n",
    "        z_meanArr.append(z_mean)\n",
    "        \n",
    "    plt.plot(z_meanArr, wlresArr, '--',color=col[i], alpha=0.8, linewidth=3, label='Excl. train 4&{:}'.format(fld))\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('WL: |<z>-<z_ml>|')\n",
    "plt.title('DES mags Cosmos')\n",
    "plt.ylim(0,0.15)\n",
    "\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "for i, fld in enumerate(psudo_des.keys()):\n",
    "\n",
    "    z_cosmo = psudo_des[fld]['clf'].predict(inpCos)\n",
    "    z_cosmo_truth = Cos_info['ZMINCHI2']\n",
    "\n",
    "    mu = []\n",
    "    sig = []\n",
    "    z_meanArr = []\n",
    "    for j in range(len(tom_zbins)-1):\n",
    "        ind = (z_cosmo_truth <= tom_zbins[j+1]) * (z_cosmo > tom_zbins[j])\n",
    "        z_mean = (tom_zbins[j] +  tom_zbins[j+1]) / 2.0\n",
    "        wlres =  wl_val_test(np.mean(z_cosmo_truth[ind]), np.mean(z_cosmo[ind]))\n",
    "        deltaz_keep =  ml_m.DeltaZ(z_cosmo_truth[ind], z_cosmo[ind])\n",
    "        stats = ml_m.getStats(deltaz_keep)\n",
    "        z_meanArr.append(z_mean)\n",
    "        mu.append(stats['median'])\n",
    "        sig.append(stats['sigma_68'])\n",
    "    z_meanArr = np.array(z_meanArr) + i*0.01 - 0.02\n",
    "    sig = np.array(sig)*0.1\n",
    "    plt.errorbar(z_meanArr, mu, yerr=sig, fmt='o',color=col[i], alpha=0.8, label='Excl. train 4&{:}'.format(fld))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('mu, sigma68*0.1')\n",
    "plt.title('Real DES mags Cosmos')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make ALPHAMBA DES file for BPZ\n",
    "d = Table.read('/Users/hoyleb/DATA/ALHAMBRA/ALHAMBRA_IN_DES.BPZ.Yv103.csv.fits')\n",
    "d = d[d['MAG_AUTO_I']<23.5]\n",
    "d = d[d['MAG_AUTO_I']>14]\n",
    "d = d[d['MAGERR_AUTO_I']<0.5]\n",
    "d = d[d['MAG_AUTO_G']<30]\n",
    "d = d[d['MAG_AUTO_I']<30]\n",
    "d = d[d['MAG_AUTO_R']<30]\n",
    "d = d[d['MAG_AUTO_Z']<30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f= open('/Users/hoyleb/Documents/third_party/BPZ/alhambra/y1a1_final_spec_valid.cat','w')\n",
    "f.write('# COADD_OBJECTS_ID\\tMAG_AUTO_G\\tMAG_AUTO_R\\tMAG_AUTO_I\\tMAG_AUTO_Z\\tMAGERR_AUTO_G\\tMAGERR_AUTO_R\\tMAGERR_AUTO_I\\tMAGERR_AUTO_Z\\tZ\\n')\n",
    "\n",
    "keys=['COADD_OBJECTS_ID','MAG_AUTO_G','MAG_AUTO_R','MAG_AUTO_I','MAG_AUTO_Z','MAGERR_AUTO_G',\n",
    "      'MAGERR_AUTO_R','MAGERR_AUTO_I','MAGERR_AUTO_Z','ZB_1']\n",
    "\n",
    "for i in range(len(d)):\n",
    "    dic = {}\n",
    "    for j in keys:\n",
    "        dic[j] = d[j][i]\n",
    "    if np.isfinite(d['MAG_AUTO_R'][i]):\n",
    "        f.write('{COADD_OBJECTS_ID}\\t{MAG_AUTO_G:0.6}\\t{MAG_AUTO_R:0.6}\\t{MAG_AUTO_I:0.6}\\t{MAG_AUTO_Z:0.6}\\t{MAGERR_AUTO_G:0.6}\\t{MAGERR_AUTO_R:0.6}\\t{MAGERR_AUTO_I:0.6}\\t{MAGERR_AUTO_Z:0.6}\\t{ZB_1}\\n'.format(**dic))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = np.genfromtext('/Users/hoyleb/Documents/third_party/BPZ/alhambra/y1a1_final_spec_valid.bpz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Test alhambra photometry is similar to DES Y1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['MAG_AUTO_I', 'MAG_AUTO_G','MAG_AUTO_R', 'MAG_AUTO_Z', 'MAG_AUTO_G-MAG_AUTO_R', \n",
    "            'MAG_AUTO_R-MAG_AUTO_I', 'MAG_AUTO_Z-MAG_AUTO_I', \n",
    "            'MAG_AUTO_Z-MAG_AUTO_G', 'MAGERR_AUTO_I']\n",
    "outF = ['COADD_OBJECTS_ID','MAG_AUTO_I', 'MAG_AUTO_G','MAG_AUTO_R', \n",
    "                                                      'MAG_AUTO_Z', 'MAGERR_AUTO_I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "inputs_alh, info_alh = ml.dataSet('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103/ALHCOSVALIDATIONID.BPZ.WLflags.Y1v103.fits', \n",
    "                                           features, outF).loadData()\n",
    "ind = (info_alh['MAG_AUTO_I']<23.5)*(info_alh['MAG_AUTO_I']>17) *(info_alh['MAGERR_AUTO_I']<0.3)*(info_alh['MAGERR_AUTO_I']>0)*(info_alh['MAG_AUTO_G']<30)*(info_alh['MAG_AUTO_G']>15)*(info_alh['MAG_AUTO_R']<30)*(info_alh['MAG_AUTO_R']>15)*(info_alh['MAG_AUTO_I']<30)*(info_alh['MAG_AUTO_I']>15)*(info_alh['MAG_AUTO_Z']<30)*(info_alh['MAG_AUTO_Z']>15)\n",
    "inputs_alh = inputs_alh[ind]\n",
    "\n",
    "ind = np.ones(len(inputs_alh), dtype=bool)\n",
    "#for i in np.arange(len(inputs_alh[0])-4)+4:\n",
    "#    ind *= (inputs_alh[:, i]>-6) * (inputs_alh[:, i]<2)\n",
    "#inputs_alh = inputs_alh[ind]\n",
    "\n",
    "inputs_y1, info_y1 = ml.dataSet('/Users/hoyleb/DATA/DES/PHOTOZ/WL_INFO_0_1M_ID.Y1A1_GOLD_1_0_3.nside128.fits', \n",
    "                                           features,outF + ['RA']).loadData()\n",
    "ind = (info_y1['MAG_AUTO_I']<23.5)*(info_y1['MAG_AUTO_I']>17) *(info_y1['MAGERR_AUTO_I']<0.3)*(\n",
    "    info_y1['MAGERR_AUTO_I']>0)*(info_y1['MAG_AUTO_G']<30)*(info_y1['MAG_AUTO_G']>15)*(info_y1['MAG_AUTO_R']<30)*(\n",
    "    info_y1['MAG_AUTO_R']>15)*(info_y1['MAG_AUTO_I']<30)*(info_y1['MAG_AUTO_I']>15)*(\n",
    "    info_y1['MAG_AUTO_Z']<30)*(info_y1['MAG_AUTO_Z']>15)*(info_y1['RA']>45)\n",
    "inputs_y1 = inputs_y1[ind]\n",
    "\n",
    "inputs_sn1, info_sn1 = ml.dataSet('/Users/hoyleb/DATA/DES/PHOTOZ/Sne0.5Deg.fits', \n",
    "                                           features,outF).loadData()\n",
    "ind = (info_sn1['MAG_AUTO_I']<23.5)*(info_sn1['MAG_AUTO_I']>17) *(info_sn1['MAGERR_AUTO_I']<0.3)*(\n",
    "    info_sn1['MAGERR_AUTO_I']>0)*(info_sn1['MAG_AUTO_G']<30)*(info_sn1['MAG_AUTO_G']>15)*(info_sn1['MAG_AUTO_R']<30)*(\n",
    "    info_sn1['MAG_AUTO_R']>15)*(info_sn1['MAG_AUTO_I']<30)*(info_sn1['MAG_AUTO_I']>15)*(\n",
    "    info_sn1['MAG_AUTO_Z']<30)*(info_sn1['MAG_AUTO_Z']>15)\n",
    "inputs_sn1 = inputs_sn1[ind]\n",
    "\n",
    "ind = np.ones(len(inputs_y1), dtype=bool)\n",
    "#for i in np.arange(len(inputs_y1[0])-4)+4:\n",
    "#    ind *= (inputs_y1[:, i]>-6) * (inputs_y1[:, i]<2)\n",
    "#inputs_y1 = inputs_y1[ind]\n",
    "\n",
    "ind1 = np.arange(len(inputs_y1))\n",
    "np.random.shuffle(ind1)\n",
    "ind1 = ind1[0: len(inputs_alh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "for i in range(len(features)):\n",
    "    print features[i], stats.ks_2samp(inputs_y1[ind1, i], inputs_alh[:, i])\n",
    "    f = plt.figure()\n",
    "    \n",
    "    _ = plt.hist(inputs_alh[:, i], bins=100, label='Cosmos[Alh] footprint', normed=True, alpha=0.5)\n",
    "    _ = plt.hist(inputs_y1[ind1, i], bins=100, label='WL objects', normed=True, alpha=0.5)\n",
    "    _ = plt.hist(inputs_sn1[:, i], bins=100, label='SNe 0.5deg', normed=True, alpha=0.5)\n",
    "    plt.xlabel(features[i])\n",
    "    plt.legend()\n",
    "    plt.xlim(14,30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(inputs_alh[:, 0], inputs_alh[:, -1],',', label='Cosmos[Alh] footprint', alpha=1)\n",
    "plt.plot(inputs_y1[:, 0],inputs_y1[:, -1], ',', label='WL galaxies', alpha=1)\n",
    "plt.plot(inputs_sn1[:, 0],inputs_sn1[:, -1], ',', label='Sne 0.5deg', alpha=1)\n",
    "\n",
    "plt.xlabel(features[0])\n",
    "plt.ylabel(features[-1])\n",
    "plt.legend(loc=2)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
