{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from weighted_kde import gaussian_kde as gss_kde\n",
    "from astropy.table import vstack\n",
    "from bh_parallelise import Parrallelise\n",
    "import sys \n",
    "import time\n",
    "import cPickle as pickle\n",
    "import sml_mla as ml\n",
    "import ml_metrics as ml_m\n",
    "import ml_params as mlp\n",
    "import math\n",
    "from astropy.table import Table, vstack\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import calculate_weights as cw\n",
    "import kmeansClusters as km\n",
    "import anomaly_detection as ad\n",
    "import augment_data as augd\n",
    "reload(augd)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import copy \n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.metrics import r2_score\n",
    "import glob\n",
    "almost_black = '#262626'\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams.update({'font.size': 32, \n",
    "                     'axes.linewidth': 5,\n",
    "                    'text.color': almost_black,\n",
    "                    'xtick.major.size': 4,\n",
    "                    'ytick.major.size': 4,\n",
    "                    'legend.fancybox': True,\n",
    "                    'figure.dpi': 300,\n",
    "                    'legend.fontsize': 14,\n",
    "                    'legend.framealpha': 0.8,\n",
    "                    'legend.shadow': True,\n",
    "                    'xtick.labelsize': 32,\n",
    "                    'ytick.labelsize': 32})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics_z1_z2': ['bh_photo_z_validation.wl_metric'], 'truths': 'REDSHIFT', 'predictions': ['MEAN_Z', 'Z_MC'], 'weights': None, 'error_function': None, 'metrics_diffz': ['numpy.median', 'bh_photo_z_validation.sigma_68', 'bh_photo_z_validation.outlier_fraction', 'bh_photo_z_validation.outFrac_2sigma68', 'bh_photo_z_validation.outFrac_3sigma68'], 'tolerance': None, 'bins': [{'MEAN_Z': '[0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]'}]}\n"
     ]
    }
   ],
   "source": [
    "tst = '/Users/hoyleb/Documents/python/modules/photoz-wg/validation/testConfig/photoz.yaml'\n",
    "import yaml\n",
    "\n",
    "test = yaml.load(open(tst, 'r'))\n",
    "test = test['point']\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preds_to_pdf_mc(pred_, zbins_):\n",
    "    pdfs = np.zeros((len(pred_), len(zbins_)), dtype=float)\n",
    "    z_mc = np.zeros(len(pred_), dtype=float)\n",
    "    for i in np.arange(len(pred_)):\n",
    "        kds = gaussian_kde(pred_[i])\n",
    "        pdfs[i] = kds.evaluate(zbins_)\n",
    "\n",
    "        z_ = kds.resample(size=1)\n",
    "        cnt = 0\n",
    "        while z_ < 0 and cnt < 4:\n",
    "            z_ = kds.resample(size=1)\n",
    "            cnt += 1\n",
    "        if cnt == 4:\n",
    "            z_ = -1\n",
    "        z_mc[i] = z_\n",
    "\n",
    "    return pdfs, z_mc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many machines to train\n",
    "Nmachines = 50\n",
    "\n",
    "#some functions to generate a machine and to test performance\n",
    "def rand_machine():\n",
    "    \n",
    "    #clf = RandomForestRegressor()\n",
    "    clf = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "    curr_params = clf.get_params()\n",
    "    params = mlp.getRandomParams()\n",
    "    params['n_estimators'] = np.random.randint(60, 250)\n",
    "    params['n_jobs'] = 5 \n",
    "    params['max_features'] = 'auto'#np.random.choice(['auto', 'sqrt', 'log2', None], size=1) \n",
    "    params['oob_score'] = True\n",
    "    curr_params = ml.combineParameters(curr_params, params)\n",
    "    curr_params = ml.tree_loss(curr_params, clf)\n",
    "    clf.set_params(**curr_params)\n",
    "    return clf\n",
    "\n",
    "\n",
    "# parralelisation function\n",
    "# beware some global variables like score_metric is in here\n",
    "def xvFitPredict(_):\n",
    "    _clf, inputs, outputs, _indho, metric = _\n",
    "    # train on non held out\n",
    "    _intr = np.setdiff1d(np.arange(len(inputs)), _indho, assume_unique=True)\n",
    "\n",
    "    inp_ = copy.deepcopy(inputs[_intr])\n",
    "    outp_ = copy.deepcopy(outputs[_intr])\n",
    "    \n",
    "    _clf.fit(inp_, outp_)\n",
    "\n",
    "    dictXv = {}\n",
    "    # calculate stats on held out fraction\n",
    "    dictXv['predict'] = _clf.predict(inputs[_indho])\n",
    "\n",
    "    pdf = allPredictions(_clf, inputs[_indho])\n",
    "    \n",
    "    dictXv['sigma'] = np.std(pdf, axis=1)\n",
    "    \n",
    "    # calcaulate score\n",
    "    dictXv['scoreXv'] = metric(outputs[_indho], dictXv['predict'], pdf)\n",
    "    dictXv['outputs'] = outputs[_indho]\n",
    "    dictXv['index'] = _indho\n",
    "    return dictXv\n",
    "\n",
    "\n",
    "#kde_augment or kde_knn_augment\n",
    "def k_fold_val(inputs, outputs, Nfolds, Niterations, metric):\n",
    "      \n",
    "    indHo = np.array_split(np.arange(len(inputs)), Nfolds)\n",
    "    results = {}\n",
    "    score_best = 100\n",
    "    for i in range(Niterations):\n",
    "        \n",
    "        clf = rand_machine()\n",
    "        resXv = {}\n",
    "    \n",
    "        arrp = []\n",
    "        for j in range(len(indHo)):\n",
    "            arrp.append([clf, inputs, outputs, indHo[j], metric])\n",
    "        \n",
    "        res1 = Parrallelise(n_jobs=2, method=xvFitPredict, loop=arrp).run()\n",
    "\n",
    "        for j in range(len(indHo)):\n",
    "            resXv[j] = res1[j]\n",
    "            \n",
    "        scoreXv = np.zeros(Nfolds).astype(float)\n",
    "        predict = np.zeros(len(inputs), dtype=float)\n",
    "        sigma = np.zeros(len(inputs), dtype=float)\n",
    "        for k in resXv:\n",
    "            scoreXv[k] = resXv[k]['scoreXv']\n",
    "            predict[indHo[k]] = resXv[k]['predict']\n",
    "            \n",
    "        score = np.mean(scoreXv)\n",
    "        print score, np.std(scoreXv)\n",
    "        \n",
    "        if score < score_best:\n",
    "            score_best = copy.copy(score)\n",
    "            #results['xval'] = resXv\n",
    "            clf.fit(inputs, outputs)\n",
    "            results['clf'] = clf\n",
    "            results['predict'] = predict\n",
    "            \n",
    "    return results, score_best\n",
    "\n",
    "\n",
    "#loop over all trees to get a redshift dist\n",
    "def allPredictions(cl, inp):\n",
    "\n",
    "    pdf = np.zeros((len(inp), len(cl.estimators_)))\n",
    "    if hasattr(cl, 'estimator_weights_'):\n",
    "        weights = cl.estimator_weights_ / np.sum(cl.estimator_weights_)\n",
    "        weightsInt = np.array(len(weights) * 3 / np.sum(weights) * weights, dtype=int)\n",
    "        wpdf = np.zeros((len(inp), np.sum(weightsInt)))\n",
    "        del pdf\n",
    "\n",
    "    sm = 0\n",
    "    #in case the file is large, split into smaller pieces to save memory.\n",
    "    if len(inp) > 1e4:\n",
    "        ind_arr = np.array_split(np.arange(len(inp)), int(len(inp)/1e4) + 2)\n",
    "    else:\n",
    "        ind_arr = [np.arange(len(inp))]\n",
    "\n",
    "    for i, DT in enumerate(cl.estimators_):\n",
    "        DTz = np.zeros(len(inp))\n",
    "\n",
    "        for ind_ in ind_arr:\n",
    "            DTz[ind_] = DT.predict(inp[ind_])\n",
    "\n",
    "        if hasattr(cl, 'estimator_weights_'):\n",
    "            #make a weighted pdf\n",
    "            for j in range(weightsInt[i]):\n",
    "                wpdf[:, sm] = DTz\n",
    "                sm += 1\n",
    "        else:\n",
    "            pdf[:, i] = DTz\n",
    "\n",
    "    if hasattr(cl, 'estimator_weights_'):\n",
    "        return wpdf[:, 0:sm]\n",
    "    return pdf\n",
    "\n",
    "def hm_sig_metric(truth_, pred_,pdf_):#, pdf_, sample_weight=None):\n",
    "    \n",
    "    stats = ml_m.getStats((truth_ - pred_))    \n",
    "    #stats_1pz = ml_m.getStats((truth_ - pred_) / (1 + truth_), sample_weight=sample_weight)\n",
    "\n",
    "    return np.abs(stats['median']*1e2) * stats['sigma_68'] * stats['sigma_95'] / (\n",
    "    np.abs(stats['median']*1e2) + np.abs(stats['sigma_95'])  + stats['sigma_68']  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = ['MAG_AUTO_G','MAG_AUTO_I','MAG_AUTO_R','MAG_AUTO_Z','MAG_AUTO_G-MAG_AUTO_I','MAG_AUTO_G-MAG_AUTO_R',\n",
    "         'MAG_AUTO_G-MAG_AUTO_Z','MAG_AUTO_I-MAG_AUTO_R','MAG_AUTO_I-MAG_AUTO_Z','MAG_AUTO_R-MAG_AUTO_Z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dxCos = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/Y1v103/COS.validation.fits')\n",
    "ind = (dxCos['MAG_AUTO_I'] < 23.5) * (dxCos['MAG_AUTO_I']>17)\n",
    "dxCos = dxCos[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs, outputs = ml.dataSet(dxCos, feats, ['REDSHIFT','MAG_AUTO_I']).loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0728693388837\n",
      "stats {'errsig68': 0.00044248626410038101, 'frac_2sig68': 0.1457731357527238, 'frac_3sig68': 0.079898205338917908, 'sigma': 0.40067278445518806, 'outlierFrac': 35.728865678763619, 'median': -0.012633391335904715, 'sigma_95': 0.72488036581492532, 'sigma_68': 0.17188299048888239, 'mean': -0.00096968281115768955}\n",
      "stats/1pz {'errsig68': 0.00027263884019614434, 'frac_2sig68': 0.14129311030405853, 'frac_3sig68': 0.081528510457810885, 'sigma': 0.19015147562793505, 'outlierFrac': 21.217824669299898, 'median': -0.0078106699271409102, 'sigma_95': 0.41936700735234411, 'sigma_68': 0.10590606529133489, 'mean': -0.033205438337006683}\n"
     ]
    }
   ],
   "source": [
    "best_val = 1e99\n",
    "\n",
    "for i in range(10):\n",
    "    clf = rand_machine()\n",
    "    clf.fit(inputs, outputs['REDSHIFT'])\n",
    "    z_p = clf.oob_prediction_\n",
    "    val = hm_sig_metric(outputs['REDSHIFT'], z_p, None)\n",
    "    if val < best_val:\n",
    "        best_val= val\n",
    "        print best_val\n",
    "        best_clf = copy.deepcopy(clf)\n",
    "        best_oob = copy.deepcopy(z_p)\n",
    "\n",
    "stats = ml_m.getStats((outputs['REDSHIFT'] - best_oob))\n",
    "stats1z = ml_m.getStats((outputs['REDSHIFT'] - best_oob)/( 1 + outputs['REDSHIFT']  ))\n",
    "\n",
    "print 'stats', stats\n",
    "print 'stats/1pz', stats1z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = allPredictions(best_clf, inputs)\n",
    "zbins = np.arange(0,6.0,0.01)\n",
    "pdfs, z_mc = preds_to_pdf_mc(df, zbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dxCos['MEAN_Z'] = best_oob\n",
    "dxCos['Z_MC'] = z_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n"
     ]
    }
   ],
   "source": [
    "import photoz_metrics_fn as pmf\n",
    "test_res = pmf.perform_tests(dxCos, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Metric values we may care about for Y1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00111348954639\n",
      "[0.017821587548105824, 0.003952850112223377, 0.004006367504095887, 0.0038462741682865342, 0.009724121308443912, 0.004456449062392065, 0.0010102365463454666, 0.012645860716627988]\n"
     ]
    }
   ],
   "source": [
    "print test_res['Z_MC']['metrics_z1_z2']['bh_photo_z_validation.wl_metric']['VALUE']\n",
    "print test_res['Z_MC']['metrics_z1_z2']['bh_photo_z_validation.wl_metric']['bins']['MEAN_Z']['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0126333913359\n",
      "[-0.01563842764538048, -0.010986831119044915, -0.01707003316240685, -0.009211397597350512, -0.0020742769273444095, -0.01190276460368167, -0.02518453435259682, -0.025850554525585157]\n"
     ]
    }
   ],
   "source": [
    "print test_res['MEAN_Z']['metrics_diffz']['numpy.median']['delta_z']['VALUE']\n",
    "print test_res['MEAN_Z']['metrics_diffz']['numpy.median']['delta_z']['bins']['MEAN_Z']['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.171874896193\n",
      "[0.0660318112161225, 0.06864450831296362, 0.09044819944083068, 0.1268570842888117, 0.18888200880987532, 0.15008200886830286, 0.191666559845192, 0.299833153341028]\n"
     ]
    }
   ],
   "source": [
    "print test_res['MEAN_Z']['metrics_diffz']['bh_photo_z_validation.sigma_68']['delta_z']['VALUE']\n",
    "print test_res['MEAN_Z']['metrics_diffz']['bh_photo_z_validation.sigma_68']['delta_z']['bins']['MEAN_Z']['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145773135753\n",
      "[0.07092198581560284, 0.07203907203907203, 0.15987582460225067, 0.1094985378533521, 0.13588614029142662, 0.16444417132673755, 0.13111545988258316, 0.13233887932683114]\n"
     ]
    }
   ],
   "source": [
    "print test_res['MEAN_Z']['metrics_diffz']['bh_photo_z_validation.outFrac_2sigma68']['delta_z']['VALUE']\n",
    "print test_res['MEAN_Z']['metrics_diffz']['bh_photo_z_validation.outFrac_2sigma68']['delta_z']['bins']['MEAN_Z']['VALUE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>How does RndF and OOB compare with AdaBoost</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results, score_best = k_fold_val(inputs, outputs['REDSHIFT'], 10, 10, hm_sig_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = allPredictions(results['clf'], inputs)\n",
    "zbins = np.arange(0,6.0,0.01)\n",
    "pdfs1, z_mc1 = preds_to_pdf_mc(df1, zbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dxCos['MEAN_Z'] =  results['predict']\n",
    "dxCos['Z_MC'] = z_mc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n"
     ]
    }
   ],
   "source": [
    "test_resAdaz = pmf.perform_tests(dxCos, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.median\n",
      "ADAz\n",
      "-0.00233542794983\n",
      "[-0.003502272013010399, -0.00014045678756453156, -0.0013439403564640962, -0.002510002255439736, 0.0053291457394759045, -0.0023874640464782715, -0.006237499415874481, -0.013971379825047148]\n",
      "RF\n",
      "-0.0126333913359\n",
      "[-0.01563842764538048, -0.010986831119044915, -0.01707003316240685, -0.009211397597350512, -0.0020742769273444095, -0.01190276460368167, -0.02518453435259682, -0.025850554525585157]\n",
      "bh_photo_z_validation.outFrac_2sigma68\n",
      "ADAz\n",
      "0.146846751319\n",
      "[0.057432432432432436, 0.10070493454179255, 0.15357598978288634, 0.12029695469925761, 0.14269208549971116, 0.1545919903643481, 0.12525433384878326, 0.1406876186458553]\n",
      "RF\n",
      "0.145773135753\n",
      "[0.07092198581560284, 0.07203907203907203, 0.15987582460225067, 0.1094985378533521, 0.13588614029142662, 0.16444417132673755, 0.13111545988258316, 0.13233887932683114]\n",
      "bh_photo_z_validation.sigma_68\n",
      "ADAz\n",
      "0.159647128104\n",
      "[0.07173324113782774, 0.07395046799986052, 0.10975829371191295, 0.1301987196895338, 0.17466999563326435, 0.13769428985104673, 0.1858492207788737, 0.2743827794971211]\n",
      "RF\n",
      "0.171874896193\n",
      "[0.0660318112161225, 0.06864450831296362, 0.09044819944083068, 0.1268570842888117, 0.18888200880987532, 0.15008200886830286, 0.191666559845192, 0.299833153341028]\n"
     ]
    }
   ],
   "source": [
    "for i in ['numpy.median', 'bh_photo_z_validation.outFrac_2sigma68','bh_photo_z_validation.sigma_68']:\n",
    "    print i\n",
    "    print 'ADAz'\n",
    "    print test_resAdaz['MEAN_Z']['metrics_diffz'][i]['delta_z']['VALUE']\n",
    "    print test_resAdaz['MEAN_Z']['metrics_diffz'][i]['delta_z']['bins']['MEAN_Z']['VALUE']\n",
    "    print 'RF'\n",
    "    print test_res['MEAN_Z']['metrics_diffz'][i]['delta_z']['VALUE']\n",
    "    print test_res['MEAN_Z']['metrics_diffz'][i]['delta_z']['bins']['MEAN_Z']['VALUE']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alh = Table.read('/Users/hoyleb/DATA/DES/PHOTOZ/ALHAMBRA_FIELD2_Y3.Matched.StellarFlag.fits')\n",
    "ind = (alh['MAG_AUTO_I']<23.5) * (alh['MAG_AUTO_I']>17) *(alh['MAGERR_AUTO_I']<0.3)\n",
    "alh = alh[ind]\n",
    "alh_inp, alh_out = ml.dataSet(alh, feats, ['REDSHIFT','MAG_AUTO_I']).loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alh['MEAN_Z'] = clf.predict(alh_inp)\n",
    "df1 = allPredictions(clf, alh_inp)\n",
    "zbins = np.arange(0,6.0,0.01)\n",
    "pdfs1, z_mc2 = preds_to_pdf_mc(df1, zbins)\n",
    "alh['Z_MC'] = z_mc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n",
      "you have not set any weights for this test\n",
      "continuing with weights=1\n"
     ]
    }
   ],
   "source": [
    "test_resALH = pmf.perform_tests(alh, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.median\n",
      "ADAz\n",
      "-0.00233542794983\n",
      "[-0.003502272013010399, -0.00014045678756453156, -0.0013439403564640962, -0.002510002255439736, 0.0053291457394759045, -0.0023874640464782715, -0.006237499415874481, -0.013971379825047148]\n",
      "RF\n",
      "-0.0126333913359\n",
      "[-0.01563842764538048, -0.010986831119044915, -0.01707003316240685, -0.009211397597350512, -0.0020742769273444095, -0.01190276460368167, -0.02518453435259682, -0.025850554525585157]\n",
      "ALHAMBRA RF\n",
      "-0.0217790224018\n",
      "[nan, -0.03776975585252437, -0.05349732346874042, -0.023814391744169272, -0.031219755303036445, -0.01348423599372639, 0.014734676398439617, -0.011821605063131235]\n",
      "bh_photo_z_validation.outFrac_2sigma68\n",
      "ADAz\n",
      "0.146846751319\n",
      "[0.057432432432432436, 0.10070493454179255, 0.15357598978288634, 0.12029695469925761, 0.14269208549971116, 0.1545919903643481, 0.12525433384878326, 0.1406876186458553]\n",
      "RF\n",
      "0.145773135753\n",
      "[0.07092198581560284, 0.07203907203907203, 0.15987582460225067, 0.1094985378533521, 0.13588614029142662, 0.16444417132673755, 0.13111545988258316, 0.13233887932683114]\n",
      "ALHAMBRA RF\n",
      "0.133706965572\n",
      "[nan, 0.11673151750972763, 0.11357340720221606, 0.08310991957104558, 0.10026385224274406, 0.16593886462882096, 0.14563806777217014, 0.12763466042154567]\n",
      "bh_photo_z_validation.sigma_68\n",
      "ADAz\n",
      "0.159647128104\n",
      "[0.07173324113782774, 0.07395046799986052, 0.10975829371191295, 0.1301987196895338, 0.17466999563326435, 0.13769428985104673, 0.1858492207788737, 0.2743827794971211]\n",
      "RF\n",
      "0.171874896193\n",
      "[0.0660318112161225, 0.06864450831296362, 0.09044819944083068, 0.1268570842888117, 0.18888200880987532, 0.15008200886830286, 0.191666559845192, 0.299833153341028]\n",
      "ALHAMBRA RF\n",
      "0.199896598165\n",
      "[nan, 0.07666722001574575, 0.08053335590810003, 0.1534634103795608, 0.23314572505465397, 0.20804295076311785, 0.22312165479857138, 0.33404476246628145]\n"
     ]
    }
   ],
   "source": [
    "for i in ['numpy.median', 'bh_photo_z_validation.outFrac_2sigma68','bh_photo_z_validation.sigma_68']:\n",
    "    print i\n",
    "    print 'ADAz'\n",
    "    print test_resAdaz['MEAN_Z']['metrics_diffz'][i]['delta_z']['VALUE']\n",
    "    print test_resAdaz['MEAN_Z']['metrics_diffz'][i]['delta_z']['bins']['MEAN_Z']['VALUE']\n",
    "    print 'RF'\n",
    "    print test_res['MEAN_Z']['metrics_diffz'][i]['delta_z']['VALUE']\n",
    "    print test_res['MEAN_Z']['metrics_diffz'][i]['delta_z']['bins']['MEAN_Z']['VALUE']\n",
    "    print 'ALHAMBRA RF'\n",
    "    print test_resALH['MEAN_Z']['metrics_diffz'][i]['delta_z']['VALUE']\n",
    "    print test_resALH['MEAN_Z']['metrics_diffz'][i]['delta_z']['bins']['MEAN_Z']['VALUE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
