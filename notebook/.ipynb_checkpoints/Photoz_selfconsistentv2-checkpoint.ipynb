{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Self consistent  galaxy redshift estimates using correlation functions</h1>\n",
    "Split galaxies into N color cells. Measure correation function for all NxN color cells. Compare with theoretical correlation function for 1) an assumed DM-galaxy bias and 2) dNdz.\n",
    "\n",
    "Iterate over 1) and 2) using the auto and cross correlations for all NxN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from weighted_kde import gaussian_kde as gss_kde\n",
    "import sys \n",
    "import os\n",
    "import time\n",
    "import cPickle as pickle\n",
    "import sml_mla as ml\n",
    "import ml_metrics as ml_m\n",
    "sys.path.append('/Users/hoyleb/Documents/python/modules/photoz-wg/validation/')\n",
    "import bh_photo_z_validation as pval\n",
    "from astropy.table import Table, vstack\n",
    "import math\n",
    "import bh_pca as bh_pca\n",
    "reload(bh_pca)\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from scipy import optimize\n",
    "import matplotlib.mlab as mlab\n",
    "import kmeansClusters as km\n",
    "from scipy.stats import entropy\n",
    "import subprocess\n",
    "#use code/kmeans_data.py to run kmeans on larger dataset\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "almost_black = '#262626'\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams.update({'font.size': 32, \n",
    "                     'axes.linewidth': 5,\n",
    "                    'text.color': almost_black,\n",
    "                    'xtick.major.size': 4,\n",
    "                    'ytick.major.size': 4,\n",
    "                    'legend.fancybox': True,\n",
    "                    'figure.dpi': 300,\n",
    "                    'legend.fontsize': 16,\n",
    "                    'legend.framealpha': 0.8,\n",
    "                    'legend.shadow': True,\n",
    "                    'xtick.labelsize': 32,\n",
    "                    'ytick.labelsize': 32})\n",
    "col = ['red', 'blue', 'green', 'grey', 'purple']\n",
    "lin = ['-', '--', '-x', '-o']\n",
    "\n",
    "\n",
    "def gmm_func(params_, n_gmm, x, plot=False):\n",
    "    y = np.zeros_like(x)\n",
    "    if plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "        f = plt.figure()\n",
    "    for i in range(n_gmm):\n",
    "        ctr, wid, amp = params_[i * 3: (i + 1) * 3]\n",
    "        y += amp * np.exp(-1.0 * ((x - ctr) / wid) ** 2)\n",
    "        if plot:\n",
    "            plt.plot(x, y)\n",
    "\n",
    "    norm = np.trapz(y, x)\n",
    "    if plot:\n",
    "        plt.plot(x, y / norm)\n",
    "        plt.show()\n",
    "    y = y / norm\n",
    "    y[y < 1e-10] = 0\n",
    "    return y\n",
    "\n",
    "pltpath = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/paper/plots/'\n",
    "\n",
    "def wbinCls(l, cl, err, lbin):\n",
    "    #binned_statistics\n",
    "    Clbin = np.zeros(len(lbin) - 1)\n",
    "    Clberr = np.zeros(len(lbin) - 1)\n",
    "    lmean = np.zeros(len(lbin) - 1)\n",
    "    for i in range(len(lbin) - 1):\n",
    "        ind = np.where((l >= lbin[i]) * (l < lbin[i + 1]))[0]\n",
    "        if len(ind) > 0:\n",
    "            w = ( 1.0 / err[ind] ) ** 2\n",
    "            Clbin[i]  = np.sum(cl[ind] * w) / np.sum(w)\n",
    "            Clberr[i] = np.sqrt(1.0 / np.sum(w))\n",
    "            lmean[i]  = np.mean(l[ind])\n",
    "    return Clbin, Clberr, lmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def call_class(dndz, bias, file_names=None , z=np.linspace(0, 1.5, num=1000)):\n",
    "    \"\"\"\n",
    "    dndz = array(dN_idz, z)\n",
    "    bias = [[b0_1, b0_2,..], [b1_0, b1_1, b1_2..], [bk_0, bk_1, bk_2,...]]\n",
    "    \n",
    "    \"\"\"\n",
    "    bias_0, bias_1, bias_k = bias\n",
    "    path1_ = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/'\n",
    "    path2_ = '/Users/hoyleb/Documents/third_party/class_public/'\n",
    "\n",
    "    temp_file_paths = path1_ + 'temp_file_paths/'\n",
    "    path_to_class = path2_ + 'class'\n",
    "    path_example_ini = path2_ + 'explanatory_base.ini'\n",
    "    \n",
    "    num_gmm = 5\n",
    "    redshift = z[1:] +z[0]/2.0 \n",
    "    if file_names is None:\n",
    "        file_names = ['dndz_{:}'.format(i) for i in range(len(dndz[:, 0]))]\n",
    "    info_dict = {'cl_files': list(file_names), 'gmm_base': [0.1, 0.1, 0.1],\n",
    "                 'bias_base': [1, 0 ,0], 'num_gmm': num_gmm,\n",
    "                 'lmax': 3000,\n",
    "                 'redshift': redshift,\n",
    "                 'l_range': np.arange(3000),\n",
    "                 'path_example_ini': path_example_ini,\n",
    "                 'path_to_class' : path_to_class\n",
    "                 }\n",
    "    info_dict['temp_file_paths'] = temp_file_paths\n",
    "\n",
    "        # generate parameter ini file\n",
    "    file_name = create_file_name(info_dict['temp_file_paths'])\n",
    "    dndz_filename = file_name + '.dndz.txt'\n",
    "    cl_out_filename = file_name + '.cl.'\n",
    "    \n",
    "    example_params = {'selection_bias0_arr': ','.join([str(i) for i in bias_0]),\n",
    "                      'selection_bias1_arr': ','.join([str(i) for i in bias_1]),\n",
    "                      'selection_biask_arr': ','.join([str(i) for i in bias_k]),\n",
    "                      'selection_bias': ','.join(['0' for i in bias_k]),\n",
    "                      'selection_mean': ','.join([str(i) for i in np.arange(len(bias_0)) * 1.2 / len(bias_0)]),\n",
    "                      'non_diagonal': len(file_names)-1,\n",
    "                      'selection_filename': dndz_filename,\n",
    "                      'root': cl_out_filename,\n",
    "                      'l_max_lss': info_dict['lmax'],\n",
    "                      'info_dict': info_dict\n",
    "                      }\n",
    "\n",
    "    # write the parameter iniput file\n",
    "    write_parameterini_vals(file_name, example_params)\n",
    "\n",
    "    # write the dndz file\n",
    "    write_dndz_file(dndz_filename, info_dict['redshift'], dndz)\n",
    "\n",
    "     # call class\n",
    "    p_ = subprocess.Popen([info_dict['path_to_class'], file_name])\n",
    "    p_.communicate()\n",
    "\n",
    "    # read results file\n",
    "    l_range_truz, class_res_truez = load_class_results(info_dict['cl_files'], cl_out_filename + 'cl.dat')\n",
    "\n",
    "\n",
    "    return l_range_truz, class_res_truez \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def gmm_func1(params_, n_gmm, x):\n",
    "    y = np.zeros_like(x)\n",
    "    for i in range(n_gmm):\n",
    "        ctr, wid = params_[i * 2: (i + 1) * 2]\n",
    "        y += np.exp(-1.0 * ((x - ctr) / wid) ** 2)\n",
    "    norm = np.trapz(y, x)\n",
    "    y = y / norm\n",
    "    y[y < 1e-10] = 0\n",
    "    return y\n",
    "\n",
    "def dndz_min_func(params_, n_gmm, x, y_true):\n",
    "    y = gmm_func1(params_, n_gmm, x)\n",
    "    return np.mean((y_true - y)**2)\n",
    "\n",
    "def dndz_min_func0(params_, n_gmm, x, y_true):\n",
    "    y = gmm_func(params_, n_gmm, x)\n",
    "    return np.mean(np.abs((y_true - y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cPickle as pickle\n",
    "import healpy as hp\n",
    "import math\n",
    "import numpy as np\n",
    "import spice\n",
    "import sys\n",
    "import os\n",
    "import astropy.io.fits as pyfits\n",
    "\n",
    "def density_to_poissonNumber(nbar_, mask_):\n",
    "    num_p = np.random.poisson(lam=nbar_, size=len(mask_))\n",
    "    return num_p\n",
    "\n",
    "def poissonNumberToDensity(numberMap_, mask_):\n",
    "    #convert discreetized map back to density map\n",
    "    meanInMask = np.mean(numberMap_[mask_], dtype=float)\n",
    "    densityMap = (numberMap_ - meanInMask) / meanInMask\n",
    "    return densityMap\n",
    "\n",
    "def loadTracers(filename, mask_):\n",
    "    numberMap = hp.read_map(filename)\n",
    "    densityMap = poissonNumberToDensity(numberMap, mask_)\n",
    "    nbarTracers = np.abs(np.mean(numberMap[mask_]))\n",
    "    return densityMap, nbarTracers\n",
    "\n",
    "cl__ =0\n",
    "def call_spice(f1_, f2_, lmax, maskfile, thetamax=45, apodizesigma=45):\n",
    "    global cl__\n",
    "    use_weights = True\n",
    "    beam = \"NO\"\n",
    "    pixelfile = 'YES'\n",
    "    weightfile = 'NO'\n",
    "    covfileout = \"YES\"\n",
    "    cl = spice.spice(bin=False, norm=False, mapfile=f1_,\n",
    "            mapfile2=f2_, nlmax=lmax, polarization=\"NO\", beam_file=\"NO\",\n",
    "            beam_file2=\"NO\", pixelfile=pixelfile, weightfile=weightfile,\n",
    "            apodizesigma=apodizesigma, thetamax=thetamax, covfileout=covfileout,\n",
    "            maskfile2=maskfile, maskfile=maskfile)\n",
    "    \n",
    "    cl__ = copy.copy(cl)\n",
    "    cls = (np.array(cl['TT']))[0: lmax]\n",
    "    covF = pyfits.open('spice.covariance.fits')\n",
    "    cov  = covF[0].data[0]\n",
    "    \n",
    "    #NOTE : the current format of this file is a three columns array\n",
    "    #the first one corresponding to the separation theta in radians\n",
    "    #the second one to cos(theta), the third one to the correlation\n",
    "    #function of the temperature and, if polarization is activated,\n",
    "    #five additional columns are written, corresponding respectively to\n",
    "    #QQ, UU, TQ, TU and QU in the coupled case and to EE, BB, TQ, TU and QU\n",
    "    #in the decoupled case (see option -decouple and -symmetric_cl).\n",
    "    di   = np.diag_indices(len(cov))\n",
    "    err_s = np.sqrt(cov[di])[1:]\n",
    "    L = np.arange(len(cls))\n",
    "    return cls * L * (L + 1) / (2 * math.pi), err_s * L * (L + 1) / (2 * math.pi)\n",
    "\n",
    "\n",
    "def average_noise(nbar_, mask_, lmax, maskfile, N=50, thetamax=45):\n",
    "    print nbar_, mask_, lmax, maskfile, N, thetamax\n",
    "    cls = np.zeros((N, lmax))\n",
    "    temp_map = 'tempnbarPolSpice.fits'\n",
    "    for i_ in range(N):\n",
    "        poisson_n = density_to_poissonNumber(nbar_, mask_)\n",
    "        density = poissonNumberToDensity(poisson_n, mask_)\n",
    "        #make simulated density map directly from Cls map and write to file\n",
    "        if os.path.exists(temp_map):\n",
    "            os.remove(temp_map)\n",
    "        hp.write_map(temp_map, density)\n",
    "        cls[i_] = call_spice(temp_map, temp_map, lmax, maskfile, thetamax=thetamax, apodizesigma = thetamax)[0]\n",
    "    return cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_noise_1nbar = np.mean(noise, axis=0)\n",
    "res = {'L': np.arange(len(avg_noise_1nbar)),'avg_noise_1nbar': avg_noise_1nbar}\n",
    "pickle.dump(res, open('data/avg_noise_1nbar.p', 'w') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise = average_noise(nbar, mask, lmax, maskfile, N=100, thetamax=thetamax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import string \n",
    "import subprocess\n",
    "import random\n",
    "def file_generator(size=9, chars=string.ascii_uppercase + string.digits):\n",
    "    \"\"\"select a random  name\"\"\"\n",
    "    return ''.join(random.choice(chars) for _ in range(size)) + '.params.ini'\n",
    "\n",
    "\n",
    "def create_file_name(path):\n",
    "    \"\"\"Generate an unused random file name\"\"\"\n",
    "    file_name = file_generator()\n",
    "    while os.path.isfile(path + file_name):\n",
    "        file_name = file_generator()\n",
    "    return path + file_name\n",
    "\n",
    "\n",
    "def write_parameterini_vals(file_name, params):\n",
    "    # write the parameter file\n",
    "\n",
    "    base_file = open(params['info_dict']['path_example_ini'], 'r')\n",
    "    fnew = open(file_name, 'w')\n",
    "\n",
    "    for i in base_file:\n",
    "        new_line = copy.copy(i)\n",
    "        if '=' in i:\n",
    "            ky = i.split('=')[0]\n",
    "            if ky in params.keys():\n",
    "                new_line = ky + '={:}'.format(params[ky]) + \"\\n\"\n",
    "        fnew.write(new_line)\n",
    "\n",
    "    base_file.close()\n",
    "    fnew.close()\n",
    "    return True\n",
    "\n",
    "def write_dndz_file(file_name, redshift, dndz_):\n",
    "    fnew = open(file_name, 'w')\n",
    "    initial_z = np.amin(redshift) - (redshift[1] - redshift[0]) / 2.0\n",
    "    if initial_z < 0:\n",
    "        print \"redshift error\"\n",
    "\n",
    "    fnew.write(str(initial_z) + ' ' + ' '.join(['0' for i in range(len(dndz_[:, 0]))]) + \"\\n\")\n",
    "\n",
    "    for i in range(len(redshift)):\n",
    "        fnew.write(str(redshift[i]) + ' ' + ' '.join(['{:0.7e}'.format(j) for j in dndz_[:, i]]) + \"\\n\")\n",
    "\n",
    "    final_z = np.amax(redshift) + (redshift[1] - redshift[0]) / 2.0\n",
    "    fnew.write(str(final_z) + ' ' + ' '.join(['0' for i in range(len(dndz_[:, 0]))]) + \"\\n\")\n",
    "    fnew.close()\n",
    "    return True\n",
    "\n",
    "\n",
    "def load_class_results(file_list, cl_file_name):\n",
    "    d = np.genfromtxt(cl_file_name)\n",
    "    res_ = {}\n",
    "    cnt = 0\n",
    "    l_range = d[:, 0]\n",
    "    d = d[:, 1:]\n",
    "    for i, fi in enumerate(file_list):\n",
    "        res_[fi] = {}\n",
    "        for j, fj in enumerate(file_list):\n",
    "            if j >= i:\n",
    "                res_[fi][fj] = d[:, cnt]\n",
    "                cnt += 1\n",
    "    return l_range, res_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#better to use MICE public sims. see readme.txt for details.\n",
    "path = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/Kclusters.merged.mice2.des.csv_0.csv.evolocrr_sampled_sampled.12.fits'\n",
    "test_d = Table.read(path)\n",
    "\n",
    "mags = ['des_asahi_full_g_true', 'des_asahi_full_r_true', 'des_asahi_full_i_true', \n",
    "        'des_asahi_full_z_true']\n",
    "\n",
    "for i, m1 in enumerate(mags):\n",
    "    y_ = m1.split('_tr')[0].split('ull_')[1]    \n",
    "    for j, m2 in enumerate(mags):\n",
    "        y2 = m2.split('_tr')[0].split('ull_')[1]\n",
    "        if i>j:\n",
    "            test_d[m1 + '-' + m2] = np.array(\n",
    "                test_d[m1]) -np.array(test_d[m2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = ['des_asahi_full_i_true', \n",
    "         'des_asahi_full_r_true-des_asahi_full_g_true',\n",
    "         'des_asahi_full_i_true-des_asahi_full_g_true',\n",
    "        'des_asahi_full_z_true-des_asahi_full_i_true', \n",
    "        'des_asahi_full_i_true-des_asahi_full_r_true']#, 'des_asahi_full_z_true-des_asahi_full_g_true', \n",
    "#       'des_asahi_full_z_true-des_asahi_full_r_true', 'des_asahi_full_z_true-des_asahi_full_i_true',\n",
    "#       'des_asahi_full_r_true', 'des_asahi_full_g_true', 'des_asahi_full_z_true']\n",
    "\n",
    "\n",
    "ins , _ = ml.dataSet(test_d, feats, [feats[0]]).loadData()\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#train decision tree\n",
    "clf = DecisionTreeRegressor(min_samples_leaf=15000)\n",
    "clf.fit(ins, ins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = clf.tree_.apply(ins.astype('float32'))\n",
    "\n",
    "num1 = np.zeros(len(np.unique(ids)))\n",
    "d1 = np.zeros((len(np.unique(ids)), len(z)))\n",
    "z_stat1 = np.zeros((len(np.unique(ids)), 2))\n",
    "for i, id_ in  enumerate(np.unique(ids)):\n",
    "    ind1 = ids==id_\n",
    "    num1[i] = np.sum(ind1)\n",
    "    d1[i] = gss_kde(test_d['z_cgal_v'][ind1]).evaluate(z)\n",
    "    z_stat1[i] = np.mean(test_d['z_cgal_v'][ind1]), np.std(test_d['z_cgal_v'][ind1])\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "plt.step(range(len(num1)), num1*1e-3, linewidth=3, label='DT {:}'.format(len(num1)))\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Number of objects [/1M]')\n",
    "plt.legend()\n",
    "\n",
    "inds = np.argsort(z_stat1[:, 0])\n",
    "f = plt.figure()\n",
    "plt.title('Decision Tree')\n",
    "plt.errorbar(range(len(inds)), z_stat1[inds, 0], yerr=z_stat1[inds, 1],fmt='o', label='DT')\n",
    "plt.ylabel('Redshift')\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(bh_pca)\n",
    "feats = ['des_asahi_full_i_true', \n",
    "         'des_asahi_full_r_true-des_asahi_full_g_true',\n",
    "         'des_asahi_full_i_true-des_asahi_full_g_true',\n",
    "        'des_asahi_full_z_true-des_asahi_full_i_true', \n",
    "        'des_asahi_full_i_true-des_asahi_full_r_true']#, 'des_asahi_full_z_true-des_asahi_full_g_true', \n",
    "#         'des_asahi_full_z_true-des_asahi_full_r_true', 'des_asahi_full_z_true-des_asahi_full_i_true',\n",
    "#         'des_asahi_full_r_true', 'des_asahi_full_g_true', 'des_asahi_full_z_true']\n",
    "\n",
    "ins , _ = ml.dataSet(test_d, feats, [feats[0]]).loadData()\n",
    "\n",
    "rnd = np.arange(len(ins))\n",
    "np.random.shuffle(rnd)\n",
    "\n",
    "print np.shape(ins[rnd[0:10000]])\n",
    "#Non-liner PCA\n",
    "pca_clf, dnew, dreverse = bh_pca.pca(ins[rnd[0:10000]], n_components=3)\n",
    "\n",
    "new_data = bh_pca.pca_transform(ins, pca_clf)\n",
    "\n",
    "print np.shape(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(min_samples_leaf=20000)\n",
    "clf.fit(new_data, new_data)\n",
    "\n",
    "ids = clf.tree_.apply(new_data.astype('float32'))\n",
    "\n",
    "num1 = np.zeros(len(np.unique(ids)))\n",
    "d1 = np.zeros((len(np.unique(ids)), len(z)))\n",
    "z_stat1 = np.zeros((len(np.unique(ids)), 2))\n",
    "for i, id_ in  enumerate(np.unique(ids)):\n",
    "    ind1 = ids==id_\n",
    "    num1[i] = np.sum(ind1)\n",
    "    d1[i] = gss_kde(test_d['z_cgal_v'][ind1]).evaluate(z)\n",
    "    z_stat1[i] = np.mean(test_d['z_cgal_v'][ind1]), np.std(test_d['z_cgal_v'][ind1])\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "plt.step(range(len(num1)), num1*1e-3, linewidth=3, label='DT {:}'.format(len(num1)))\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Number of objects [/1M]')\n",
    "plt.legend()\n",
    "\n",
    "inds = np.argsort(z_stat1[:, 0])\n",
    "f = plt.figure()\n",
    "plt.title('Decision Tree + PCA')\n",
    "plt.errorbar(range(len(inds)), z_stat1[inds, 0], yerr=z_stat1[inds, 1],fmt='o', label='DT')\n",
    "plt.ylabel('Redshift')\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.legend(loc=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Full sample redshift distribution</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "_ = plt.hist(test_d['z_cgal_v'],bins=30)\n",
    "plt.xlabel('True redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h2>Split data in to color cells using AffinityPropagation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feats = ['des_asahi_full_i_true', \n",
    "         'des_asahi_full_r_true-des_asahi_full_g_true',\n",
    "         'des_asahi_full_i_true-des_asahi_full_g_true',\n",
    "        'des_asahi_full_z_true-des_asahi_full_i_true', \n",
    "        'des_asahi_full_i_true-des_asahi_full_r_true', 'des_asahi_full_z_true-des_asahi_full_g_true']#, \n",
    "#         'des_asahi_full_z_true-des_asahi_full_r_true', 'des_asahi_full_z_true-des_asahi_full_i_true',\n",
    "#         'des_asahi_full_r_true', 'des_asahi_full_g_true', 'des_asahi_full_z_true']\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation, KMeans\n",
    "\n",
    "ins , _ = ml.dataSet(test_d, feats, [feats[0]]).loadData()\n",
    "\n",
    "ind = np.arange(len(ins))\n",
    "np.random.shuffle(ind)\n",
    "ind = ind[0: int(len(ind)*0.0007)]\n",
    "print 'Ndata', len(ind)\n",
    "z = np.linspace(0, 1.5, num=1000)\n",
    "\n",
    "for p2 in [0.7]:\n",
    "    \n",
    "    c2 = AffinityPropagation(damping=p2)\n",
    "    c2.fit(ins[ind])\n",
    "    c2_p = c2.predict(ins)\n",
    "    \n",
    "    c_o = KMeans(n_clusters=len(np.unique(c2_p)))\n",
    "    c_o.fit(ins[ind])\n",
    "    c_o_p = c_o.predict(ins)\n",
    "    \n",
    "    num1 = np.zeros(len(np.unique(c_o_p)))\n",
    "    d1 = np.zeros((len(np.unique(c_o_p)), len(z)))\n",
    "    z_stat1 = np.zeros((len(np.unique(c_o_p)), 2))\n",
    "    for i in  np.unique(c_o_p):\n",
    "        ind1 = c_o_p==i\n",
    "        num1[i] = np.sum(ind1)\n",
    "        d1[i] = gss_kde(test_d['z_cgal_v'][ind1]).evaluate(z)\n",
    "        if np.sum(ind1)*1e-3 > 20: \n",
    "            z_stat1[i] = np.mean(test_d['z_cgal_v'][ind1]), np.std(test_d['z_cgal_v'][ind1])\n",
    "        \n",
    "    num2 = np.zeros(len(np.unique(c2_p)))\n",
    "    d2 = np.zeros((len(np.unique(c2_p)), len(z)))\n",
    "    z_stat2 = np.zeros((len(np.unique(c2_p)), 2))\n",
    "    for i in  np.unique(c2_p):\n",
    "        ind1 = c2_p ==i    \n",
    "        d2[i] = gss_kde(test_d['z_cgal_v'][ind1]).evaluate(z)\n",
    "        num2[i] = np.sum(ind1)\n",
    "        if np.sum(ind1)*1e-3 > 20: \n",
    "            z_stat2[i] = np.mean(test_d['z_cgal_v'][ind1]), np.std(test_d['z_cgal_v'][ind1])\n",
    "        \n",
    "    f = plt.figure()\n",
    "    plt.step(range(len(num1)), num1*1e-3, linewidth=3, label='Kmeans {:}'.format(len(num1)))\n",
    "    plt.step(range(len(num2)), num2*1e-3, linewidth=3, label='AP {:}'.format(len(num2)))\n",
    "    plt.xlabel('Cluster ID')\n",
    "    plt.ylabel('Number of objects [/1M]')\n",
    "    plt.legend()\n",
    "    \n",
    "    if False:\n",
    "        f = plt.figure()\n",
    "        plt.title('Kmeans')\n",
    "        for i in  np.unique(c_o_p):\n",
    "            plt.plot(z, d1[i], label='KM {:} #{:}M'.format(i, num1[i]*1e-3))\n",
    "        plt.legend()\n",
    "        f = plt.figure()\n",
    "        plt.title('AP')\n",
    "        for i in  np.unique(c2_p):\n",
    "            plt.plot(z, d2[i], label='AP {:} #{:}M'.format(i, num2[i]*1e-3))\n",
    "        plt.legend()\n",
    "    \n",
    "    \n",
    "    inds = np.argsort(z_stat1[:, 0])\n",
    "    inds2 = np.argsort(z_stat2[:, 0])\n",
    "    f = plt.figure()\n",
    "    plt.title('Kmeans')\n",
    "    plt.errorbar(range(len(inds)), z_stat1[inds, 0], yerr=z_stat1[inds, 1],fmt='o', label='Kmeans')\n",
    "    plt.errorbar(range(len(inds2)), z_stat2[inds2, 0], yerr=z_stat2[inds2, 1],fmt='o', label='AP')\n",
    "    plt.ylabel('Redshift')\n",
    "    plt.xlabel('Cluster ID')\n",
    "    plt.legend(loc=4)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats = ['des_asahi_full_i_true', 'des_asahi_full_r_true', 'des_asahi_full_i_true', 'des_asahi_full_z_true',\n",
    "        'des_asahi_full_r_true-des_asahi_full_g_true',\n",
    " 'des_asahi_full_i_true-des_asahi_full_g_true', \n",
    "         'des_asahi_full_i_true-des_asahi_full_r_true', 'des_asahi_full_z_true-des_asahi_full_g_true'] #,\n",
    "#         'des_asahi_full_z_true-des_asahi_full_r_true', 'des_asahi_full_z_true-des_asahi_full_i_true']\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation, KMeans\n",
    "\n",
    "ins , _ = ml.dataSet(test_d, feats, [feats[0]]).loadData()\n",
    "\n",
    "ind = np.arange(len(ins))\n",
    "np.random.shuffle(ind)\n",
    "ind = ind[0: int(len(ind)*0.01)]\n",
    "print 'Ndata', len(ind)\n",
    "z = np.linspace(0, 1.5, num=1000)\n",
    "for p2 in np.arange(40, 48, 2):\n",
    "\n",
    "    c_o = KMeans(n_clusters=p2)\n",
    "    c_o.fit(ins[ind])\n",
    "    c_o_p = c_o.predict(ins)\n",
    "    \n",
    "    num1 = np.zeros(len(np.unique(c_o_p)))\n",
    "    d1 = np.zeros((len(np.unique(c_o_p)), len(z)))\n",
    "    z_stat1 = np.zeros((len(np.unique(c_o_p)), 2))\n",
    "    for i in  np.unique(c_o_p):\n",
    "        ind1 = c_o_p==i\n",
    "        num1[i] = np.sum(ind1)\n",
    "        d1[i] = gss_kde(test_d['z_cgal_v'][ind1]).evaluate(z)\n",
    "        if (num1[i]*1e-3 > 10):\n",
    "            z_stat1[i] = np.mean(test_d['z_cgal_v'][ind1]), np.std(test_d['z_cgal_v'][ind1])\n",
    "    \n",
    "    f = plt.figure()\n",
    "    plt.step(range(len(num1)), num1*1e-3, linewidth=3, label='Kmeans {:}'.format(len(num1)))\n",
    "    plt.xlabel('Cluster ID')\n",
    "    plt.ylabel('Number of objects [/1M]')\n",
    "    plt.legend()\n",
    "    \n",
    "    f = plt.figure()\n",
    "    plt.title('Kmeans')\n",
    "    for i in  np.unique(c_o_p):\n",
    "        if (num1[i]*1e-3 > 10):\n",
    "            plt.plot(z, d1[i], label='Clus {:} #data {:}M '.format(i, num1[i]*1e-3))\n",
    "    plt.legend()\n",
    "  \n",
    "    inds = np.argsort(z_stat1[:, 0])\n",
    "    f = plt.figure()\n",
    "    plt.title('Kmeans')\n",
    "    plt.errorbar(range(len(inds)), z_stat1[inds, 0], yerr=z_stat1[inds, 1],fmt='o')\n",
    "    plt.ylabel('Redshift')\n",
    "    plt.xlabel('Cluster ID')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Split data into color cells using Kmeans clustering</h2>\n",
    "Once we've split the data, let's look at the z-distribution of each color 'cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "kid = np.unique(np.array(test_d['KMEANS_CLUSTERID']))\n",
    "print kid\n",
    "print test_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.keys()\n",
    "print files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r= p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_des.15centers.Nside.512.zdist.p', 'r'))\n",
    "files = r['redshift_dndz'].keys()\n",
    "\n",
    "num = np.zeros(len(files))\n",
    "num_est = np.zeros(len(files))\n",
    "z = np.linspace(0, 1.5, num=1000)\n",
    "dndz = np.zeros((len(files), len(z)))\n",
    "z_stat = np.zeros((len(files), 2))\n",
    "\n",
    "kid = []\n",
    "for i, fil in enumerate(files):\n",
    "    cluster_id = int(fil.split('my_map')[1].split('.')[0])\n",
    "    kid.append(cluster_id)\n",
    "    num[i] = np.sum(r['truez_hist'][fil])\n",
    "    num_est[i] = np.sum(test_d['KMEANS_CLUSTERID']==cluster_id)\n",
    "    dndz[i] = gss_kde(test_d['z_cgal_v'][test_d['KMEANS_CLUSTERID']==cluster_id]).evaluate(z)\n",
    "    z_stat[i] = np.mean(test_d['z_cgal_v'][test_d['KMEANS_CLUSTERID']==cluster_id]), np.std(test_d['z_cgal_v'][test_d['KMEANS_CLUSTERID']==cluster_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind  = np.argsort(z_stat[:, 0])\n",
    "print ind, z_stat[ind, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#how are the data distributed among cells?\n",
    "kid = np.array(kid)\n",
    "plt.step(range(len(num)), num*1e-6, linewidth=3)\n",
    "plt.step(range(len(num_est)), num_est*1e-3,color='red', linewidth=3)\n",
    "plt.xlabel('K-means cluster ID')\n",
    "plt.ylabel('Number of objects [/1M]')\n",
    "plt.savefig(pltpath + 'num_KMClus12.pdf')\n",
    "\n",
    "f = plt.figure()\n",
    "ind  = np.argsort(z_stat[:, 0])\n",
    "plt.errorbar(kid+1, z_stat[ind, 0], yerr=z_stat[ind,1],fmt ='o')\n",
    "plt.xticks(kid+1, kid[ind].astype(int), rotation='vertical', fontsize=18)\n",
    "plt.xlabel('K-means cluster ID')\n",
    "plt.ylabel('Mean reshift')\n",
    "plt.savefig(pltpath + 'z_KMClus12.pdf')\n",
    "\n",
    "\n",
    "for i, id1 in enumerate(kid):\n",
    "    if i %6 == 0: \n",
    "        f = plt.figure()\n",
    "        plt.xlabel('Redshift')\n",
    "    plt.plot(z, dndz[i], label='KM Cluster {:}'.format(int(id1)))\n",
    "    plt.legend()\n",
    "plt.savefig(pltpath + 'dndz_KMClus12.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mags = ['des_asahi_full_g_true', 'des_asahi_full_r_true', 'des_asahi_full_i_true', \n",
    "        'des_asahi_full_z_true','des_asahi_full_r-g_true', 'des_asahi_full_i-g_true', \n",
    "        'des_asahi_full_i-r_true', 'des_asahi_full_z-g_true', 'des_asahi_full_z-r_true', \n",
    "        'des_asahi_full_z-i_true']\n",
    "\n",
    "for i, id1 in enumerate(kid[1:-1]):\n",
    "    \n",
    "    ind = np.array(test_d['KMEANS_CLUSTERID']==id1)\n",
    "    ind1 = np.array(test_d['KMEANS_CLUSTERID']==id1-1)\n",
    "    ind2 = np.array(test_d['KMEANS_CLUSTERID']==id1+1)\n",
    "    indne = ind + ind1 + ind2\n",
    "    \n",
    "    rndx = np.random.choice(mags)\n",
    "    rndy = np.random.choice([j for j in mags if j != rndx])\n",
    "    \n",
    "    f = plt.figure()\n",
    "    plt.plot(np.array(test_d[rndx][indne ==False]), np.array(test_d[rndy][indne==False]), 'o', label=None, alpha=0.2, rasterized=True)\n",
    "\n",
    "    plt.plot(test_d[rndx][ind1], test_d[rndy][ind1], 'o', label='KM Cluster {:}'.format(\n",
    "            int(id1-1)), alpha=0.7, rasterized=True)\n",
    "    plt.plot(test_d[rndx][ind], test_d[rndy][ind], 'o', label='KM Cluster {:}'.format(\n",
    "            int(id1)), alpha=0.7, rasterized=True)\n",
    "    plt.plot(test_d[rndx][ind2], test_d[rndy][ind2], 'o', label='KM Cluster {:}'.format(\n",
    "            int(id1+1)), alpha=0.7, rasterized=True)\n",
    "    \n",
    "    xl = rndx.split('_tr')[0].split('ull_')[1]\n",
    "    y_ = rndy.split('_tr')[0].split('ull_')[1]\n",
    "    plt.ylabel(y_)\n",
    "    plt.xlabel(xl)\n",
    "    plt.legend(loc=3)\n",
    "    plt.savefig(pltpath + 'clus_col{:}.pdf'.format(int(id1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Can we fit a GMM to this distribution?</h3>\n",
    "We will want to model this distribution. let's try to do it with 3 or 4 GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "cnt = 0\n",
    "lin = ['-', '--', '-x', '-o']\n",
    "col = ['red', 'green','blue', 'orange', 'yellow', 'grey' ]\n",
    "num_gmm = 5\n",
    "gmm_base = [0.1, 0.1, 0.5]\n",
    "for i1 in np.arange(num_gmm - 1):\n",
    "    gmm_base.append(0.1  + (i1 + 1) * 1.1 / num_gmm)\n",
    "    gmm_base.append(0.1)\n",
    "    gmm_base.append(0.5)\n",
    "\n",
    "bestgmm_dndz = np.zeros_like(dndz)\n",
    "for i, id1 in enumerate(kid):\n",
    "    res = minimize(dndz_min_func0, gmm_base, method='Nelder-Mead', \n",
    "                   tol=1e-8, args=(num_gmm, z, dndz[i]))\n",
    "    y = gmm_func(res.x, num_gmm, z)\n",
    "    chi2 = dndz_min_func0(res.x, num_gmm, z, dndz[i])\n",
    "    gmms = np.array(res.x)\n",
    "    print np.shape(gmms)\n",
    "    print res['nit'],chi2, gmms[np.arange(num_gmm)*3+2]\n",
    "    \n",
    "    #sys.exit()\n",
    "    if i% 3 == 0:\n",
    "        f = plt.figure()\n",
    "        \n",
    "    plt.plot(z, dndz[i], label='True-z KMC{:}'.format(int(id1)),color=col[i%4], alpha=0.7, linewidth=3)\n",
    "    plt.plot(z, y, '--', label='Approx GMM-z MSE={:0.3f}'.format(chi2),color=col[i%4], alpha=0.7, linewidth=3)\n",
    "    plt.legend()\n",
    "    bestgmm_dndz[i] = y\n",
    "    if i %3 == 2:\n",
    "        plt.xlabel('Redshift')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(pltpath + 'GMM{:}_dndz_KMClus{:}.pdf'.format(num_gmm, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Healpix the ra/dec distribution of each color cell</h2>\n",
    "\n",
    "Plot the distribution of data in each color cell, and then save each map to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask1 = hp.read_map('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/maps/total_mask.mice2_42.fits')\n",
    "plt.rcParams.update({'font.size': 16, \n",
    "                     'axes.linewidth': 5,\n",
    "                    'text.color': almost_black,\n",
    "                    'figure.dpi': 300,\n",
    "                    'legend.fontsize': 16,\n",
    "                    'legend.framealpha': 0.8,\n",
    "                    })\n",
    "hp.mollview(mask1, title='Mice mask')\n",
    "plt.savefig(pltpath + 'Mice2Mask.pdf'.format(i),pad_inches=0.1)\n",
    "\n",
    "N = 0\n",
    "for i in range(9):\n",
    "    mp1 = hp.read_map(\"/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/maps/mice2_42_my_map\" + str(i) + \".fits\")\n",
    "    print \"maps/my_map\" + str(i) + \".fits\", np.sum(mp1)\n",
    "    N+= np.sum(mp1)\n",
    "    wmap_map_I_masked = hp.ma(mp1)\n",
    "    wmap_map_I_masked.mask = np.logical_not(mask1)\n",
    "    hp.mollview(wmap_map_I_masked.filled(), title='K-means Cluster {:}'.format(i))\n",
    "    plt.savefig(pltpath + 'HPmap_KMClus{:}.pdf'.format(i),pad_inches=0.1)\n",
    "print \"total number: \", N\n",
    "\n",
    "plt.rcParams.update({'font.size': 32, \n",
    "                     'axes.linewidth': 5,\n",
    "                    'text.color': almost_black,\n",
    "                    'xtick.major.size': 4,\n",
    "                    'ytick.major.size': 4,\n",
    "                    'legend.fancybox': True,\n",
    "                    'figure.dpi': 300,\n",
    "                    'legend.fontsize': 16,\n",
    "                    'legend.framealpha': 0.8,\n",
    "                    'legend.shadow': True,\n",
    "                    'xtick.labelsize': 32,\n",
    "                    'ytick.labelsize': 32})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What are pol-spice parameters for this pixelisation and numebr density</h3>\n",
    "\n",
    "Determine besst apodisation_sigma and number of noise estimates to obtain input cls back again (bias==1)\n",
    "-- answer thetamax=45 (for 1/8 sky mask) AND apodisation==45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nd = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_15.Nside.1024.cls.p', 'r'))\n",
    "d = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_des.15centers.Nside.1024.zdist.p', 'r'))\n",
    "print d.keys(), nd.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convergence tests for our Cls</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#part1 get some realistic Class Cl's to play with.\n",
    "Nside ='1024'\n",
    "\n",
    "nd = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_15.Nside.'+Nside+'.cls.p', 'r'))\n",
    "d = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_des.15centers.Nside.'+Nside+'.zdist.p', 'r'))\n",
    "\n",
    "k = d['redshift_dndz'].keys()\n",
    "\n",
    "dndz = np.zeros((len(k), len(d['redshift_dndz'][k[0]][0])))\n",
    "z = d['z_bins']\n",
    "bias0 = []\n",
    "bias1 = []\n",
    "biask = []\n",
    "for i, k1 in enumerate(k):\n",
    "    dndz[i, :] = d['redshift_dndz'][k1][1]\n",
    "    z = d['redshift_dndz'][k1][0]\n",
    "    bias0.append(1)\n",
    "    bias1.append(0)\n",
    "    biask.append(0)\n",
    "    print k1, ' -- ', d['cls'][k1].keys(), len(d['cls'][k1][k1])\n",
    "                     \n",
    "bias = [bias0, bias1, biask]\n",
    "\n",
    "#get some class_cl's that we can play with.\n",
    "l_range, class_res  =  call_class(dndz, bias, file_names=k, z=z)\n",
    "\n",
    "#part 2, make maps and try to recover input Cls\n",
    "\n",
    "for i, k1 in enumerate(k):\n",
    "    L = np.arange(len(class_res[k1][k1]))\n",
    "    clt =  class_res[k1][k1] * 2 * math.pi / (L * (L +1))\n",
    "    clt[~np.isfinite(clt)] = 0\n",
    "    #class output = [l(l+1)/2pi] C_l's\n",
    "    f = plt.figure()\n",
    "    \n",
    "    \n",
    "    #if False:\n",
    "    mapt = hp.synfast(clt, 512)\n",
    "    hp.write_map('temp_map.fits', mapt, nest=0)\n",
    "    f1_ = 'temp_map.fits'\n",
    "    lmax = max(L)\n",
    "    #for theta\n",
    "    maskfile = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/total_mask.fits'\n",
    "    for thetamax, apodizesigma in [[10, 10]]:\n",
    "        cl, clerr = call_spice(f1_, f1_, lmax, maskfile, thetamax=thetamax, apodizesigma=apodizesigma)\n",
    "        L1 = np.arange(len(cl))\n",
    "        cl_ = cl * 2 * math.pi / (L1 * (L1 +1))\n",
    "        clerr_ = clerr * 2 * math.pi / (L1 * (L1 +1))\n",
    "        plt.errorbar(L1, cl_ ,yerr = clerr_, fmt= '--', label='$\\Theta${:}, AS{:}'.format(thetamax, apodizesigma))\n",
    "    plt.plot(L,  clt , label=k1)\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    f = plt.figure()\n",
    "    chi2 = np.zeros(len(L))\n",
    "    DoF = np.zeros(len(L))\n",
    "    for j in range(400):\n",
    "        ind = (L > j ) *(L < 450)\n",
    "        chi2[j] = np.sum(np.power((clt[ind] - cl_[ind])/(clerr_[ind]*2), 2))\n",
    "        DoF[j] = np.sum(ind)\n",
    "    plt.plot(L, chi2)\n",
    "    plt.plot(L, DoF)\n",
    "    plt.ylabel('$\\chi^2$')\n",
    "    plt.xlabel('L')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nside ='512'\n",
    "Nside ='1024'\n",
    "\n",
    "nd = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_15.Nside.' + Nside + '.cls.p', 'r'))\n",
    "d = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_des.15centers.Nside.' + Nside + '.zdist.p', 'r'))\n",
    "\n",
    "#part1 get some realistic Class Cl's to play with.\n",
    "k = d['redshift_dndz'].keys()\n",
    "\n",
    "dndz = np.zeros((len(k), len(d['redshift_dndz'][k[0]][0])))\n",
    "z = d['z_bins']\n",
    "bias0 = []\n",
    "bias1 = []\n",
    "biask = []\n",
    "for i, k1 in enumerate(k):\n",
    "    dndz[i, :] = d['redshift_dndz'][k1][1]\n",
    "    z = d['redshift_dndz'][k1][0]\n",
    "    bias0.append(1)\n",
    "    bias1.append(0)\n",
    "    biask.append(0)\n",
    "                      \n",
    "bias = [bias0, bias1, biask]\n",
    "\n",
    "maskfile = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/total_mask.mice2_15.Nside.'+Nside+'.fits'\n",
    "thetamax, apodizesigma =10, 10\n",
    "mask = hp.read_map(maskfile)\n",
    "mask = mask > 0\n",
    "    \n",
    "#get some class_cl's that we can play with.\n",
    "l_range, class_res  =  call_class(dndz, bias, file_names=k, z=z)\n",
    "\n",
    "#part 2, make maps and try to recover input Cls\n",
    "i=0 \n",
    "#k1 = k[0]\n",
    "for k1 in k:\n",
    "    L = np.arange(len(class_res[k1][k1]))\n",
    "    clt =  class_res[k1][k1] * 2 * math.pi / (L * (L +1))\n",
    "    clt[~np.isfinite(clt)] = 0\n",
    "    #class output = [l(l+1)/2pi] C_l's\n",
    "    f = plt.figure()\n",
    "\n",
    "\n",
    "    #if False:\n",
    "    mapt = hp.synfast(clt, int(Nside))\n",
    "    f1_ = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/temp_map.fits'\n",
    "    hp.write_map(f1_, mapt, nest=0)\n",
    "\n",
    "    lmax = max(L)\n",
    "    #for theta\n",
    "    #maskfile = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/total_mask.fits'\n",
    "\n",
    "    for thetamax, apodizesigma in [[45, 45]]:#, [180, 180], ['NO', 'NO']]:\n",
    "        cl, clerr = call_spice(f1_, f1_, lmax, maskfile, thetamax=thetamax, apodizesigma=apodizesigma)\n",
    "        L1 = np.arange(len(cl))\n",
    "        cl_ = cl * 2 * math.pi / (L1 * (L1 +1))\n",
    "        clerr_ = clerr * 2 * math.pi / (L1 * (L1 +1))\n",
    "        plt.errorbar(L1, cl_ ,yerr = clerr_, fmt= '--', label='$\\Theta${:}, AS{:}'.format(thetamax, apodizesigma))\n",
    "    plt.plot(L,  clt , label=k1)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "\n",
    "    f = plt.figure()\n",
    "    chi2 = np.zeros(len(L))\n",
    "    DoF = np.zeros(len(L))\n",
    "    for j in range(1400):\n",
    "        ind = (L > 0 ) *(L < j)\n",
    "        chi2[j] = np.sum(np.power((clt[ind] - cl_[ind])/(clerr_[ind]), 2))\n",
    "        DoF[j] = np.sum(ind)\n",
    "    plt.plot(L, chi2)\n",
    "    plt.plot(L, DoF)\n",
    "    plt.ylabel('$\\chi^2$')\n",
    "    plt.xlabel('L')\n",
    "    plt.ylim(600, 700 )\n",
    "    plt.xlim(600, 700 )\n",
    "    print chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wbinCls(l, cl, err, lbin):\n",
    "    #binned_statistics\n",
    "    Clbin = np.zeros(len(lbin)-1)\n",
    "    Clberr = np.zeros(len(lbin)-1)\n",
    "    lmean = np.zeros(len(lbin)-1)\n",
    "    for i in range(len(lbin)-1):\n",
    "        ind = np.where( (l>=lbin[i])*(l<lbin[i+1]) )[0]\n",
    "        if len(ind)>0:\n",
    "            w = ( 1.0/err[ind] )**2\n",
    "            Clbin[i]  = np.sum(cl[ind]*w)/np.sum(w)\n",
    "            Clberr[i] = np.sqrt(1.0/np.sum(w))\n",
    "            lmean[i]  = np.mean(l[ind])\n",
    "    return Clbin, Clberr, lmean\n",
    "\n",
    "lbin = np.arange(10, 1200, 40)\n",
    "Cl, Clerr, lmean = wbinCls(L1, cl_, clerr_, lbin)\n",
    "Cl_t, Clerr_t, lmean_t = wbinCls(L, clt, np.ones_like(clt), lbin)\n",
    "\n",
    "\n",
    "plt.errorbar(lmean, Cl ,yerr = Clerr, fmt= '--', label='$\\Theta${:}, AS{:}'.format(thetamax, apodizesigma))\n",
    "plt.plot(lmean_t,  Cl_t , label=k1)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "    \n",
    "f = plt.figure()\n",
    "Ls = np.linspace(10, 1200, 15)\n",
    "chi2 = np.zeros(len(Ls))\n",
    "DoF = np.zeros(len(Ls))\n",
    "for j, vl in enumerate(Ls):\n",
    "    ind = (lmean > 40 ) * (lmean < vl)\n",
    "    ind_t = (lmean_t > 40 ) *(lmean_t < vl)\n",
    "    chi2[j] = np.sum(np.power((Cl_t[ind_t] - Cl[ind])/(Clerr[ind]), 2))\n",
    "    DoF[j] = np.sum(ind)\n",
    "plt.plot(Ls, chi2)\n",
    "plt.plot(Ls, DoF)\n",
    "plt.ylabel('$\\chi^2$')\n",
    "plt.xlabel('L')\n",
    "#plt.ylim(100, 1900 )\n",
    "#plt.xlim(100, 1900 )\n",
    "print chi2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cl_t[ind_t] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What is the Cl error compent from Resolution issues</h3>\n",
    "\n",
    "nbar depends on number of k-means cluster, and map resolution. What are good choices of nbar , to motive how many clustes we can have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#part1 get some realistic Class Cl's to play with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for Nside in ['1024']:\n",
    "\n",
    "    nd = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_15.Nside.'+Nside+'.cls.p', 'r'))\n",
    "    d = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_des.15centers.Nside.'+Nside+'.zdist.p', 'r'))\n",
    "\n",
    "    print nd.keys()\n",
    "    print d.keys()\n",
    "\n",
    "\n",
    "    k = d['redshift_dndz'].keys()\n",
    "    z = d['z_bins']\n",
    "\n",
    "    dndz = np.zeros((len(k), len(d['redshift_dndz'][k[0]][0])))\n",
    "    np.shape(dndz)\n",
    "    bias0 = []\n",
    "    bias1 = []\n",
    "    biask = []\n",
    "    for i, k1 in enumerate(k):\n",
    "        dndz[i, :] = d['redshift_dndz'][k1][1]\n",
    "        z = d['redshift_dndz'][k1][0]\n",
    "        bias0.append(1)\n",
    "        bias1.append(0)\n",
    "        biask.append(0)\n",
    "\n",
    "    bias = [bias0, bias1, biask]\n",
    "\n",
    "    #get some class_cl's that we can play with.\n",
    "    l_range, class_res  =  call_class(dndz, bias, file_names=k, z=z)\n",
    "\n",
    "    #part 2, make maps and try to recover input Cls\n",
    "    lmax = 3000\n",
    "    thetamax, apodizesigma =45, 45\n",
    "    #for theta\n",
    "    maskfile = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/total_mask.mice2_15.Nside.'+Nside+'.fits'\n",
    "\n",
    "    mask = hp.read_map(maskfile)    \n",
    "    mask = hp.ud_grade(mask, nside_out=2048, order_in='RING', order_out='RING')\n",
    "    mask = mask > 0\n",
    "    maskfile = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/total_mask.fits'\n",
    "    hp.write_map(maskfile, mask)\n",
    "    \n",
    "    noise = {}\n",
    "    density_map = {}\n",
    "    k = np.array(k)\n",
    "    k = [k[0]]\n",
    "    for i, k1 in enumerate(k):\n",
    "        L = np.arange(len(class_res[k1][k1]))\n",
    "        clt =  class_res[k1][k1] * 2 * math.pi / (L * (L +1))\n",
    "        clt[~np.isfinite(clt)] = 0\n",
    "        #class output = [l(l+1)/2pi] C_l's\n",
    "\n",
    "        f = plt.figure()\n",
    "        #get perfect Cls, without discreetisation\n",
    "        mapt = hp.synfast(clt, 2048)\n",
    "        f1_ = 'temp_map.fits'\n",
    "\n",
    "        if os.path.exists(f1_):\n",
    "            os.remove(f1_)\n",
    "\n",
    "        hp.write_map(f1_, mapt, nest=0)\n",
    "\n",
    "        cl, clerr = call_spice(f1_, f1_, lmax, maskfile, thetamax=thetamax, apodizesigma=apodizesigma)\n",
    "        #(90.0-put[DEC][ind])*math.pi/180.0,put[RA][ind]*math.pi/180.0\n",
    "\n",
    "        L1 = np.arange(len(cl))\n",
    "        cl_1 = cl * 2 * math.pi / (L1 * (L1 +1))\n",
    "        clerr_1 = clerr * 2 * math.pi / (L1 * (L1 +1))\n",
    "        #measured Cl from continuous case\n",
    "        plt.errorbar(L1, cl_1 ,yerr = clerr_1, fmt= '--', label='Continuous')\n",
    "\n",
    "        #measured Cl from dN/dz given by data\n",
    "        plt.plot(L, clt, color=col[i%4], label='From DnDz->Class', linewidth=2)\n",
    "\n",
    "        #get error on Cls, from Poisson discreetisation\n",
    "        nbar = 1\n",
    "        N = 100\n",
    "        print 'nbar',nbar\n",
    "        #noise = average_noise(nbar, mask, lmax, maskfile, N=N, thetamax=thetamax)\n",
    "\n",
    "        for j in range(len(noise)):\n",
    "            L1 = np.arange(len(noise[j]))\n",
    "            cl_ = noise[k1][j] * 2 * math.pi / (L1 * (L1 +1))\n",
    "            #clerr_ = noise[k1][1] * 2 * math.pi / (L1 * (L1 +1))\n",
    "            if j ==0:\n",
    "                plt.plot(L1, cl_,  '--',color='brown', label='Discreet <noise> of @{:}'.format(nbar))\n",
    "            plt.plot(L1, cl_,  '--', color='brown')\n",
    "\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.title(Nside)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.errorbar(L1, cl ,yerr = clerr, fmt= '--', label='Continuous')\n",
    "\n",
    "#measured Cl from dN/dz given by data\n",
    "plt.plot(L, clt * (L * (L +1)) / (2 * math.pi), color=col[i%4], label='From DnDz->Class', linewidth=2)\n",
    "\n",
    "#get error on Cls, from Poisson discreetisation\n",
    "nbar = 1\n",
    "N = 20\n",
    "print 'nbar',nbar\n",
    "#noise = average_noise(nbar, mask, lmax, maskfile, N=N, thetamax=thetamax)\n",
    "\n",
    "L1 = np.arange(len(avg_noise_1nbar))\n",
    "plt.plot(L1, avg_noise_1nbar*0.2 ,  '--',color='brown', label='Discreet <noise> of @{:}'.format(nbar))\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4,1e-1)\n",
    "plt.legend()\n",
    "plt.title(Nside)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "f = plt.figure()\n",
    "Ls = np.linspace(10, 1200, 15)\n",
    "chi2 = np.zeros(len(Ls))\n",
    "DoF = np.zeros(len(Ls))\n",
    "for j, vl in enumerate(Ls):\n",
    "    ind = (lmean > 40 ) * (lmean < vl)\n",
    "    ind_t = (lmean_t > 40 ) *(lmean_t < vl)\n",
    "    chi2[j] = np.sum(np.power((Cl_t[ind_t] - Cl[ind])/(Clerr[ind]), 2))\n",
    "    DoF[j] = np.sum(ind)\n",
    "plt.plot(Ls, chi2)\n",
    "plt.plot(Ls, DoF)\n",
    "plt.ylabel('$\\chi^2$')\n",
    "plt.xlabel('L')\n",
    "#plt.ylim(100, 1900 )\n",
    "#plt.xlim(100, 1900 )\n",
    "print chi2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Measure differences between correlation functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2.42.3Gauss.dndz.cls.p', 'r'))\n",
    "s = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/sim.data.Nfiles_3.dndz.bias.p', 'r'))\n",
    "\n",
    "print d.keys(), s.keys()\n",
    "\n",
    "k = d['redshift_dndz'].keys()\n",
    "\n",
    "dndz = np.zeros((len(k), len(d['redshift_dndz'][k[0]][0])))\n",
    "np.shape(dndz)\n",
    "bias0 = []\n",
    "bias1 = []\n",
    "biask = []\n",
    "for i, k1 in enumerate(k):\n",
    "    dndz[i, :] = d['redshift_dndz'][k1][1]\n",
    "    z = d['redshift_dndz'][k1][0]\n",
    "    bias0.append(1)\n",
    "    bias1.append(0)\n",
    "    biask.append(0)\n",
    "    print k1, ' -- ', d['cls'][k1].keys(), len(d['cls'][k1][k1])\n",
    "                     \n",
    "bias = [bias0, bias1, biask]\n",
    "\n",
    "l_range, class_res  =  call_class(dndz, bias, file_names=k, z=z)\n",
    "\n",
    "\n",
    "for i, k1 in enumerate(k):\n",
    "    #print class_res[k1][k1]\n",
    "    plt.plot(l_range, class_res[k1][k1], label=k1, color=col[i])\n",
    "    plt.plot(np.arange(d['lmax']), d['noise'][k1] + d['cls'][k1][k1][0], '--', color=col[i])\n",
    "    #plt.errorbar(np.arange(d['lmax']), d['cls'][k1][k1][0], yerr=d['cls'][k1][k1][0], fmt='--', color=col[i])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2.42.zdists.dndz.cls.p', 'r'))\n",
    "\n",
    "print d.keys(), s.keys()\n",
    "\n",
    "k = d['redshift_dndz'].keys()\n",
    "\n",
    "mn = 0\n",
    "cnt=-1\n",
    "for i, k1 in enumerate(k):\n",
    "    if d['nbar'][k1] > mn:\n",
    "        mn = d['nbar'][k1] \n",
    "        cnt +=1\n",
    "        plt.plot(np.arange(d['lmax']), d['noise'][k1] *100.0 / d['cls'][k1][k1][0], label=k1 + '{:}'.format(d['nbar'][k1]), color=col[cnt])\n",
    "    #plt.plot(np.arange(d['lmax']), d['noise'][k1], '--', color=col[i])\n",
    "    #plt.errorbar(np.arange(d['lmax']), d['cls'][k1][k1][0], yerr=d['cls'][k1][k1][0], fmt='--', color=col[i])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Sc=1.0\n",
    "fsky = 0.25\n",
    "for i, id1 in enumerate(kid):\n",
    "    if i%3 ==0:\n",
    "        f = plt.figure()\n",
    "    \n",
    "    err = np.sqrt(2.0 / (2 * l_range_truz * (l_range_truz + 1)*fsky)) * class_res_truez[id1][id1]\n",
    "    p_,  p__ = np.array(class_res_truez[id1][id1]) - np.array(err)*Sc, np.array(\n",
    "        class_res_truez[id1][id1]) + np.array(err)*Sc\n",
    "    plt.fill_between(l_range_truz, p_, p__,color=col[i%4], alpha=0.4)\n",
    "\n",
    "    plt.plot(l_range_truz, class_res_truez[id1][id1], label='True-z KMClus{:}'.format(int(id1)),color=col[i%4], alpha=0.7, linewidth=3)\n",
    "    \n",
    "    err = np.sqrt(2.0 / (2 * l_range_bestgmm * (l_range_bestgmm + 1) * fsky)) * class_res_bestgmm[id1][id1]\n",
    "    p_,  p__ = np.array(class_res_bestgmm[id1][id1]) - np.array(err)*Sc, np.array(\n",
    "        class_res_bestgmm[id1][id1]) + np.array(err)*Sc\n",
    "    plt.fill_between(l_range_bestgmm, p_, p__ ,color=col[i%4], alpha=0.4)\n",
    "\n",
    "    plt.plot(l_range_bestgmm, class_res_bestgmm[id1][id1], '--', label='Approx GMM-z',color=col[i%4], alpha=0.7, linewidth=3)\n",
    "    if i %3 == 2:\n",
    "        plt.xlabel('$l$')   \n",
    "        plt.ylabel('$C_l$ [$l(l+1)/2\\pi$]')   \n",
    "        plt.legend(loc = 2)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(pltpath + 'Cls{:}_dndz_KMClus{:}.pdf'.format(num_gmm, int(id1)))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Sc=2.0\n",
    "fsky = 0.25\n",
    "cnt=0\n",
    "ids = [[[0,1], [0,2], [1,2]], [[6,7], [6,8], [7,8]], [[9,10], [9,11], [10,11]], [[12,13], [12,14], [13,14]]]\n",
    "\n",
    "for i, idn in enumerate(ids):\n",
    "    f = plt.figure()\n",
    "    for id1, id2 in idn:\n",
    "       \n",
    "        err = np.sqrt(2.0 / (2 * l_range_truz * (l_range_truz + 1)*fsky)) * class_res_truez[id1][id2]\n",
    "        p_,  p__ = np.array(class_res_truez[id1][id2]) - np.array(err)*Sc, np.array(class_res_truez[id1][id2]) + np.array(err)*Sc\n",
    "        plt.fill_between(l_range_truz, p_, p__,color=col[cnt%4], alpha=0.4)\n",
    "\n",
    "        plt.plot(l_range_truz, class_res_truez[id1][id2], label='True-z KMClus{:} x KMClus{:}'.format(int(id1), int(id2)),color=col[cnt%4], alpha=0.7, linewidth=3)\n",
    "\n",
    "        plt.plot(l_range_bestgmm, class_res_bestgmm[id1][id2], '--', label='Approx GMM-z',color=col[cnt%4], alpha=0.7, linewidth=3)\n",
    "        err = np.sqrt(2.0 / (2 * l_range_bestgmm * (l_range_bestgmm + 1)*fsky)) * class_res_bestgmm[id1][id2]\n",
    "        p_,  p__ = np.array(class_res_bestgmm[id1][id2]) - np.array(err)*Sc, np.array(class_res_bestgmm[id1][id2]) + np.array(err)*Sc\n",
    "        plt.fill_between(l_range_bestgmm, p_, p__ ,color=col[cnt%4], alpha=0.4)\n",
    "        cnt +=1\n",
    "        \n",
    "    plt.xlabel('$l$')   \n",
    "    plt.ylabel('$C_l$ [$l(l+1)/2\\pi$]')   \n",
    "    plt.legend(loc = 2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pltpath + 'Cls{:}_dndz_KMClus{:}x{:}.pdf'.format(num_gmm, int(id1), int(id2)))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PolSpice to measure correlation functions</h2>\n",
    "Measure all NxN correlatoin functions, and save to disk. N.b. this doesn't seem to work in the notebook. Call from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2_des.42centers.zdist.p', 'r'))\n",
    "\n",
    "ids = ['maps/mice2_42_my_map0.fits','maps/mice2_42_my_map1.fits','maps/mice2_42_my_map2.fits']\n",
    "cl = p.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/mice2.42.cls.p'))\n",
    "\n",
    "L = np.arange(cl['lmax'])\n",
    "lbin = np.linspace(0, cl['lmax'], num=50)\n",
    "for i, id1 in enumerate(ids):\n",
    "    if i%3 ==0:\n",
    "        f = plt.figure()\n",
    "\n",
    "    err = cl['cls'][id1][id1][1]*10\n",
    "    cl_ = cl['cls'][id1][id1][0]\n",
    "    \n",
    "    Clbin, Clberr, lmean = wbinCls(L, cl_, err, lbin)\n",
    "    \n",
    "    id1_ = id1.split('.fit')[0].split('my_map')[1]\n",
    "    plt.errorbar(lmean, Clbin, yerr=Clberr, label='KMClus{:}'.format(int(id1_)),color=col[i%4], alpha=0.7, linewidth=3)\n",
    "\n",
    "    if i %3 == 2:\n",
    "        plt.xlabel('$l$')   \n",
    "        plt.ylabel('$C_l$ [$l(l+1)/2\\pi$]')   \n",
    "        plt.legend(loc = 2)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(pltpath + 'Cls_measured_KMClus{:}.pdf'.format(int(id1_)))\n",
    "\n",
    "cnt =0\n",
    "for i, id1 in enumerate(ids):\n",
    "    \n",
    "    for j, id2 in enumerate(ids):\n",
    "        if j>i:\n",
    "            if cnt%3 ==0:\n",
    "                f = plt.figure()\n",
    "\n",
    "        \n",
    "            err = cl['cls'][id1][id2][1]*10\n",
    "            cl_ = cl['cls'][id1][id2][0]\n",
    "            id1_ = id1.split('.fit')[0].split('my_map')[1]\n",
    "            id2_ = id2.split('.fit')[0].split('my_map')[1]\n",
    "            Clbin, Clberr, lmean = wbinCls(L, cl_, err, lbin)\n",
    "            plt.errorbar(lmean, Clbin, yerr=Clberr, label='KMClus{:}x{:}'.format(int(id1_), int(id2_)),color=col[cnt%4], alpha=0.7, linewidth=3)\n",
    "\n",
    "            if cnt %3 == 2:\n",
    "                plt.xlabel('$l$')   \n",
    "                plt.ylabel('$C_l$ [$l(l+1)/2\\pi$]')   \n",
    "                plt.legend(loc = 2)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(pltpath + 'Cls_measured_KMClus{:}x{:}.pdf'.format(int(id1_), int(id2_)))\n",
    "            cnt+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Explore Cl polspice output for different thetamax</h3>\n",
    "--- result we used thetamax =10 in the CC analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = res[15].keys()\n",
    "lbin = np.linspace(0,768, num=150)\n",
    "for f1 in k:\n",
    "    f = plt.figure()\n",
    "    for i, thetamax in enumerate(res):\n",
    "     \n",
    "        l = np.arange(len(res[thetamax][f1][f1][0]))\n",
    "        cl_ = res[thetamax][f1][f1][0]\n",
    "        err = res[thetamax][f1][f1][1]\n",
    "        if np.amax(err) < 10 :\n",
    "            if thetamax>1:\n",
    "                Clbin, Clberr, lmean = wbinCls(l, cl_, err, lbin)\n",
    "                plt.errorbar(lmean+i, Clbin, yerr=Clberr, label = 'thetamax {:}'.format(thetamax))\n",
    "\n",
    "        \n",
    "    err = cl['cls'][f1][f1][1]\n",
    "    cl_ = cl['cls'][f1][f1][0]\n",
    "    L = np.arange(len(cl_))\n",
    "    Clbin, Clberr, lmean = wbinCls(L, cl_, err, lbin)\n",
    "\n",
    "    plt.errorbar(lmean+i, Clbin, yerr=Clberr, label='{:}'.format(f1),color='yellow', alpha=0.7, linewidth=3)    \n",
    "    plt.legend(loc=2)\n",
    "    \n",
    "thetamax = 10\n",
    "f = plt.figure()\n",
    "k = res[15].keys()\n",
    "for i, f1 in enumerate(k):\n",
    "    for j, f2 in enumerate(k):\n",
    "        if j>i:\n",
    "            l = np.arange(len(res[thetamax][f1][f2][0]))\n",
    "            cl_ = res[thetamax][f1][f2][0]\n",
    "            err = res[thetamax][f1][f2][1]\n",
    "\n",
    "            Clbin, Clberr, lmean = wbinCls(l, cl_, err, lbin)\n",
    "            plt.errorbar(lmean+i, Clbin, yerr=Clberr*1.5, label = 'thetamax {:}'.format(thetamax))\n",
    "\n",
    "\n",
    "            err = cl['cls'][f1][f2][1]\n",
    "            cl_ = cl['cls'][f1][f2][0]\n",
    "            L = np.arange(len(cl_))\n",
    "            Clbin, Clberr, lmean = wbinCls(L, cl_, err, lbin)\n",
    "\n",
    "            plt.plot(lmean, Clbin, label='{:}x{:}'.format(f1.split('my_map')[0],f2.split('my_map')[0]), color='yellow', alpha=0.7, linewidth=3)    \n",
    "            plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plot the NxN correlation functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the maps\n",
    "#res_cls = pickle.load(open('maps/cl_maps.p', 'r'))\n",
    "res_cls = pickle.load(open('data/mice2_cls.p', 'r'))\n",
    "print res_cls.keys()\n",
    "\n",
    "print res_cls['cls'].keys()\n",
    "files = res_cls['files']    \n",
    "clusters = np.arange(len(files))                   \n",
    "cnt = 0\n",
    "lin = ['-', '--', '-x', '-o']\n",
    "for i, f1 in enumerate(files):\n",
    "    for j, f2 in enumerate(files):\n",
    "        if j>=i:\n",
    "            if cnt % 6 ==5:\n",
    "                plt.legend()\n",
    "                plt.xlabel('L')\n",
    "                plt.yscale('log')\n",
    "                plt.ylim(1e-2,1e3)\n",
    "                f = plt.figure()\n",
    "\n",
    "            L1 = np.arange(res_cls['lmax'])\n",
    "            plt.plot(L1, res_cls['cls'][f1][f2][0] * L1 * (L1 +1)/ (2 * math.pi), lin[cnt%4], \n",
    "                     label=\"cid: {:}-x-{:}\".format(i, j), linewidth=3, alpha=0.6)\n",
    "            cnt+=1\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('L')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Cl')\n",
    "plt.ylim(1e-2,1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1 = pickle.load(open('maps/mice2_des.42centers.zdist.p', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print r1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bns = r1['z_bins']\n",
    "bns = (bns[1:] + bns[0:-1]) / 2\n",
    "\n",
    "AllDnDz = np.zeros((len(r1['truez_hist']), len(bns)))\n",
    "\n",
    "for vl, i in enumerate(r1['truez_hist']):\n",
    "    plt.plot(bns, r1['truez_hist'][i], label='ClstrID_{:} Num:{:0.1f}M'.format(i, np.sum(r1['truez_hist'][i])*1e-6))\n",
    "    \n",
    "    AllDnDz[vl] = r1['truez_hist'][i]#bns[i] + np.random.normal(size=r1['truez_hist'][i])*bns[0]*0.5\n",
    "    if i % 5 ==4:      \n",
    "        plt.legend()\n",
    "        f = plt.figure()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>SDSS data</h2>\n",
    "Let's perform the same analysis on SDSS data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_data = 'data/SDSSDR12_cleanSpecPhot.fits'\n",
    "\n",
    "#load weighting feature list\n",
    "weight_f_d = ['DERED_U', 'DERED_G', 'DERED_R','DERED_Z','DERED_I','DERED_Z-DERED_I',\n",
    "              'DERED_G-DERED_U','DERED_R-DERED_G']\n",
    "#get training and validation indicies\n",
    "\n",
    "#get data to determine weights\n",
    "inptest_d, put_d = ml.dataSet(obs_data, weight_f_d, ['SPECZ','SPECZ_ERR'] + weight_f_d).loadData()\n",
    "\n",
    "ind = (put_d['SPECZ'] > 0.05)* (put_d['SPECZ_ERR'] < 0.01)\n",
    "\n",
    "for i in put_d:\n",
    "    put_d[i] = put_d[i][ind]\n",
    "\n",
    "inptest_d = inptest_d[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km_clf = km.fit_kmeans(inptest_d, 20)\n",
    "km_id = km_clf.predict(inptest_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, id1 in enumerate(np.unique(km_id)):\n",
    "    ind = km_id==id1\n",
    "    print np.sum(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "km_un = np.unique(km_id)\n",
    "for i, id1 in enumerate(km_un[1:-1]):\n",
    "    ind = np.array(km_id==id1)\n",
    "    ind1 = np.array(km_id==id1-1)\n",
    "    ind2 = np.array(km_id==id1+1)\n",
    "    indne = ind + ind1 + ind2\n",
    "    \n",
    "    rndx = np.random.choice(weight_f_d)\n",
    "    rndy = np.random.choice([j for j in weight_f_d if j != rndx])\n",
    "    \n",
    "    f = plt.figure()\n",
    "    plt.plot(np.array(put_d[rndx][indne ==False]), np.array(put_d[rndy][indne==False]), 'o', label=None, alpha=0.2, rasterized=True)\n",
    "\n",
    "    plt.plot(put_d[rndx][ind1], put_d[rndy][ind1], 'o', label='SDSS KMClus{:}'.format(\n",
    "            int(id1-1)), alpha=0.7, rasterized=True)\n",
    "    plt.plot(put_d[rndx][ind], put_d[rndy][ind], 'o', label='SDSS KMClus{:}'.format(\n",
    "            int(id1)), alpha=0.7, rasterized=True)\n",
    "    plt.plot(put_d[rndx][ind2], put_d[rndy][ind2], 'o', label='SDSS KMClus{:}'.format(\n",
    "            int(id1+1)), alpha=0.7, rasterized=True)\n",
    "    \n",
    "    xl = rndx\n",
    "    y_ = rndy\n",
    "    plt.ylabel(y_)\n",
    "    plt.xlabel(xl)\n",
    "    plt.legend(loc=3)\n",
    "    plt.savefig(pltpath + 'sdss_clus_col{:}.pdf'.format(int(id1)))\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "km_un = np.unique(km_id)\n",
    "from scipy.optimize import minimize\n",
    "cnt = 0\n",
    "lin = ['-', '--', '-x', '-o']\n",
    "col = ['red', 'green','blue', 'orange', 'yellow', 'grey' ]\n",
    "num_gmm = 5\n",
    "gmm_base = [0.1, 0.1, 0.4]\n",
    "for i1 in np.arange(num_gmm - 1):\n",
    "    gmm_base.append(0.1  + (i1 + 1) * 1.1 / num_gmm)\n",
    "    gmm_base.append(0.1)\n",
    "    gmm_base.append(0.4)\n",
    "\n",
    "    \n",
    "#what does the redshift range look like for each K-means cluster?\n",
    "zbins = np.arange(0, 3.5, 0.01)\n",
    "\n",
    "for i, id1 in enumerate(km_un):\n",
    "    ind = km_id==id1\n",
    "    \n",
    "    kde = gss_kde(put_d['SPECZ'][ind]).evaluate(zbins)\n",
    "\n",
    "    res = minimize(dndz_min_func0, gmm_base, method='Nelder-Mead', \n",
    "                   tol=1e-8, args=(num_gmm, zbins,kde))\n",
    "    y = gmm_func(res.x, num_gmm, zbins)\n",
    "    chi2 = dndz_min_func0(res.x, num_gmm, zbins,kde)\n",
    "    \n",
    "    gmms = np.array(res.x)\n",
    "    print np.shape(gmms)\n",
    "    print res['nit'],chi2, gmms[np.arange(num_gmm)*3+2]\n",
    "    \n",
    "    if i% 3 == 0:\n",
    "        f = plt.figure()\n",
    "        \n",
    "    plt.plot(zbins, kde, label='SDSS-z KMClus{:}'.format(int(id1)),color=col[i%4], alpha=0.7, linewidth=3)\n",
    "    plt.plot(zbins, y, '--', label='Approx GMM-z MSE={:0.3f}'.format(chi2),color=col[i%4], alpha=0.7, linewidth=3)\n",
    "    plt.legend()\n",
    "\n",
    "    if i %3 == 2:\n",
    "        plt.xlabel('Redshift')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(pltpath + 'sdss_GMM{:}_dndz_KMClus{:}.pdf'.format(num_gmm, i))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Prepare SDSS data to make heal-pix maps</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Nside same reslution as cmb mask !!!!!\n",
    "Nside = 512  gnu plot st\n",
    "Npixel =hp.nside2npix(Nside)\n",
    "PixSize =4*math.pi*(180*180/(math.pi*math.pi))/Npixel\n",
    "\n",
    "IP    = hp.ang2pix(Nside,(90.0-put_d[DEC_d])*math.pi/180.0,put_d[RA_d]*math.pi/180.0,nest=0)\n",
    "IPMap = np.bincount(IP,minlength=Npixel)\n",
    "f = plt.figure()\n",
    "hp.mollview(IPMap, title=\"All Data\")\n",
    "f = plt.figure()\n",
    "plt.hist(IPMap, bins=np.arange(np.amax(IPMap))+1)\n",
    "\n",
    "#make mask\n",
    "ind1 = IPMap > 0\n",
    "avg, sigma = np.mean(IPMap[ind1]), np.std(IPMap[ind1])\n",
    "\n",
    "mask = IPMap > 0\n",
    "print avg,   sigma\n",
    "\n",
    "hp.mollview(mask, title=\"Mask\")\n",
    "\n",
    "hp.write_map(\"dr12_total_mask.fits\", mask, nest=False)\n",
    "\n",
    "for i in np.unique(clusters_d):\n",
    "    \n",
    "    ind = clusters_d==i\n",
    "    IP    = hp.ang2pix(Nside,(90.0-put_d[DEC_d][ind])*math.pi/180.0,put_d[RA_d][ind]*math.pi/180.0,nest=0)\n",
    "   \n",
    "    IPMap = np.bincount(IP,minlength=Npixel)\n",
    "    mn = np.mean(IPMap[mask])\n",
    "    map_ = (IPMap - mn) / mn\n",
    "    f = plt.figure()\n",
    "    hp.mollview(IPMap, title=\"Cluster ID: {:}\".format(i))\n",
    " \n",
    "    hp.write_map(\"maps/dr12_map\" + str(i) + \".fits\", map_, nest=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zbins = np.arange(0, 4,0.02)\n",
    "zbn = zbins[1:] + zbins[1]/2.0\n",
    "AllDnDz = np.zeros((len(np.unique(clusters_d)), len(zbn)))\n",
    "for i in np.unique(clusters_d):\n",
    "    ind = clusters_d==i\n",
    "    AllDnDz[i, :] = np.histogram(put_d[Z_d][ind], bins = zbins)[0]\n",
    " \n",
    "truth_dndz_file = 'data/dndz_dr12gals.truth.txt'\n",
    "\n",
    "f3 = open(truth_dndz_file, 'w')\n",
    "f3.write( '#zbins ' + ' '.join(['Gal{:}'.format(i) for i in np.unique(clusters_d)]) + \"\\n\")\n",
    "f3.write('0.0 '+ ' '.join(['0.0' for _ in np.unique(clusters_d)]) + \"\\n\")\n",
    "\n",
    "for i in np.arange(len(zbn)):\n",
    "    f3.write(str(zbn[i]) + ' ' + ' '.join([str(j) for j in AllDnDz[:, i]]) + \"\\n\")\n",
    "\n",
    "maxZ = zbn[-1] + zbn[0]\n",
    "f3.write(str(maxZ)+ ' ' + ' '.join(['0.0' for _ in np.unique(clusters_d)]) + \"\\n\")\n",
    "\n",
    "f3.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#read in the cls from the maps\n",
    "res_cls_dr12 = pickle.load(open('maps/dr12_cls.p', 'r'))\n",
    "\n",
    "lmax = 100\n",
    "theory_cls = np.genfromtxt('data/cls_dndz_dr12_cl.dat')\n",
    "N = len(np.unique(clusters))\n",
    "L = theory_cls[0:lmax,0]\n",
    "\n",
    "cnt = 0\n",
    "lin = ['-', '--', '-x', '-o']\n",
    "for i in np.unique(clusters_d):\n",
    "    for j in np.unique(clusters_d):\n",
    "        if j>=i:\n",
    "            if cnt % 6 ==5:\n",
    "                plt.legend()\n",
    "                plt.xlabel('L')\n",
    "                plt.yscale('log')\n",
    "                f = plt.figure()\n",
    "            f1 = \"maps/dr12_map\" + str(i) + \".fits\"\n",
    "            f2 = \"maps/dr12_map\" + str(j) + \".fits\"\n",
    "            L1 = np.arange(len(res_cls_dr12['cls'][f1][f2]))\n",
    " \n",
    "            cl_data = binned_statistic(L1 , res_cls_dr12['cls'][f1][f2] * L1 * (L1 + 1)/ (2 * math.pi), bins=25)\n",
    "            plt.plot(cl_data[1][1:] - cl_data[1][1]/2.0 , cl_data[0], 'o', \n",
    "                     label=\"cid: {:}-x-{:}\".format(i, j), color=col[cnt%5], alpha=0.4)\n",
    "            \n",
    "            cnt+=1\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('L')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Cl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h2>Get measured correlation functions in suitable format</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cPickle as pickle\n",
    "import healpy as hp\n",
    "import math\n",
    "import numpy as np\n",
    "import spice\n",
    "import sys\n",
    "import astropy.io.fits  as pyfits\n",
    "\n",
    "def wbinCls(l, cl, err, lbin):\n",
    "  #binned_statistics\n",
    "  Clbin = np.zeros(len(lbin) - 1)\n",
    "  Clberr = np.zeros(len(lbin) - 1)\n",
    "  lmean = np.zeros(len(lbin) - 1)\n",
    "  for i in range(len(lbin) - 1):\n",
    "    ind = np.where( (l >= lbin[i]) * (l < lbin[i + 1]) )[0]\n",
    "    if len(ind) > 0:\n",
    "      w = ( 1.0 / err[ind] ) ** 2\n",
    "      Clbin[i]  = np.sum(cl[ind] * w) / np.sum(w)\n",
    "      Clberr[i] = np.sqrt(1.0 / np.sum(w))\n",
    "      lmean[i]  = np.mean(l[ind])\n",
    "  return Clbin,Clberr,lmean\n",
    "\n",
    "#f1_ = 'data/NumPerPixel_SDSS8-0109gals_ring_Nside512.fit'\n",
    "#f2_ = 'data/NumPerPixel_SDSS8-0109gals_ring_Nside512.fit' \n",
    "lmax = 700 \n",
    "maskfile = 'total_mask.fits'\n",
    "\n",
    "use_weights=True\n",
    "beam=\"NO\"\n",
    "pixelfile='YES'\n",
    "weightfile='NO'\n",
    "thetamax = \"NO\"\n",
    "apodizesigma=thetamax\n",
    "covfileout=\"YES\"\n",
    "\n",
    "f1_ = 'temp_file1.fits'\n",
    "f2_  = 'temp_file2.fits'\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for thetamax in [5, 10, 12]:\n",
    "    apodizesigma = thetamax\n",
    "    cl = spice.spice(bin=False, norm=False, mapfile=f1_,\n",
    "            mapfile2=f2_, nlmax=lmax, polarization=\"NO\", beam_file=\"NO\",\n",
    "            beam_file2=\"NO\", pixelfile=pixelfile, weightfile=weightfile,\n",
    "            apodizesigma=apodizesigma, thetamax=thetamax, covfileout=covfileout,\n",
    "            maskfile2=maskfile, maskfile=maskfile)\n",
    "    cls = np.array(cl['TT'])\n",
    "    L = np.arange(len(cls))\n",
    "    cls = cls * L * (L + 1) / (2 * math.pi)\n",
    "    \n",
    "    covF = pyfits.open('spice.covariance.fits')\n",
    "    cov  = covF[0].data[0]\n",
    "    di   = np.diag_indices(len(cov))\n",
    "    err_s = np.sqrt(cov[di])[1:lmax+1]\n",
    "    err_s = err_s * L * (L + 1) / (2 * math.pi)\n",
    "    Clbin, Clberr, lmean = wbinCls(L, cls, err_s, np.arange(100)*50)\n",
    "    plt.plot(lmean, Clbin, label='$\\Theta$: {:}'.format(thetamax))\n",
    "\n",
    "    \n",
    "theory_d1 = np.genfromtxt('/Users/hoyleb/Documents/science/clusters_x_lss/hoyleb/powerspectra/data/g1c5c20_cl.dat')\n",
    "\n",
    "L = theory_d1[0:700, 0]\n",
    "plt.plot(L, theory_d1[0:700, 2]*1.1,'-', label='theory')\n",
    "plt.ylim(1e-3,1e-1)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#choose some [2/3] maps that are 'easier' to model.\n",
    "res = p.load(open('data/mice2.42.cls.p'))\n",
    "resz = p.load(open('data/mice2_des.42centers.zdist.p'))\n",
    "\n",
    "files = np.array(res['files'])\n",
    "\n",
    "res1 = copy.deepcopy(res)\n",
    "\n",
    "res1['files'] = files\n",
    "\n",
    "    \n",
    "res1['zbins'] = resz['z_bins']\n",
    "res1['truez_hist'] = {}\n",
    "for i, fil in enumerate(files):\n",
    "    res1['truez_hist'][fil] = resz['truez_hist'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.dump(res1, open('data/mice2.42.zdists.cls.p','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resz = p.load(open('data/mice2_des.42centers.zdist.p'))\n",
    "print resz.keys()\n",
    "print len(resz['z_bins'])\n",
    "print len(resz['truez_hist'])\n",
    "\n",
    "for i in [40, 31 ,19]: #resz['photoz_hist'].keys(): #[40, 31 ,19]:\n",
    "    if i % 4==0:\n",
    "        f = plt.figure()\n",
    "        plt.xlabel('redshift')\n",
    "        \n",
    "    plt.plot(resz['z_bins'][1:] -resz['z_bins'][1]/2.0 , resz['truez_hist'][i], label='{:}'.format(i))\n",
    "    plt.legend()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nice_gauss = [40, 31 ,19]\n",
    "files = np.array(res['files'])[nice_gauss]\n",
    "\n",
    "res1 = copy.deepcopy(res)\n",
    "\n",
    "res1['files'] = files\n",
    "\n",
    "for i in ['noise', 'nbar']:\n",
    "    for j in res[i].keys():\n",
    "        if j not in files:\n",
    "            del res1[i][j]\n",
    "            \n",
    "for i in res['cls'].keys():\n",
    "    if i not in files:\n",
    "        del res1['cls'][i]\n",
    "    else:\n",
    "        for j in  res['cls'][i].keys():\n",
    "            \n",
    "            if j not in files:\n",
    "                del res1['cls'][i][j]\n",
    "\n",
    "res1['zbins'] = resz['z_bins']\n",
    "res1['truez_hist'] = {}\n",
    "for i, fil in enumerate(files):\n",
    "    res1['truez_hist'][fil] = resz['truez_hist'][nice_gauss[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print files\n",
    "for i in res1['cls'].keys():\n",
    "    print i, res1['cls'][i].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "p.dump(res1, open('data/mice2.42.3Gauss.cls.p', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Compare pure theory and parameter space exploration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dist_from_dndz(dndz, z):\n",
    "    arr = np.array(0)\n",
    "    for i, val in enumerate(dndz):\n",
    "        if val >0:\n",
    "            arr = np.append(arr, np.array( [z[i]] * int(val*0.1)))\n",
    "    arr = np.ravel(arr)\n",
    "    arr = arr + (np.random.uniform(size=len(arr))-0.5)*(z[1]-z[0])/2.0\n",
    "    return arr\n",
    "    \n",
    "path = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/'\n",
    "\n",
    "dfiles = [[path + 'sim_data/sim.data.Nfiles_3.p',  path + 'sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_3.p'],\n",
    "        [path + 'sim_data/sim.data.Nfiles_3.p', path + 'sim_data/chain.hybrid_mcmc_.n_gmm.5.sim.data.Nfiles_3.p'],\n",
    "          [path + 'sim_data/sim.data.Nfiles_20.p', path + 'sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_20.p'],\n",
    "         [path + 'data/mice2.42.3Gauss.cls.p', path + 'data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.3Gauss.cls.p'],\n",
    "         [path + 'data/mice2.42.zdists.cls.p', path + 'data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.cls.p']\n",
    "          ]\n",
    "z = np.arange(200) / 100.0\n",
    "redshift = (z[1:] + z[0:-1]) / 2.0\n",
    "\n",
    "for df, cf in dfiles:\n",
    "    r = p.load(open(cf, 'r'))\n",
    "    print cf\n",
    "    print r['hybrid_nsteps'], r['hybrid_converged'], r['hybrid_best_chi2']\n",
    "    \n",
    "sys.exit()\n",
    "\n",
    "for df, cf in dfiles:\n",
    "    f = plt.figure()\n",
    "    d = p.load(open(df, 'r'))\n",
    "    r = p.load(open(cf, 'r'))\n",
    "    \n",
    "    print cf\n",
    "\n",
    "    num_gmm = r['info']['num_gmm']\n",
    "\n",
    "    if 'example_params' in d:\n",
    "        true_z_dndz = d['truez_hist']\n",
    "    else:\n",
    "        true_z_dndz = np.zeros_like([d['truez_hist'][i] for i in d['truez_hist']])\n",
    "        rd = d['zbins']\n",
    "        zz = (rd[1:] + rd[0:-1])/2.0\n",
    "        for i, ky in  enumerate(d['truez_hist'].keys()):\n",
    "            arr = dist_from_dndz(d['truez_hist'][ky], zz)\n",
    "            true_z_dndz[i] = gss_kde(arr).evaluate(redshift)\n",
    "        \n",
    "    best_dndz_ = np.zeros_like(true_z_dndz)\n",
    "    \n",
    "    n_params = len(r['hybrid_best_position']) / len(r['cls'].keys())\n",
    "    print n_params\n",
    "    \n",
    "    b0_ = []\n",
    "    b1_ = []\n",
    "    bk_ = []\n",
    "    for i, ky in enumerate(r['cls'].keys()):\n",
    "        #[bias_base + gmm_base]\n",
    "        bias_gmm = np.array(r['hybrid_best_position'])[i * n_params: (i + 1) * n_params]\n",
    "        b0_.append(bias_gmm[0])\n",
    "        b1_.append(bias_gmm[1])\n",
    "        bk_.append(bias_gmm[2])\n",
    "        \n",
    "        best_dndz_[i, :] = gmm_func(bias_gmm[3:], num_gmm, redshift)\n",
    "\n",
    "        plt.plot(redshift, best_dndz_[i, :], '-', color=col[i%5], label='{:}'.format(ky))\n",
    "    \n",
    "        plt.plot(redshift, true_z_dndz[i, :], '--', color=col[i%5])\n",
    "    \n",
    "    plt.xlabel('Redshift')\n",
    "    plt.title('NGMM: ' + cf.split('/')[-1].split('.cls')[0].split('hybrid_mcmc_.n_gmm.')[1] +'$ \\chi^2={:0.3}$'.format(r['hybrid_best_chi2']*0.5))\n",
    "    plt.legend()\n",
    "    if 'example_params' in d:\n",
    "        print 'b_0'\n",
    "        print b0_ \n",
    "        print d['example_params']['selection_bias0_arr'].split(',')\n",
    "        print 'b_1'\n",
    "        print b1_\n",
    "        print d['example_params']['selection_bias1_arr'].split(',')\n",
    "        print 'b_k'\n",
    "        print bk_\n",
    "        print d['example_params']['selection_biask_arr'].split(',')\n",
    "\n",
    "\"\"\"Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_3.p\n",
    "48 True 583697.674459\n",
    "122 True 564248.774773\n",
    "649 True 453174.025\n",
    "775 True 449425.537725\n",
    "955 True 417025.764758\n",
    "1177 True 414227.04326\n",
    "1819 True 397993.897263\n",
    "1951 True 397993.897263\n",
    "2077 True 397993.897263\n",
    "2863 True 396567.645623\n",
    "4081 True 392610.171229\n",
    "5551 True 392610.171229\n",
    "6223 True 392610.171229\n",
    "\n",
    "114 True 368897.580447\n",
    "162 True 368897.580447\n",
    "258 True 368897.580447\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.5.sim.data.Nfiles_3.p\n",
    "6 True 606333.360065\n",
    "40 True 494822.307116\n",
    "108 True 460102.154785\n",
    "132 True 460102.154785\n",
    "168 True 460102.154785\n",
    "204 True 460102.154785\n",
    "324 True 459730.411377\n",
    "330 True 459730.411377\n",
    "354 True 459730.411377\n",
    "378 True 459730.411377\n",
    "534 True 455216.23645\n",
    "774 True 446636.856383\n",
    "1068 True 445220.413953\n",
    "1206 True 445220.413953\n",
    "\n",
    "36 True 436999.516754\n",
    "54 True 436999.516754\n",
    "90 True 436999.516754\n",
    "96 True 436999.516754\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_20.p\n",
    "6 True 2.78173670304e+12\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.3Gauss.cls.p\n",
    "6 True 479009.428125\n",
    "18 True 418442.338683\n",
    "96 True 202342.388142\n",
    "120 True 174191.771013\n",
    "150 True 174191.771013\n",
    "192 True 171261.464873\n",
    "306 True 156304.763777\n",
    "336 True 117291.389972\n",
    "360 True 117291.389972\n",
    "522 True 116253.286451\n",
    "774 True 93539.3675498\n",
    "1086 True 45849.4602343\n",
    "1236 True 45849.4602343\n",
    "1272 True 45849.4602343\n",
    "1290 True 45849.4602343\n",
    "1320 True 45849.4602343\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.cls.p\n",
    "14 True 589968370.484\n",
    "22 True 589968370.484\n",
    "30 True 589968370.484\n",
    "38 True 589968370.484\n",
    "44 True 439368643.835\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dist_from_dndz(dndz, z):\n",
    "    arr = np.array(0)\n",
    "    for i, val in enumerate(dndz):\n",
    "        if val >0:\n",
    "            arr = np.append(arr, np.array( [z[i]] * int(val*0.1)))\n",
    "    arr = np.ravel(arr)\n",
    "    arr = arr + (np.random.uniform(size=len(arr))-0.5)*(z[1]-z[0])/2.0\n",
    "    return arr\n",
    "    \n",
    "path = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/'\n",
    "\n",
    "dfiles = [[path + 'sim_data/sim.data.Nfiles_3.p',  path + 'sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_3.p_mcmc.p'],\n",
    "         [path + 'sim_data/sim.data.Nfiles_3.p', path + 'sim_data/chain.hybrid_mcmc_.n_gmm.5.sim.data.Nfiles_3.p_mcmc.p'],\n",
    "          [path + 'sim_data/sim.data.Nfiles_20.p', path + 'sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_20.p_mcmc.p'],\n",
    "         [path + 'data/mice2.42.3Gauss.cls.p', path + 'data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.3Gauss.cls.p_mcmc.p'],\n",
    "         [path + 'data/mice2.42.zdists.cls.p', path + 'data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.cls.p_mcmc.p']\n",
    "          ]\n",
    "z = np.arange(200) / 100.0\n",
    "redshift = (z[1:] + z[0:-1]) / 2.0\n",
    "\n",
    "for df, cf in dfiles:\n",
    "    print cf\n",
    "    r = p.load(open(cf, 'r'))\n",
    "    print 'after hybrid'\n",
    "    print r['hybrid_nsteps'], r['hybrid_best_chi2']\n",
    "    \n",
    "    pos  = r['chains'][2][0][0]\n",
    "    max_fom = np.amax(r['chains'][2][1][0])\n",
    "    for i in np.arange(len(r['chains']) -2) +2:\n",
    "        if np.amax(r['chains'][i][1]) > max_fom:\n",
    "            ind_max = np.argmax(r['chains'][i][1])\n",
    "            max_fom = r['chains'][i][1][ind_max]\n",
    "            pos = copy.copy(r['chains'][i][0][ind_max])\n",
    "\n",
    "    print 'after emcee'\n",
    "    print (len(r['chains'])-2) * len(r['chains'][1]), max_fom  * (-2.0)\n",
    "\n",
    "sys.exit()\n",
    "\n",
    "for df, cf in dfiles:\n",
    "    f = plt.figure()\n",
    "    d = p.load(open(df, 'r'))\n",
    "    r = p.load(open(cf, 'r'))\n",
    "    \n",
    "    print cf\n",
    "\n",
    "    pos  = r['chains'][0]\n",
    "    max_fom = np.amax(r['chains'][1])\n",
    "    for i in np.arange(len(r['chains']) -2) +2:\n",
    "        if np.amax(r['chains'][i][1]) > max_fom:\n",
    "            ind_max = np.argmax(r['chains'][i][1])\n",
    "            max_fom = r['chains'][i][1][ind_max]\n",
    "            pos = copy.copy(r['chains'][i][0][ind_max])\n",
    "            \n",
    "    num_gmm = r['info']['num_gmm']\n",
    "\n",
    "    if 'example_params' in d:\n",
    "        true_z_dndz = d['truez_hist']\n",
    "    else:\n",
    "        true_z_dndz = np.zeros_like([d['truez_hist'][i] for i in d['truez_hist']])\n",
    "        rd = d['zbins']\n",
    "        zz = (rd[1:] + rd[0:-1])/2.0\n",
    "        for i, ky in  enumerate(d['truez_hist'].keys()):\n",
    "            arr = dist_from_dndz(d['truez_hist'][ky], zz)\n",
    "            true_z_dndz[i] = gss_kde(arr).evaluate(redshift)\n",
    "        \n",
    "    best_dndz_ = np.zeros_like(true_z_dndz)\n",
    "    \n",
    "    n_params = len(pos) / len(r['cls'].keys())\n",
    "\n",
    "    b0_ = []\n",
    "    b1_ = []\n",
    "    bk_ = []\n",
    "\n",
    "    for i, ky in enumerate(r['cls'].keys()):\n",
    "        #[bias_base + gmm_base]\n",
    "        bias_gmm = np.array(pos)[i * n_params: (i + 1) * n_params]\n",
    "        b0_.append(bias_gmm[0])\n",
    "        b1_.append(bias_gmm[1])\n",
    "        bk_.append(bias_gmm[2])\n",
    "        best_dndz_[i, :] = gmm_func(bias_gmm[3:], num_gmm, redshift)\n",
    "\n",
    "        plt.plot(redshift, best_dndz_[i, :], '-', color=col[i%5], label='{:}'.format(ky))\n",
    "    \n",
    "        plt.plot(redshift, true_z_dndz[i, :], '--', color=col[i%5])\n",
    "    \n",
    "    plt.xlabel('Redshift')\n",
    "    plt.title('NGMM: ' + cf.split('/')[-1].split('.cls')[0].split('hybrid_mcmc_.n_gmm.')[1] +'$ \\chi^2={:0.3}$'.format(r['hybrid_best_chi2']*0.5))\n",
    "    plt.legend()\n",
    "    if 'example_params' in d:\n",
    "        print 'b_0'\n",
    "        print b0_ \n",
    "        print d['example_params']['selection_bias0_arr'].split(',')\n",
    "        print 'b_1'\n",
    "        print b1_\n",
    "        print d['example_params']['selection_bias1_arr'].split(',')\n",
    "        print 'b_k'\n",
    "        print bk_\n",
    "        print d['example_params']['selection_biask_arr'].split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_3.p\n",
    "6223 True 392610.171229\n",
    "258 True 368897.580447\n",
    "\n",
    "228384 216094.25869\n",
    "348480 199851.154483\n",
    "397152 75719.4025837\n",
    "516672 5994.94508714\n",
    "883008 5207.92605292\n",
    "1053792 5155.74094717\n",
    "1086624 5154.4703073\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.5.sim.data.Nfiles_3.p\n",
    "1206 True 445220.413953\n",
    "96 436999.516754\n",
    "\n",
    "195264 380760.949171\n",
    "310176 328073.804065\n",
    "366336 303081.31618\n",
    "525312 156648.668812\n",
    "918432 18681.6373234\n",
    "1092096 14299.8113503\n",
    "1124928 14084.9092059\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_20.p\n",
    "6 True 2.78173670304e+12\n",
    "\n",
    "24960 1.83649300131e+12\n",
    "32640 1.48029859976e+12\n",
    "55680 1.34189632797e+12\n",
    "65280 1.28793410069e+12\n",
    "94080 886840241182.0\n",
    "172800 335143986807.0\n",
    "211200 210966537114.0\n",
    "220800 200758132322.0\n",
    " \n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.3Gauss.cls.p\n",
    "1320 True 45849.4602343\n",
    "\n",
    "154656 23979.0286201\n",
    "195264 23143.9695999\n",
    "304992 21660.4795206\n",
    "355104 21041.3322786\n",
    "500256 20003.631461\n",
    "900288 17985.2143248\n",
    "1073952 17503.5324058\n",
    "1105920 17283.4830116\n",
    "\n",
    "/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/data/chain.hybrid_mcmc_.n_gmm.5.mice2.42.cls.p\n",
    "14 True 589968370.484\n",
    "22 True 589968370.484\n",
    "38    589968370.484\n",
    "after emcee\n",
    "12096 579257217.414\n",
    "48384 549364116.47\n",
    "60480 549364116.47\n",
    "60480 549364116.47\n",
    "72576 544678235.073\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob \n",
    "pth = '/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/'\n",
    "for cf in glob.glob(pth + '/data/*fix*.p') + glob.glob(pth + '/sim_data/*fix*.p'):\n",
    "\n",
    "    path_ = '/'.join([k for k in cf.split('/')[0:-1]]) + '/'\n",
    "    if 'fix_redshift' in cf:\n",
    "        df =  path_ + cf.split('fix_redshift.')[1].replace('_mcmc.p', '')\n",
    "    elif 'bias_fixed' in cf:\n",
    "        df =  path_ + cf.split('bias_fixed.')[1].replace('_mcmc.p', '')\n",
    "\n",
    "    z = np.arange(200) / 100.0\n",
    "    redshift = (z[1:] + z[0:-1]) / 2.0\n",
    "\n",
    "    print cf\n",
    "    #print df\n",
    "    r = p.load(open(cf, 'r'))\n",
    "    r1 = p.load(open(df, 'r'))\n",
    "    print 'after hybrid'\n",
    "    print r['hybrid_nsteps'], r['hybrid_best_chi2']\n",
    "    \n",
    "    pos =  r['hybrid_best_position']\n",
    "    if 'chains' in r:\n",
    "        if len(r['chains']) > 2:\n",
    "            pos  = r['chains'][0][0]\n",
    "            max_fom = np.amax(r['chains'][0][1])\n",
    "            for i in np.arange(len(r['chains']) -2) +2:\n",
    "                if np.amax(r['chains'][i][1]) > max_fom:\n",
    "                    ind_max = np.argmax(r['chains'][i][1])\n",
    "                    max_fom = r['chains'][i][1][ind_max]\n",
    "                    pos = copy.copy(r['chains'][i][0][ind_max])\n",
    "                    max_i = i\n",
    "                    \n",
    "            print 'after emcee'\n",
    "            print (len(r['chains'])-2) * len(r['chains'][1]), max_fom  * (-2.0)\n",
    "    \n",
    "    if 'fix_redshift' in r['info']:\n",
    "        for cnt, ii in enumerate(r['cls'].keys()):\n",
    "            bias_params = pos[cnt *3: (cnt+1)*3]\n",
    "            print ii, '\\nbias params', bias_params\n",
    "\n",
    "            if 'fix_bias' in r1:\n",
    "                print 'truth bias', r1['fix_bias'][ii]\n",
    "\n",
    "    if 'fix_bias' in r['info']:\n",
    "        if 'redshift_dndz' in r1:\n",
    "            f = plt.figure()\n",
    "            plt.title(cf.split('/')[-1])\n",
    "            \n",
    "        print 'redshift params'\n",
    "        for cnt, ii in enumerate(r['cls'].keys()):\n",
    "            z_params = pos[cnt *r['info']['num_gmm']*3 : (cnt+1)*r['info']['num_gmm']*3 ]\n",
    "            #print ii, pos[cnt *r['info']['num_gmm']*3 : (cnt+1)*r['info']['num_gmm']*3 ]\n",
    "            \n",
    "            if 'redshift_dndz' in r1:\n",
    "                z = r1['redshift_dndz'][ii][0]\n",
    "                dndz = r1['redshift_dndz'][ii][1]\n",
    "                #print 'truth redshift', get_gmm_params(z, dndz, r['info']['num_gmm'])\n",
    "                \n",
    "                pred_z = gmm_func(z, z_params, r['info']['num_gmm'])\n",
    "                plt.plot(z, dndz, label=ii, color=col[cnt%4], alpha=0.5, linewidth=3)\n",
    "                plt.plot(z,pred_z, '--', label='Best Guess',color=col[cnt%4], alpha=0.5, linewidth=3)\n",
    "                plt.legend()\n",
    "                plt.xlabel('Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def gmm_func(x, params_, n_gmm):\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    for i in range(n_gmm):\n",
    "        ctr, wid, amp = params_[i * 3: (i + 1) * 3]\n",
    "        y += amp * np.exp(-1.0 * ((x - ctr) / wid) ** 2)\n",
    "\n",
    "    norm = np.trapz(y, x)\n",
    "\n",
    "    y = y / norm\n",
    "    y[y < 1e-10] = 0\n",
    "    return y\n",
    "\n",
    "\n",
    "#if we wanna optimise the z-distribution for number of GMMs\n",
    "def dndz_min_func0(params_, n_gmm, x, y_true):\n",
    "    y = gmm_func(x, params_, n_gmm)\n",
    "    return np.mean(np.abs((y_true - y)**2))\n",
    "\n",
    "\n",
    "def get_gmm_params(z, dndz, num_gmm):\n",
    "    from scipy.optimize import minimize\n",
    "    gmm_base = [0.1, 0.1, 0.5]\n",
    "    for i1 in np.arange(num_gmm - 1):\n",
    "        gmm_base.append(0.1 + (i1 + 1) * 1.1 / num_gmm)\n",
    "        gmm_base.append(0.1)\n",
    "        gmm_base.append(0.5)\n",
    "\n",
    "    res = minimize(dndz_min_func0, gmm_base, method='Nelder-Mead',\n",
    "                   tol=1e-8, args=(num_gmm, z, dndz))\n",
    "\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1['fix_bias']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = pickle.load(open(\n",
    "'/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/chain.hybrid_mcmc_.n_gmm.1.sim.data.Nfiles_3.p_mcmc.p', \n",
    "'r'))\n",
    "pos  = res['chains'][0]\n",
    "max_fom = np.amax(res['chains'][1])\n",
    "\n",
    "for i in np.arange(len(res['chains']) -2) +2:\n",
    "    if np.amax(res['chains'][i][1]) > max_fom:\n",
    "        pos = copy.copy(res['chains'][i][0])\n",
    "        max_fom = np.amax(res['chains'][i][1]) \n",
    "        print i, np.amax(res['chains'][i][1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_gmm_params(z, dndz, num_gmm):\n",
    "    from scipy.optimize import minimize\n",
    "    gmm_base = [0.1, 0.1, 0.5]\n",
    "    for i1 in np.arange(num_gmm - 1):\n",
    "        gmm_base.append(0.1 + (i1 + 1) * 1.1 / num_gmm)\n",
    "        gmm_base.append(0.1)\n",
    "        gmm_base.append(0.5)\n",
    "\n",
    "    res = minimize(dndz_min_func0_, gmm_base, method='Nelder-Mead',\n",
    "                   tol=1e-12, args=(num_gmm, z, dndz))\n",
    "\n",
    "    return np.array(res.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gmm_func_(x, params_, n_gmm):\n",
    "    y = np.zeros_like(x)\n",
    "    \n",
    "    for i in range(n_gmm):\n",
    "        ctr, wid, amp = params_[i * 3: (i + 1) * 3]\n",
    "        y += amp * np.exp(-1.0 * ((x - ctr) / wid) ** 2)\n",
    "    norm = np.trapz(y, x=x)\n",
    "    y = y / norm\n",
    "    y[y < 1e-10] = 0\n",
    "    return y\n",
    "\n",
    "#if we wanna optimise the z-distribution for number of GMMs\n",
    "def dndz_min_func0_(params_, n_gmm, x, y_true):\n",
    "    y = gmm_func_(x, params_, n_gmm)\n",
    "    return np.mean(np.abs((y_true - y)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfiles = [#path + 'data/mice2.42.3Gauss.cls.p', \n",
    "          #path + 'data/mice2.42.zdists.cls.p',\n",
    "         path + '/data/mice2_des.15centers.zdist.p']\n",
    "\n",
    "num_gmm = 5\n",
    "\n",
    "for i in dfiles:\n",
    "    r = pickle.load(open(i, 'r'))\n",
    "    r['zbins'] = np.arange(200, dtype=float) / 100.0\n",
    "    files = r['files']\n",
    "    z = (r['zbins'][1:] + r['zbins'][0:-1])/2\n",
    "    ind = z < 5\n",
    "    \n",
    "    r['redshift_dndz'] = {}\n",
    "    for j, fil in enumerate(files):\n",
    "        \n",
    "        norm = np.trapz(r['truez_hist'][fil][ind], x=z[ind])\n",
    "        r['redshift_dndz'][fil] = [z, r['truez_hist'][fil][ind]/norm]\n",
    "\n",
    "        p_gmm = get_gmm_params(z[ind], r['truez_hist'][fil][ind]/norm, num_gmm)\n",
    "        \n",
    "        y = gmm_func_(z, p_gmm, num_gmm)\n",
    "        \n",
    "        for k in range(num_gmm):\n",
    "\n",
    "            ctr, wid, amp = p_gmm[k*3:(k+1)*3]\n",
    "            if ctr > 5 or ctr < -0.2:\n",
    "                print fil, 'ctr', ctr\n",
    "            if wid < -2:\n",
    "                print fil, 'wid', wid\n",
    "            if amp < -6 or amp > 6:\n",
    "                print fil, 'amp', amp\n",
    "                \n",
    "        if j==1000:\n",
    "            #f =plt.figure()\n",
    "            plt.plot(z , r['truez_hist'][fil]/norm ,label=fil, color=col[j%5])\n",
    "            plt.plot(z, y, '--', color=col[j%5])\n",
    "            plt.legend()\n",
    "    \n",
    "    #pickle.dump(r, open(i.split('cls.')[0] + 'dndz.cls.p', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = p.load(open('data/mice2.15.cls.p'))\n",
    "files = np.array(res['files'])\n",
    "\n",
    "for i, fil in enumerate(files):\n",
    "    print i, fil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfiles = [path + 'sim_data/sim.data.Nfiles_3.p',\n",
    "          path + 'sim_data/sim.data.Nfiles_20.p']\n",
    "\n",
    "dndz = np.genfromtxt(path + 'sim_data/sim.data.Nfiles_20.dndz.txt')\n",
    "\n",
    "num_gmm = 1\n",
    "for i in dfiles:\n",
    "    r = pickle.load(open(i, 'r'))\n",
    "    files  = r['files']\n",
    "    \n",
    "    r['redshift_dndz'] = {}  \n",
    "    r['fix_bias'] = {}\n",
    "    z = dndz[:, 0]\n",
    "    params = r['example_params']\n",
    "    \n",
    "    bias0 = [float(j) for j in params['selection_bias0_arr'].split(',')]\n",
    "    bias1 = [float(j) for j in params['selection_bias1_arr'].split(',')]\n",
    "    biask = [float(j) for j in params['selection_biask_arr'].split(',')]        \n",
    "            \n",
    "    for j, fil in enumerate(files):\n",
    "        norm = np.trapz(dndz[:, j + 1], x=z)\n",
    "        r['redshift_dndz'][fil] = [z, dndz[:, j + 1]/norm]\n",
    "        r['fix_bias'][fil] = np.array([bias0[j], bias1[j], biask[j]])\n",
    "        \n",
    "        p_gmm = get_gmm_params(z, dndz[:, j + 1]/norm, num_gmm)\n",
    "        for k in range(num_gmm):\n",
    "            ctr, wid, amp = p_gmm[k*3:(k+1)*3]\n",
    "            if ctr > 5 or ctr < -0.3:\n",
    "                print fil, 'ctr', ctr\n",
    "            if wid < -2:\n",
    "                print fil, 'wid', wid\n",
    "            if amp < -6 or amp > 6:\n",
    "                print fil, 'amp', amp\n",
    "        \n",
    "        y = gmm_func_(z, p_gmm, num_gmm)\n",
    "        \n",
    "        \n",
    "        #if j %4 ==0:\n",
    "        #    f =plt.figure()\n",
    "        #plt.plot(z , dndz[:, j + 1]/norm ,'--',label=fil, color=col[j%4],linewidth=3)\n",
    "        #plt.plot(z, y, 'o-', color=col[j%4],linewidth=1)\n",
    "        #plt.legend()\n",
    "    #apickle.dump(r, open(i[0:-1] + 'dndz.bias.p', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = pickle.load(open('/Users/hoyleb/Documents/science/PHOTOZ_CROSSCORR/sim_data/sim.data.Nfiles_20.dndz.bias.p', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(r['redshift_dndz']['file_10'][0], r['redshift_dndz']['file_10'][1])\n",
    "num_gmm = 5\n",
    "p_gmm = get_gmm_params(r['redshift_dndz']['file_10'][0], r['redshift_dndz']['file_10'][1], num_gmm)\n",
    "y = gmm_func_(r['redshift_dndz']['file_10'][0], p_gmm, num_gmm)\n",
    "plt.plot(r['redshift_dndz']['file_10'][0], y, '--')\n",
    "\n",
    "print p_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
