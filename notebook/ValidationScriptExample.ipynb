{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Example validation script</h1>\n",
    "<p>In this notebook we walk you through the steps of validating your point predictions and pdfs. We will use the same codes that will be used in the final validation stage. </p>\n",
    "<p>First, ensure that your repo is up to date, by running this command</p>\n",
    "<code>cd /path/to/photoz-wg/</code>\n",
    "\n",
    "Followed by \n",
    "\n",
    "<code>git pull</code>\n",
    "\n",
    "<h3>The validation script</h3>\n",
    "<p>The validation script is found in the validation directory. You may ignore this notebook, and call the validation script directly from the directory (or anywhere if you add the directory to your path variable). This will instantly check that your file is well formed, and then perform all the standard tests, and output the scores.</p>\n",
    "\n",
    "usage like\n",
    "\n",
    "\n",
    "<code>%>photoz_metrics.py data/PointPredictions1.fits</code>\n",
    "\n",
    "\n",
    "or to do pdfs predictions at a time\n",
    "\n",
    "<code>%>photoz_metrics.py data/pdfPredictions*.hdf5</code>\n",
    "\n",
    "\n",
    "or a mix of the two, many point prediction files, and many pdf files\n",
    "\n",
    "<code>%>photoz_metrics.py data/pdfPredictions\\*.hdf5 data/PointPredictions\\*.fits</code>\n",
    "\n",
    "\n",
    "\n",
    "or you can make more fine tuned validations using a configuration YaML file\n",
    "\n",
    "\n",
    "<code>%>photoz_metrics.py config.yaml </code>\n",
    "\n",
    "\n",
    "\n",
    "<h4>help file</h4>\n",
    "If your just call it like this:\n",
    "\n",
    "<code>%>photoz_metrics.py</code> \n",
    "\n",
    "\n",
    "\n",
    "We will write a example YaML file to this directory.\n",
    "\n",
    "<h3>The validation code</h3>\n",
    "<p>Dependecies, pandas, astropy, pyYaml</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some dependencies. We'll need YAML (pip install pyYaml)\n",
    "import numpy as np\n",
    "#double count numpy, just to make our lives a bit easier!\n",
    "import numpy as numpy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "#what is the path to DES photo-z wg bucket/validation?\n",
    "#for Ben this is:\n",
    "#modify this for your system\n",
    "path_bh = '/Users/hoyleb/Documents/python/modules/photoz-wg/validation/'\n",
    "\n",
    "sys.path.append(path_bh)\n",
    "\n",
    "import bh_photo_z_validation as pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load the point predictions files</h3>\n",
    "<p>We assume that you already have the data in the correct format. This means it has the required point prediction redshift estimates, and Z_SPEC, and COADD_OBJECTS_ID and MAG_DETMODEL_I. We will now perform some \"unit-tests\" to ensure this.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COADD_OBJECTS_ID MAG_DETMODEL_I ...       Z_SPEC           Z_MC    \n",
      "---------------- -------------- ... ----------------- -------------\n",
      "               0  28.4614999009 ...  0.00070468158408  1.1448526257\n",
      "               1  21.2833863978 ... 0.000675929035848 1.61458159011\n"
     ]
    }
   ],
   "source": [
    "#change this to your fits file path\n",
    "pointPredictionFitsPath = path_bh + 'tests/data/validPointPrediction.fits'\n",
    "\n",
    "okay, dataFrame = pval.valid_file(pointPredictionFitsPath)\n",
    "if okay is False:\n",
    "    print \"the file is not in the correct format\"\n",
    "    print \"erorr message: \" + dataFrame\n",
    "print dataFrame[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the tests</h3>\n",
    "<p>We next will build a test. We write each test as a really lovely YaML file. YaML is desgined to be easy for humans to read. You'll understand how easy each test becomes, in a few seconds. </p>\n",
    "\n",
    "<p>Each test determines which metrics (such as $\\sigma_{68}$ or the K-S test) will be measured, and optionally if we want to measure the metric by binning the data along one of the columns, e.g. if we want to bin along MAG_DETMODEL_I. We can also decide to set an allowed \"tolerance\", this informs us if the tests passed with the required precision</p>\n",
    "\n",
    "<p>You don't need to write any tests if you don't want to. The standard ones are included already when you run the script from the command line. Below I shown an exmaple of what a test looks like. You can include as many tests, from as many sources as you like. Each test it it's own yaml file.</p>\n",
    "\n",
    "<p>The base tests can be found here </p>\n",
    "\n",
    "<code>%>ls photoz-wg/validation/testConfig/*.yaml</code>\n",
    "\n",
    "And looks like this: [The comments are also included in the file, for easy reading!]\n",
    "\n",
    "===== begin YaML file =======\n",
    "#these are the point prediction tests\n",
    "\n",
    "point:\n",
    "    #which photo-z predictions do we want to test\n",
    "    predictions: ['MODE_Z', 'MEAN_Z', 'Z_MC']\n",
    "    \n",
    "    #what is the true redshift that we will compare with?\n",
    "    truths: 'Z_SPEC'\n",
    "    \n",
    "    #what metrics do we want to measure. \"numpy.std\" is the standard deviation from numpy\n",
    "    # and \"bh_photo_z_validation.sigma_68\" is the sigma_68 metric found in the bh_photo_z_validation.py file\n",
    "    metrics: [numpy.std, numpy.median, bh_photo_z_validation.sigma_68, bh_photo_z_validation.outlier_fraction]\n",
    "    \n",
    "    #do we want to assign an accetable tolerance to each of these tests?\n",
    "    tolerance: [0.4, 0.001, 0.02, 5]\n",
    "    \n",
    "    #Finally do we want to also measure the metrics in some \"bins\". \n",
    "    #we define binning like this: column_name: 'string of bins / string of function that makes bins'\n",
    "    #we can have as many binning systems as we like\n",
    "    bins: ['MAG_DETMODEL_I': '[10, 15, 20, 25, 30]', 'MODE_Z': 'np.linspace(0, 2, 20)']\n",
    "\n",
    "\n",
    "\n",
    "#these are the pdf tests\n",
    "\n",
    "pdf: \n",
    "    \n",
    "    #in this example I don't want to do any binning.\n",
    "    bins:\n",
    "    \n",
    "    #I just want to measure these pdf comparison metrics\n",
    "    metrics: [bh_photo_z_validation.kstest, bh_photo_z_validation.npoisson, bh_photo_z_validation.log_loss]\n",
    "    \n",
    "    #And I don't care about tolerances.\n",
    "    tolerance:\n",
    "\n",
    "===== end YaML file =======\n",
    "\n",
    "\n",
    "You see that we have now defined a set of tests for both point predictions, and pdfs.\n",
    "\n",
    "\n",
    "<h3>Loading the tests</h3>\n",
    "<p>We load the tests like this!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pdf': {'metrics': ['bh_photo_z_validation.kstest', 'bh_photo_z_validation.npoisson', 'bh_photo_z_validation.log_loss'], 'truths': 'Z_SPEC', 'tolerance': None, 'bins': None}, 'point': {'metrics': ['numpy.std', 'numpy.median', 'bh_photo_z_validation.sigma_68', 'bh_photo_z_validation.outlier_fraction'], 'weights': 'WEIGHTS', 'error_function': ['bh_photo_z_validation.bootstrap_mean_error'], 'tolerance': [0.4, 0.001, 0.02, 5], 'truths': 'Z_SPEC', 'predictions': ['MODE_Z', 'MEAN_Z', 'Z_MC'], 'bins': [{'MAG_DETMODEL_I': '[ 17.5, 19, 22, 25]'}, {'MODE_Z': 'numpy.linspace(0, 2, 4)'}]}}\n",
      "\n",
      "Example of extracting a statistic to measure\n",
      "\n",
      "numpy.median\n",
      "\n",
      "Example of which error we can assign to this metric\n",
      "\n",
      "bh_photo_z_validation.bootstrap_mean_error\n",
      "\n",
      "This means look in bh_photo_z_validation.py to see this function. You can add your own error function too!\n"
     ]
    }
   ],
   "source": [
    "testYamlPath = path_bh + 'testConfig/photoz.yaml'\n",
    "testConfig = yaml.load(open(testYamlPath, 'r'))\n",
    "\n",
    "#the YaML file is parsed nicely to a python dictionary!\n",
    "print testConfig\n",
    "print \"\\nExample of extracting a statistic to measure\\n\"\n",
    "print testConfig['point']['metrics'][1]\n",
    "print \"\\nExample of which error we can assign to this metric\\n\"\n",
    "print testConfig['point']['error_function'][0]\n",
    "\n",
    "print \"\\nThis means look in bh_photo_z_validation.py to see this function. You can add your own error function too!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>YaML corrupt?</h3>\n",
    "<p>If your YaML file doesn't work, copy and check it here: http://yaml-online-parser.appspot.com\n",
    "\n",
    "<h3>Running a test for point predictions</h3>\n",
    "<p>Now we can play some testing magic. One thing to note, is they Python is <b>friggin</b> awesome. Remember we wrote the metric like this: 'bh_photo_z_validation.sigma_68', well we can turn this into an executable using a function found in bh_photo_z_validation.py called get_function(). We'll see this in the below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MODE_Z\n",
      "we measure the statistic: std\n",
      "and get the value: 0.56659060775 [or error and mean from bootstrap] {'sigma': 0.0076778096183699645, 'mean': 0.56177085733806831}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MODE_Z\n",
      "we measure the statistic: median\n",
      "and get the value: -0.967171558711 [or error and mean from bootstrap] {'sigma': 0.02336502874854943, 'mean': -0.97627721378164534}\n",
      "This bettter than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MODE_Z\n",
      "we measure the statistic: sigma_68\n",
      "and get the value: 0.658871062114 [or error and mean from bootstrap] {'sigma': 0.015576327800481437, 'mean': 0.66672617750460161}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MODE_Z\n",
      "we measure the statistic: outlier_fraction\n",
      "and get the value: 91.6 [or error and mean from bootstrap] {'sigma': 0.9364293886887578, 'mean': 91.630000000000024}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MEAN_Z\n",
      "we measure the statistic: std\n",
      "and get the value: 0.580711666474 [or error and mean from bootstrap] {'sigma': 0.0078259948782373589, 'mean': 0.58097187925693572}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MEAN_Z\n",
      "we measure the statistic: median\n",
      "and get the value: -0.992195304082 [or error and mean from bootstrap] {'sigma': 0.035051879292461986, 'mean': -0.99124518460297251}\n",
      "This bettter than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MEAN_Z\n",
      "we measure the statistic: sigma_68\n",
      "and get the value: 0.689953026427 [or error and mean from bootstrap] {'sigma': 0.014327818238296224, 'mean': 0.69058158744615317}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: MEAN_Z\n",
      "we measure the statistic: outlier_fraction\n",
      "and get the value: 91.4 [or error and mean from bootstrap] {'sigma': 0.90470989825468429, 'mean': 90.649999999999977}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: Z_MC\n",
      "we measure the statistic: std\n",
      "and get the value: 0.57502885927 [or error and mean from bootstrap] {'sigma': 0.0085464138600993417, 'mean': 0.5775443381122668}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: Z_MC\n",
      "we measure the statistic: median\n",
      "and get the value: -0.976955952082 [or error and mean from bootstrap] {'sigma': 0.030716069655949904, 'mean': -0.95990994704694932}\n",
      "This bettter than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: Z_MC\n",
      "we measure the statistic: sigma_68\n",
      "and get the value: 0.671078381837 [or error and mean from bootstrap] {'sigma': 0.014619895447742523, 'mean': 0.67504412302201788}\n",
      "This is worse than expected!\n",
      " \n",
      "\n",
      "using file: /Users/hoyleb/Documents/python/modules/photoz-wg/validation/tests/data/validPointPrediction.fits\n",
      "point prediction: Z_MC\n",
      "we measure the statistic: outlier_fraction\n",
      "and get the value: 91.9 [or error and mean from bootstrap] {'sigma': 0.91037135280060377, 'mean': 91.832000000000008}\n",
      "This is worse than expected!\n"
     ]
    }
   ],
   "source": [
    "pointTestConfig = testConfig['point']\n",
    "for eachPointPrediction in pointTestConfig['predictions']:\n",
    "    #let's calcalate the redshift scaled residuals Deltaz = (z - photz) / (1 + z)\n",
    "    deltaz_1pz = pval.delta_z_1pz(dataFrame[pointTestConfig['truths']], dataFrame[eachPointPrediction])\n",
    "    \n",
    "    #are we adding weights to each galaxy prediction?\n",
    "    weights = dataFrame[pointTestConfig['weights']]\n",
    "    \n",
    "    #now let's calculate the value of each chosen metric\n",
    "    for i, eachMetric in enumerate(pointTestConfig['metrics']):\n",
    "        \n",
    "        #amazing metric string to function conversion. \n",
    "        #Add your own functions by putting them in bh_photo_z_validation.py\n",
    "        metric_function = pval.get_function(eachMetric)\n",
    "        metric_value =  metric_function(deltaz_1pz)\n",
    "        \n",
    "        #no add our generic error function, we'll need weights for this\n",
    "        error_function = pval.get_function(pointTestConfig['error_function'][0])\n",
    "        \n",
    "        error_value = error_function(deltaz_1pz, weights, metric_function)\n",
    "        \n",
    "        print \" \\n\"\n",
    "        print \"using file: \" + pointPredictionFitsPath \n",
    "        print \"point prediction: \" + eachPointPrediction \n",
    "        print \"we measure the statistic: \" + eachMetric.split('.')[-1] \n",
    "        print \"and get the value: \" + str(metric_value) + \" [or error and mean from bootstrap]\", error_value\n",
    "        if metric_value < pointTestConfig['tolerance'][i]:\n",
    "            print \"This bettter than expected!\"\n",
    "        else:\n",
    "            print \"This is worse than expected!\"\n",
    "\n",
    "# All the results of these tests will be printed to the screen below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>pdf tests</h2>\n",
    "<p>Now let's turn our attention to the pdf tests. Let's load them and look at them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': ['bh_photo_z_validation.kstest', 'bh_photo_z_validation.npoisson', 'bh_photo_z_validation.log_loss'], 'truths': 'Z_SPEC', 'tolerance': None, 'bins': None}\n"
     ]
    }
   ],
   "source": [
    "pdfTestConfig = testConfig['pdf']\n",
    "print pdfTestConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
