{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Photo-z validation metrics on Resampled Alhambra/Cosmos Data</h2>\n",
    "\n",
    "This notebook shows how to load a .yaml /.p pickle file from all 100 of the resampled Alhambra/Cosmos validation files.\n",
    "\n",
    "We then determine the error, from the spread of metric values from the 100 RS validation data, and also from the Cosmic Variance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "point_NFE2G.p\n",
    "RS_ALH_COS_0.v1.fitsML_KDE_machine.v1.DES.point.predictions.fits\n",
    "\n",
    "point_C3SFO.p\n",
    "RS_ALH_COS_0.bpz.v1.probs.fits:\n",
    "    \n",
    "--REDSHIFT\n",
    "point_5YT90.p \n",
    "RS_ALH_COS_0.bpz.v1.probs.fits.SPEC.fits\n",
    "\n",
    "point_W7PFO.p\n",
    "RS_ALH_COS_0.v1.fitsML_KDE_machine.v1.DES.point.predictions.fits.SPEC.fits\n",
    "\n",
    "--SPEC_Z\n",
    "point_DKCBO.p\n",
    "RS_ALH_COS_0.v1.fitsML_KDE_machine.v1.DES.point.predictions.fits.SPEC.fits\n",
    "\n",
    "point_YM673.p\n",
    "RS_ALH_COS_0.bpz.v1.probs.fits.SPEC.fits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "path = '/Users/hoyleb/Documents/python/modules/photoz-wg/validation/'\n",
    "\n",
    "path_to_pickle_output_file = path + 'point_C3SFO.p'\n",
    "path_to_cos_var_pickle_file = path + 'cosmic_variance_data/cosvariance_cosmos_z_metrics.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "almost_black = '#262626'\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams.update({'font.size': 32, \n",
    "                     'axes.linewidth': 5,\n",
    "                    'text.color': almost_black,\n",
    "                    'xtick.major.size': 4,\n",
    "                    'ytick.major.size': 4,\n",
    "                    'legend.fancybox': True,\n",
    "                    'figure.dpi': 300,\n",
    "                    'legend.fontsize': 16,\n",
    "                    'legend.framealpha': 0.8,\n",
    "                    'legend.shadow': True,\n",
    "                    'xtick.labelsize': 22,\n",
    "                    'ytick.labelsize': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Metrics of interst</h3>\n",
    "\n",
    "Let us decide which metrics we want to measure. Edit this list with metrics that we measured from the validation script. Look at the structure of the validation .yaml file to understand this indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Form:\n",
    "#'metric_name': [WHICH_Z_COLUMN, WAY_TO_COMPARE_DISTs, METRIC, [,MEASURED_ON]]\n",
    "metrics = {'sigma_68': ['MEAN_Z', 'metrics_diffz','bh_photo_z_validation.sigma_68', 'delta_z'],\n",
    "           'outlier_fraction': ['MEAN_Z', 'metrics_diffz', \n",
    "                                'bh_photo_z_validation.outlier_fraction', 'diff_1pz'],\n",
    "           'median': ['MEAN_Z', 'metrics_diffz', 'numpy.median', 'delta_z'],\n",
    "           'wl_metric': ['Z_MC', 'metrics_z1_z2', 'bh_photo_z_validation.wl_metric']\n",
    "           }\n",
    "bin_column = 'MEAN_Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load results files</h3>\n",
    "\n",
    "Now let's load the .p [pickle] file output from the validation pipeline, and also the cosmic variance results we calculated elsewhere [Ask Youngsoo/Ben/Markus for details].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pickle.load(open(path_to_pickle_output_file, 'r'))\n",
    "cosvar = pickle.load(open(path_to_cos_var_pickle_file, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#import yaml\n",
    "#r = yaml.load(open(path + 'point_BJQ8S.yaml', 'r'))\n",
    "#pickle.dump(r, open(path + 'point_BJQ8S.p', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = res.keys()\n",
    "def get_val(dct, ky):\n",
    "    return dct[ky]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the error component from the resampled Alhambra data\n",
    "m_res = {} #temporary value storage\n",
    "metric_res = {} #this holds the median metric value, and std from the RS samples. Also the binned results\n",
    "for m in metrics.keys(): \n",
    "    met_kys = metrics[m]\n",
    "    m_res[m] ={'VALUES': [], 'BINS': {}, 'BIN_CENTER': []}\n",
    "    metric_res[m] = {'VALUES':[], 'BINS': {}}\n",
    "    for f in files:\n",
    "        test_name = res[f].keys()[0]\n",
    "        \n",
    "        for j, ky in enumerate(met_kys):\n",
    "            if j ==0:\n",
    "                dct = get_val(res[f][test_name], ky)\n",
    "            else:\n",
    "                dct = get_val(dct, ky)\n",
    "        \n",
    "        m_res[m]['VALUES'].append(dct['VALUE'])\n",
    "        z_bins = dct['bins'][bin_column]['BIN_CENTERS']\n",
    "\n",
    "        for j, zbn in enumerate(z_bins):\n",
    "            if j not in m_res[m]['BINS']:\n",
    "                m_res[m]['BINS'][j] = []\n",
    "                m_res[m]['BIN_CENTER'].append(zbn)\n",
    "            m_res[m]['BINS'][j].append(dct['bins'][bin_column]['VALUE'][j])\n",
    "    \n",
    "    #get the median value and the error component from the standard deviation of the resampled data.\n",
    "    metric_res[m]['VALUES'] = np.median(m_res[m]['VALUES']), np.std(m_res[m]['VALUES'])\n",
    "    for j, zbn in enumerate(m_res[m]['BIN_CENTER']):\n",
    "        metric_res[m]['BINS'][zbn] = np.median(m_res[m]['BINS'][j]), np.std(m_res[m]['BINS'][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Next add in CosmicVariance error component</h3>\n",
    "\n",
    "We repeat the above, and additionally calculate the error on each metric from cosmic variance. and from validating on high quality photo-z instead of spec-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_error_metric = {} #this will hold the median metric values, RS errors, AND CosVar Errors\n",
    "for m in metrics.keys(): \n",
    "    z_bin_edges = np.array(cosvar['z_bins'])\n",
    "    full_error_metric[m] = {'BINS':{}}\n",
    "    m1 = m\n",
    "    #argh! changed metric name. Silly me!\n",
    "    if m =='outlier_fraction':\n",
    "        m1 = 'outlierFrac'\n",
    "    \n",
    "    for j, zbn in enumerate(m_res[m]['BIN_CENTER']):\n",
    "        ind = np.where(zbn > z_bin_edges)[0][0]\n",
    "        met_cos_var_photz = np.std([cosvar['res'][f][ind]['z_cosmos'][m1] for f in cosvar['files']])\n",
    "        met_cos_var_truth = np.abs(met_cos_var_photz - np.std([cosvar['res'][f][ind]['z_truth'][m1] for f in cosvar['files']]))\n",
    "        \n",
    "        full_error_metric[m]['BINS'][zbn] = np.median(m_res[m]['BINS'][j]), np.std(m_res[m]['BINS'][j]), met_cos_var_photz, met_cos_var_truth\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot both error components</h3>\n",
    "\n",
    "Let's add the cosmic variance error in quadrature to the ReSample error, and plot the results for each metric, as a function of the tomographic bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ms = 8\n",
    "lw = 3\n",
    "for m in full_error_metric:\n",
    "    f= plt.figure()\n",
    "    z = full_error_metric[m]['BINS'].keys()\n",
    "    errRS = np.array([full_error_metric[m]['BINS'][j][1] for j in z]) #err from ReSample\n",
    "    errCV =  np.array([full_error_metric[m]['BINS'][j][2] for j in z]) #err from CosVar\n",
    "    errNonSpecZ =  np.array([full_error_metric[m]['BINS'][j][3] for j in z]) #err from CosVar\n",
    "    \n",
    "    err = np.sqrt(errRS**2 + errCV**2 + errNonSpecZ**2) #add in quadrature\n",
    "    plt.errorbar(np.array(z)-0.02, [full_error_metric[m]['BINS'][j][0] for j in z], yerr=errNonSpecZ,fmt=',', markersize=str(Ms), elinewidth=lw,label='Photz-Specz err')\n",
    "    plt.errorbar(np.array(z)-0.01, [full_error_metric[m]['BINS'][j][0] for j in z], yerr=errCV,fmt=',', markersize=str(Ms), elinewidth=lw,label='RS mag err')\n",
    "    plt.errorbar(np.array(z), [full_error_metric[m]['BINS'][j][0] for j in z], yerr=errRS,fmt=',',markersize=str(Ms), elinewidth=lw, label='CosVar err')\n",
    "    plt.errorbar(np.array(z)+0.01, [full_error_metric[m]['BINS'][j][0] for j in z], yerr=err, fmt='o',markersize=str(Ms), elinewidth=lw, label='All errs')\n",
    "    plt.xlabel('Tomographic redshift bin')\n",
    "    plt.title('BPZ code')\n",
    "    \n",
    "    \n",
    "    plt.ylabel(m)\n",
    "    plt.legend(loc=2)\n",
    "    if m =='wl_metric':  #little hack to show WL requirements.\n",
    "        plt.plot([0,1.2], [0.02,0.02],'--', linewidth=3)\n",
    "        plt.ylim(0, 0.2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
